<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a">338: The NarrativeQA Reading Comprehension Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811260</td>
<td>0.979874</td>
<td><a href="https://www.semanticscholar.org/paper/f038ebfb6124053360133f7347fef3f3643437d8">0: Improving Machine Reading Comprehension with Multi-Task Learning and Self-Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811069</td>
<td>-0.031775</td>
<td><a href="https://www.semanticscholar.org/paper/9aec67c52ca8172f4ee1bafc3bc53521342dc621">0: Syntax-Aware Multi-Spans Generation for Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.808692</td>
<td>0.985117</td>
<td><a href="https://www.semanticscholar.org/paper/e27031f5a47025eaedd65af3b4a48f07b5636514">14: A Framework for Evaluation of Machine Reading Comprehension Gold Standards</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805756</td>
<td>0.991406</td>
<td><a href="https://www.semanticscholar.org/paper/8d00049c345b9c8cc76ea2ea2565f8bb69f6b683">107: Retrospective Reader for Machine Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793709</td>
<td>0.630534</td>
<td><a href="https://www.semanticscholar.org/paper/046cb4fd0f0155686e45b26b346d1c9acfe93958">0: Tagging Reading Comprehension Materials With Document Extraction Attention Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788715</td>
<td>0.974700</td>
<td><a href="https://www.semanticscholar.org/paper/af38829cdb55ee7b71d49399f71397d975e40a95">1: ConditionalQA: A Complex Reading Comprehension Dataset with Conditional Answers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785613</td>
<td>0.980249</td>
<td><a href="https://www.semanticscholar.org/paper/0f08f4458dcf7618263405cbf31e6a48684bc1fa">0: Discrete Reasoning Templates for Natural Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782656</td>
<td>0.699180</td>
<td><a href="https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc">207: FVQA: Fact-Based Visual Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781640</td>
<td>0.625680</td>
<td><a href="https://www.semanticscholar.org/paper/40e73a562810e0c620dbb28383f22a595a32b9a2">1: Understanding Synonymous Referring Expressions via Contrastive Features</a></td>
</tr>
<tr>
<td>0</td>
<td>0.697271</td>
<td>0.998277</td>
<td><a href="https://www.semanticscholar.org/paper/8f1c9b656157b1d851563fb42129245701d83175">70: Transforming Question Answering Datasets Into Natural Language Inference Datasets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799950</td>
<td>0.998251</td>
<td><a href="https://www.semanticscholar.org/paper/990a7b4eceedb6e053e6386269481bdfc42a1094">608: CoQA: A Conversational Question Answering Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756301</td>
<td>0.998021</td>
<td><a href="https://www.semanticscholar.org/paper/cd832f7081ab7b83240140c4e5e58b4fb1f8e0e6">96: Interpretation of Natural Language Rules in Conversational Machine Reading</a></td>
</tr>
<tr>
<td>0</td>
<td>0.652033</td>
<td>0.997816</td>
<td><a href="https://www.semanticscholar.org/paper/0a5606f0d56c618aa610cb1677e2788a3bd678fa">67: A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC</a></td>
</tr>
<tr>
<td>0</td>
<td>0.773787</td>
<td>0.996923</td>
<td><a href="https://www.semanticscholar.org/paper/995b7affd684b910d5a1c520c3af00fd20cc39b0">167: DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications</a></td>
</tr>
<tr>
<td>0</td>
<td>0.789566</td>
<td>0.996741</td>
<td><a href="https://www.semanticscholar.org/paper/39e734da43eb8c72e9549b42e96760545036f8e5">428: QuAC: Question Answering in Context</a></td>
</tr>
<tr>
<td>0</td>
<td>0.779780</td>
<td>0.996443</td>
<td><a href="https://www.semanticscholar.org/paper/3eda43078ae1f4741f09be08c4ecab6229046a5c">579: NewsQA: A Machine Comprehension Dataset</a></td>
</tr>
<tr>
<td>0</td>
<td>0.764570</td>
<td>0.995863</td>
<td><a href="https://www.semanticscholar.org/paper/b2821ea94b1a7645a8befabce3a161473eb2e965">78: Unsupervised Question Answering by Cloze Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760189</td>
<td>0.995776</td>
<td><a href="https://www.semanticscholar.org/paper/c2fa95fd90665aeef031fe3cc1b5f5572e4fe16c">27: FriendsQA: Open-Domain Question Answering on TV Show Transcripts</a></td>
</tr>
</table></html>
