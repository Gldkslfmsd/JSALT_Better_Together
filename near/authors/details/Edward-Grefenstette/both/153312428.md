<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/fbf03bf621ffee283911e765d525a75fc0d11bae">48: CompILE: Compositional Imitation Learning and Execution</a></td>
</tr>
<tr>
<td>1</td>
<td>0.961953</td>
<td>0.982927</td>
<td><a href="https://www.semanticscholar.org/paper/683599f260a877fef5e97a643852b854ae3db9a1">10: Compositional Imitation Learning: Explaining and executing one task at a time</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806513</td>
<td>0.970163</td>
<td><a href="https://www.semanticscholar.org/paper/de1d160558cbeff4e0dc703a43f6dcf25b42c3eb">2: Hierarchical Variational Imitation Learning of Control Programs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804089</td>
<td>0.913909</td>
<td><a href="https://www.semanticscholar.org/paper/34f5d2f039558ba0b6a5103553ad68321fa6eabd">33: Guiding Policies with Language via Meta-Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802974</td>
<td>0.903187</td>
<td><a href="https://www.semanticscholar.org/paper/745aa968dd81c3639b8d765ea63855cf0741ad92">12: Synthesizing Programmatic Policies that Inductively Generalize</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800736</td>
<td>-0.028243</td>
<td>NA:232203509</td>
</tr>
<tr>
<td>0</td>
<td>0.797492</td>
<td>0.897222</td>
<td><a href="https://www.semanticscholar.org/paper/3af4bf4c1bc05b029b05d333a4b963594727de4f">1: PLOTS: Procedure Learning from Observations using Subtask Structure</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791740</td>
<td>0.791561</td>
<td><a href="https://www.semanticscholar.org/paper/2b7eec22946e331814f4e61a5c2dee0eadf8ef02">1: Learning Skill Hierarchies from Predicate Descriptions and Self-Supervision</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781399</td>
<td>0.830286</td>
<td><a href="https://www.semanticscholar.org/paper/9b88cb2d166a19127ccda82239d0e194290f082c">4: Deep reinforcement learning using compositional representations for performing instructions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.775564</td>
<td>0.837873</td>
<td><a href="https://www.semanticscholar.org/paper/ce7e0c1e5f22fa80fbeba7792c1323180a99359f">8: Compositional Reinforcement Learning from Logical Specifications</a></td>
</tr>
<tr>
<td>0</td>
<td>0.739297</td>
<td>0.978576</td>
<td><a href="https://www.semanticscholar.org/paper/f18d245627d6089cb8a0e4a7757f45c13b96bdaf">101: Learning and Querying Fast Generative Models for Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.726904</td>
<td>0.977015</td>
<td><a href="https://www.semanticscholar.org/paper/401dfc5efbd182eaef6945249aea8a0a1e3cced5">71: Shaping Belief States with Generative Environment Models for RL</a></td>
</tr>
<tr>
<td>0</td>
<td>0.667967</td>
<td>0.975111</td>
<td><a href="https://www.semanticscholar.org/paper/963cc19101ac6409ba6db0bc07d8ce1baecaf84a">28: Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.677640</td>
<td>0.973852</td>
<td><a href="https://www.semanticscholar.org/paper/1f9bd213998abcce0f1826f13ea082997047ad4c">4: Combating False Negatives in Adversarial Imitation Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.662875</td>
<td>0.972594</td>
<td><a href="https://www.semanticscholar.org/paper/bb430ec2f25e4a1513073a2a4098cbb942c2e3e0">150: Recurrent Environment Simulators</a></td>
</tr>
<tr>
<td>0</td>
<td>0.706993</td>
<td>0.972520</td>
<td><a href="https://www.semanticscholar.org/paper/d0ca8e0b9e1d31d832b4b25bfe8ef825abb7c833">63: COBRA: Data-Efficient Model-Based RL through Unsupervised Object Discovery and Curiosity-Driven Exploration</a></td>
</tr>
<tr>
<td>0</td>
<td>0.704736</td>
<td>0.970576</td>
<td><a href="https://www.semanticscholar.org/paper/8dabfc8f58d4c1067a557fd658cf5c9a82260c11">0: Blockwise Sequential Model Learning for Partially Observable Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758023</td>
<td>0.970316</td>
<td><a href="https://www.semanticscholar.org/paper/0acae07e0fb13ba551c307fc30ed476ad4b6cb39">120: Coordinated Multi-Agent Imitation Learning</a></td>
</tr>
</table></html>
