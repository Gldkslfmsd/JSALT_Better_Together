<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/599f7863721d542dcef2da49b41d82b21e4f80b3">137: Learning to Compose Words into Sentences with Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.833541</td>
<td>0.960802</td>
<td><a href="https://www.semanticscholar.org/paper/d22f24414753c9b20f78df28d8937ce16c3b28d3">29: Jointly Learning to Label Sentences and Tokens</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831721</td>
<td>0.893005</td>
<td><a href="https://www.semanticscholar.org/paper/f3d04bd02df3be26365ebe3005bcd45db3736058">0: Extensions to Tree-Recursive Neural Networks for Natural Language Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.827907</td>
<td>0.844222</td>
<td><a href="https://www.semanticscholar.org/paper/eb8fb36d983c42d5f708e4709eeb8489dbe05236">2: Simplifying Sentences with Sequence to Sequence Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811365</td>
<td>0.624195</td>
<td><a href="https://www.semanticscholar.org/paper/83ed88e4f745cc9aecd1fbd479612b11beddcb86">95: CLEAR: Contrastive Learning for Sentence Representation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810154</td>
<td>0.950964</td>
<td><a href="https://www.semanticscholar.org/paper/c105b28ced47fd685b57eff6be73e03b7b073a27">78: Sentence Ordering and Coherence Modeling using Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802120</td>
<td>0.893333</td>
<td><a href="https://www.semanticscholar.org/paper/0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38">476: Semi-supervised sequence tagging with bidirectional language models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802066</td>
<td>0.921237</td>
<td><a href="https://www.semanticscholar.org/paper/f4efccf51d54c1b60823a58bc27eb2092169e675">6: Multi-task Learning for Universal Sentence Embeddings: A Thorough Evaluation using Transfer and Auxiliary Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800034</td>
<td>0.619823</td>
<td><a href="https://www.semanticscholar.org/paper/785a7f1fbf8a175eb37324bab82b0d6396746466">0: Learning Meanings for Sentences with Recursive Autoencoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799030</td>
<td>0.937356</td>
<td><a href="https://www.semanticscholar.org/paper/427fd39d61ee2ae234d132e5353160bb2476e931">0: Sequential LSTM-based Encoder for NLI</a></td>
</tr>
<tr>
<td>0</td>
<td>0.841850</td>
<td>0.991732</td>
<td><a href="https://www.semanticscholar.org/paper/3096b9e5b17dedbee9554fbd1d6e20f7a095e48a">70: Jointly learning sentence embeddings and syntax with unsupervised Tree-LSTMs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799079</td>
<td>0.989650</td>
<td><a href="https://www.semanticscholar.org/paper/a308e67ad08f29c7bcfeef9e7a20f72453e31678">14: Latent Tree Learning with Differentiable Parsers: Shift-Reduce Parsing and Chart Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782626</td>
<td>0.988060</td>
<td><a href="https://www.semanticscholar.org/paper/cff79255a94b9b05a4ce893eb403a522e0923f04">128: Neural Semantic Encoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.725392</td>
<td>0.987801</td>
<td><a href="https://www.semanticscholar.org/paper/1f9e2d6df1eaaf04aebf428d9fa9a9ffc89e373c">190: A Joint Model of Intent Determination and Slot Filling for Spoken Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.722139</td>
<td>0.987698</td>
<td><a href="https://www.semanticscholar.org/paper/17c5267f59f7bf28f9605cac644e694b39c6d642">56: ONENET: Joint domain, intent, slot prediction for spoken language understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.685512</td>
<td>0.986782</td>
<td><a href="https://www.semanticscholar.org/paper/df0745ce821007cb3122f00509cc18f2885fa8bd">134: End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804985</td>
<td>0.985893</td>
<td><a href="https://www.semanticscholar.org/paper/027f9695189355d18ec6be8e48f3d23ea25db35d">150: Learning to Compose Task-Specific Tree Structures</a></td>
</tr>
<tr>
<td>0</td>
<td>0.703777</td>
<td>0.985465</td>
<td><a href="https://www.semanticscholar.org/paper/9b82c6e78ceaa5e540862849defc818f7c8a47df">339: Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM</a></td>
</tr>
<tr>
<td>0</td>
<td>0.660295</td>
<td>0.985232</td>
<td><a href="https://www.semanticscholar.org/paper/25512943124ec62488a45a1aba177e2eca1ea109">0: POS Scaling Attention Model for Joint Slot Filling and Intent Classification</a></td>
</tr>
</table></html>
