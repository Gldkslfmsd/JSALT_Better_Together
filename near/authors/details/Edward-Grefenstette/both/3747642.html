<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/970f474fc5408f079f627adbc9a300dfca7e317e">65: Learning to Compute Word Embeddings On the Fly</a></td>
</tr>
<tr>
<td>0</td>
<td>0.860638</td>
<td>0.973182</td>
<td><a href="https://www.semanticscholar.org/paper/8e32e1f02b7060ce419a964b800d0927a2e1d69c">120: Mimicking Word Embeddings using Subword RNNs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.857024</td>
<td>0.856435</td>
<td><a href="https://www.semanticscholar.org/paper/e0c4a2116ec0f3dc48457627bbd8bfe1f0026479">0: Overcoming Poor Word Embeddings with Word Definitions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.849661</td>
<td>0.701885</td>
<td><a href="https://www.semanticscholar.org/paper/d0ff10febd7e78b12c8b315e6feb599100dde967">0: Distributional memory explainable word embeddings in continuous space</a></td>
</tr>
<tr>
<td>0</td>
<td>0.846098</td>
<td>0.830909</td>
<td><a href="https://www.semanticscholar.org/paper/e89f679710507e239775a1e9c81988c3f928cbed">239: Word Embeddings through Hellinger PCA</a></td>
</tr>
<tr>
<td>0</td>
<td>0.846008</td>
<td>0.949921</td>
<td><a href="https://www.semanticscholar.org/paper/5fb5a45f69b2b68b5da3579f776613f931c7aa2c">17: InferLite: Simple Universal Sentence Representations from Natural Language Inference Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.840367</td>
<td>0.829951</td>
<td><a href="https://www.semanticscholar.org/paper/f9f91e7bac46b13444eddeb2438b01089e73b786">295: Tailoring Continuous Word Representations for Dependency Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.833273</td>
<td>0.827367</td>
<td><a href="https://www.semanticscholar.org/paper/6a729b580f4bdb978711722b0b212dc04e904196">6: Learning class-specific word embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830430</td>
<td>0.927635</td>
<td><a href="https://www.semanticscholar.org/paper/054f8e72919fb3140f95e259f7de143b9845cc8a">1: Out-of-Vocabulary Embedding Imputation with Grounded Language Information by Graph Convolutional Networks.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.828727</td>
<td>0.895517</td>
<td><a href="https://www.semanticscholar.org/paper/8f12c142dd892923872c003928d24a7b5c890e35">0: Shape of Elephant: Study of Macro Properties of Word Embeddings Spaces</a></td>
</tr>
<tr>
<td>0</td>
<td>0.635291</td>
<td>0.990637</td>
<td><a href="https://www.semanticscholar.org/paper/f6409610f98317aa34b2b1b05eb054103d800ad3">0: Text Matching Model that Fuse Position-Encoding with Multiple Attentional Mechanisms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.650561</td>
<td>0.989969</td>
<td><a href="https://www.semanticscholar.org/paper/7334f45c06555d4b6bf7e6b4437574c11369697e">34: Chinese Relation Extraction with Multi-Grained Information and External Linguistic Knowledge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.661512</td>
<td>0.989264</td>
<td><a href="https://www.semanticscholar.org/paper/235e255462446d7364d9a5df7dc6fe736a7249ad">341: Reporting Score Distributions Makes a Difference: Performance Study of LSTM-networks for Sequence Tagging</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.988707</td>
<td><a href="https://www.semanticscholar.org/paper/2b83a718e6a0ab5439cbc0bfe288d2fd54a1792c">1: CED-BGFN: Chinese Event Detection via Bidirectional Glyph-Aware Dynamic Fusion Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.655889</td>
<td>0.987409</td>
<td><a href="https://www.semanticscholar.org/paper/e323f3e86cd766b50ade5d722af810f1ce3d2664">22: Obligation and Prohibition Extraction Using Hierarchical RNNs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.670250</td>
<td>0.987199</td>
<td><a href="https://www.semanticscholar.org/paper/b0db941b5f9cd3a9c1ace0cb9fd9b65acb7dd219">0: A Label Dependence-aware Sequence Generation Model for Multi-level Implicit Discourse Relation Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.664339</td>
<td>0.986870</td>
<td><a href="https://www.semanticscholar.org/paper/ea407573bfcd39f9a478fe33cf6ce0ee1780a5f0">285: Natural Language Inference by Tree-Based Convolution and Heuristic Matching</a></td>
</tr>
<tr>
<td>0</td>
<td>0.641966</td>
<td>0.986619</td>
<td><a href="https://www.semanticscholar.org/paper/a9df777e4d8100e52e90fa4bd2d783d25a2fd173">536: Bilateral Multi-Perspective Matching for Natural Language Sentences</a></td>
</tr>
<tr>
<td>0</td>
<td>0.706078</td>
<td>0.986221</td>
<td><a href="https://www.semanticscholar.org/paper/8dd6aae51e31a72752c4be5cddbdd76dfdc6cda4">1972: End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</a></td>
</tr>
</table></html>
