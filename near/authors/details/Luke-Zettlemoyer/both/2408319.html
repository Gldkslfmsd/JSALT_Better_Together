<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/58bd0afc8a1b98e16a67ebda436e60c6f6410f56">290: A Joint Model of Language and Perception for Grounded Attribute Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.839670</td>
<td>0.685933</td>
<td><a href="https://www.semanticscholar.org/paper/4ae7dfabc739dda48a242e7f747995333031df68">33: A probabilistic approach to learning a visually grounded language model through human-robot interaction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804951</td>
<td>0.858491</td>
<td><a href="https://www.semanticscholar.org/paper/5f911b35fa3e56ed8a8cdb2fce211155faa8d091">47: Grounded Language Learning: Where Robotics and NLP Meet</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786443</td>
<td>0.297001</td>
<td><a href="https://www.semanticscholar.org/paper/4a18affba68096f53a8a884e4a9ebd34e65d305f">67: Relational inductive bias for physical construction in humans and machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781304</td>
<td>0.786030</td>
<td><a href="https://www.semanticscholar.org/paper/267f3674d02ab3b53e0ac58e082380547b0bbf1c">0: Beyond Labels and Captions: Contextualizing Grounded Semantics for Explainable Visual Interpretation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.779253</td>
<td>0.824261</td>
<td><a href="https://www.semanticscholar.org/paper/fc78991050e355477f9d0ba51a241947e8bc9b9d">8: CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774527</td>
<td>0.483980</td>
<td><a href="https://www.semanticscholar.org/paper/84fb678d39095c6be070aad1e005bc83712c2d66">9: Learning as the Unsupervised Alignment of Conceptual Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767540</td>
<td>-0.047754</td>
<td>NA:206093674</td>
</tr>
<tr>
<td>0</td>
<td>0.763996</td>
<td>0.251622</td>
<td><a href="https://www.semanticscholar.org/paper/52139bcd19ebe368d488b27458095f3d6e9ef5b9">19: The Multi-Entity Variational Autoencoder</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760677</td>
<td>0.578068</td>
<td><a href="https://www.semanticscholar.org/paper/99d92f71fbbd3fcac4213798844b1a11654359dd">4: A framework for recognizing and executing verb phrases</a></td>
</tr>
<tr>
<td>0</td>
<td>0.778877</td>
<td>0.983961</td>
<td><a href="https://www.semanticscholar.org/paper/c45fd881bcc20bc1a754ee4b446d99aaff1d3dd5">162: Jointly Learning to Parse and Perceive: Connecting Natural Language to the Physical World</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801213</td>
<td>0.983008</td>
<td><a href="https://www.semanticscholar.org/paper/f0eb5eee7173380e290f737187c4584ebe501331">40: Toward Interactive Grounded Language Acqusition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.773299</td>
<td>0.973776</td>
<td><a href="https://www.semanticscholar.org/paper/4d4db4d8ac9f0d0cc0fe2f8e4d487354300ba91a">32: Jointly Improving Parsing and Perception for Natural Language Commands through Human-Robot Dialog</a></td>
</tr>
<tr>
<td>0</td>
<td>0.761774</td>
<td>0.972856</td>
<td><a href="https://www.semanticscholar.org/paper/d41596611d2a0b755265c9c9ffa07cc034b46e71">44: Improving Grounded Natural Language Understanding through Human-Robot Dialog</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821106</td>
<td>0.970354</td>
<td><a href="https://www.semanticscholar.org/paper/d444de6f3df06c9c1fd6cae889cc12115e3d9238">4: Building Language-Agnostic Grounded Language Learning Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742974</td>
<td>0.964490</td>
<td><a href="https://www.semanticscholar.org/paper/1b0c78644069b231b9f2421086f21a17644b9726">11: Multimodal estimation and communication of latent semantic knowledge for robust execution of robot instructions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759793</td>
<td>0.963468</td>
<td><a href="https://www.semanticscholar.org/paper/9669d8537898599290166586a3a81716105db378">3: Improving Grounded Natural Language Understanding through Human-Robot Dialog</a></td>
</tr>
<tr>
<td>0</td>
<td>0.713942</td>
<td>0.962931</td>
<td><a href="https://www.semanticscholar.org/paper/bb06a75c5848c638148ea9649639484f1323a576">35: Grounded Semantic Role Labeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751798</td>
<td>0.962924</td>
<td><a href="https://www.semanticscholar.org/paper/1c49d48268bf93061e308f2a3c320176a0407567">38: Efficient grounding of abstract spatial concepts for natural language interaction with robot platforms</a></td>
</tr>
</table></html>
