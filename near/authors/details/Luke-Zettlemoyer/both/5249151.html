<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/cc1648c91ffda21bbe6e5f08f69c683588fc384c">261: Reinforcement Learning for Mapping Instructions to Actions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.978706</td>
<td>0.906084</td>
<td><a href="https://www.semanticscholar.org/paper/2918f4d921c2f85f41c250d7ed44e4705ece65fd">0: Reinforcement Learning for Mapping Instructions to Actions Citation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.838952</td>
<td>0.785726</td>
<td><a href="https://www.semanticscholar.org/paper/323dd51eb778cb428d56b7e291491f709f45ada2">19: Guiding Reinforcement Learning Exploration Using Natural Language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829635</td>
<td>0.859338</td>
<td><a href="https://www.semanticscholar.org/paper/82f93fe25ab59164c8dbb571de7afcce1e43c839">29: Situated Mapping of Sequential Instructions to Actions with Single-step Reward Observation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821482</td>
<td>0.868504</td>
<td><a href="https://www.semanticscholar.org/paper/0916d3112978bbe5f123553b5460ac1d05c6a8fd">0: Mapping Language to Programs using Multiple Reward Components with Inverse Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816467</td>
<td>0.807732</td>
<td><a href="https://www.semanticscholar.org/paper/71b152f65fd9967ec39f1e1f359ad0d99be1bab2">29: Learning to Follow Language Instructions with Adversarial Reward Induction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.815064</td>
<td>0.753526</td>
<td><a href="https://www.semanticscholar.org/paper/766d48ad414065e5e2fa4fef13c8951f28b58bf4">30: The Natural Language of Actions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804903</td>
<td>0.824623</td>
<td><a href="https://www.semanticscholar.org/paper/34f5d2f039558ba0b6a5103553ad68321fa6eabd">33: Guiding Policies with Language via Meta-Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798624</td>
<td>0.581840</td>
<td><a href="https://www.semanticscholar.org/paper/0ae2c69573673c16e96ab48aa9fc8b6ed807b451">25: Improving reinforcement learning by using sequence trees</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791684</td>
<td>0.550461</td>
<td><a href="https://www.semanticscholar.org/paper/ec9cf6922aae97b7c728693e78bd5cb812cc4e1e">17: Learning Novel Policies For Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731202</td>
<td>0.987532</td>
<td><a href="https://www.semanticscholar.org/paper/da5289121e139b6810781301a890c94c25a0d3d7">195: Learning to Follow Navigational Directions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786940</td>
<td>0.987099</td>
<td><a href="https://www.semanticscholar.org/paper/66ff889f25829822169d5971e706013ed909d574">109: Reading between the Lines: Learning to Map High-Level Instructions to Commands</a></td>
</tr>
<tr>
<td>0</td>
<td>0.628157</td>
<td>0.977171</td>
<td><a href="https://www.semanticscholar.org/paper/a46d84b9c4e3f76141615ce44538bb638df7e082">35: NJFun- A Reinforcement Learning Spoken Dialogue System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691024</td>
<td>0.972020</td>
<td><a href="https://www.semanticscholar.org/paper/ef0c25182664ee588d8c4af77946cdd7bde4bd32">22: Integrated Learning of Dialog Strategies and Semantic Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674400</td>
<td>0.970632</td>
<td><a href="https://www.semanticscholar.org/paper/a74fb349706be2bc5cf95ef7469620dd2db4d5cc">130: An ISU Dialogue System Exhibiting Reinforcement Learning of Dialogue Policies: Generic Slot-Filling in the TALK In-car System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727300</td>
<td>0.968102</td>
<td><a href="https://www.semanticscholar.org/paper/3dcb123c2fa47808e3f0e2af2c67c72d5da38914">46: Reinforcement Learning of Question-Answering Dialogue Policies for Virtual Museum Guides</a></td>
</tr>
<tr>
<td>0</td>
<td>0.706953</td>
<td>0.967973</td>
<td><a href="https://www.semanticscholar.org/paper/6f59702aa1c114f45372b9dd6110812c23ac2d8d">9: Learning to Interpret Natural Language Instructions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.618969</td>
<td>0.966707</td>
<td><a href="https://www.semanticscholar.org/paper/b0842f8464d322e64854f1e08c97625b50d32672">23: Combining Chat and Task-Based Multimodal Dialogue for More Engaging HRI: A Scalable Method Using Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.683425</td>
<td>0.966572</td>
<td><a href="https://www.semanticscholar.org/paper/2a16ace054364557c8b8b4bf55f7293cd6d1a9ab">144: Learning to Interpret Natural Language Commands through Human-Robot Dialog</a></td>
</tr>
</table></html>
