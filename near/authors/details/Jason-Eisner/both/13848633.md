<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/d323d011a3214116a18d623501bca9a31d33cf4c">54: Are All Languages Equally Hard to Language-Model?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.998541</td>
<td>0.921071</td>
<td><a href="https://www.semanticscholar.org/paper/1a5dcdb9206e34de052b22d076bef186f7959c94">9: Are All Languages Equally Hard to Language-Model?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829323</td>
<td>0.743533</td>
<td><a href="https://www.semanticscholar.org/paper/d6fa3acbb070132979165671c80344fd4c6f9450">0: LMdiff: A Visual Diff Tool to Compare Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823306</td>
<td>0.861027</td>
<td><a href="https://www.semanticscholar.org/paper/18429049d0576eb3506bcbe37c7776302c9c42b9">0: An Empirical Study of Factors Affecting Language-Independent Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801251</td>
<td>0.939096</td>
<td><a href="https://www.semanticscholar.org/paper/ed5003e6a2b97dd4b65c5190ccb88b9c45b032b8">32: Learning to Create and Reuse Words in Open-Vocabulary Neural Language Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799537</td>
<td>0.573841</td>
<td><a href="https://www.semanticscholar.org/paper/7be21ebb963a2d6bbfbdd315a7c9e9bd52c740de">17: Using cross-language cues for story-specific language modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.797708</td>
<td>0.803074</td>
<td><a href="https://www.semanticscholar.org/paper/87f714f3534c7a3ca2bf41ce5825139ddc8247bf">59: What to do about non-standard (or non-canonical) language in NLP</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794201</td>
<td>0.950091</td>
<td><a href="https://www.semanticscholar.org/paper/a48abad56acb085fe180c76a40d361aacd0dc049">9: Exploiting Syntactic Structure for Better Language Modeling: A Syntactic Distance Approach</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793819</td>
<td>0.069383</td>
<td><a href="https://www.semanticscholar.org/paper/778b9699413747d5fcbe8ce260a598859c5c79d1">1: Efficient Language Models Combination: Application to Phrase Finding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790217</td>
<td>0.411538</td>
<td><a href="https://www.semanticscholar.org/paper/378ab9fc84ff57bbfa45a81590ec0bc19a3c632e">24: Multilingual Resource Sharing Across Both Related and Unrelated Languages: An Implemented, Open-Source Framework for Practical Natural Language Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.623683</td>
<td>0.986393</td>
<td><a href="https://www.semanticscholar.org/paper/7345843e87c81e24e42264859b214d26042f8d51">421: Recurrent Neural Network Grammars</a></td>
</tr>
<tr>
<td>0</td>
<td>0.538152</td>
<td>0.986297</td>
<td><a href="https://www.semanticscholar.org/paper/8785efdad2abc384d38e76a84fb96d19bbe788c1">139: Bidirectional Recurrent Neural Network with Attention Mechanism for Punctuation Restoration</a></td>
</tr>
<tr>
<td>0</td>
<td>0.664976</td>
<td>0.984570</td>
<td><a href="https://www.semanticscholar.org/paper/1937c6934528bcf9950c39bbe5360a36365315fb">13: Leveraging a Character, Word and Prosody Triplet for an ASR Error Robust and Agglutination Friendly Punctuation Approach</a></td>
</tr>
<tr>
<td>0</td>
<td>0.744895</td>
<td>0.983970</td>
<td><a href="https://www.semanticscholar.org/paper/d617f51833860dc50d202af7f80be71304b2e994">3: Between words and characters: A Brief History of Open-Vocabulary Modeling and Tokenization in NLP</a></td>
</tr>
<tr>
<td>0</td>
<td>0.688990</td>
<td>0.983460</td>
<td><a href="https://www.semanticscholar.org/paper/dd3291fe1245c9ffe492eb34f143be74f36a9b34">75: Disfluency Detection Using a Bidirectional LSTM</a></td>
</tr>
<tr>
<td>0</td>
<td>0.729200</td>
<td>0.982409</td>
<td><a href="https://www.semanticscholar.org/paper/f1cbf097ce436f7304a1984f4a29ab41f75ebfe3">131: Neural Language Modeling by Jointly Learning Syntax and Lexicon</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732225</td>
<td>0.982116</td>
<td><a href="https://www.semanticscholar.org/paper/24ddc6d938c32766559d3e5c66de11ac1743fc21">64: Straight to the Tree: Constituency Parsing with Neural Syntactic Distance</a></td>
</tr>
<tr>
<td>0</td>
<td>0.647654</td>
<td>0.982105</td>
<td><a href="https://www.semanticscholar.org/paper/4e502d010e31a7855c719ec4aaceb34920e0828b">42: Sequence-to-sequence models for punctuated transcription combining lexical and acoustic features</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734516</td>
<td>0.981684</td>
<td><a href="https://www.semanticscholar.org/paper/5054f6080e232c4ef456e2888950c211a6d0d268">69: Scheduled Multi-Task Learning: From Syntax to Translation</a></td>
</tr>
</table></html>
