<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/3081c0ae1157e986d4fbec21764081d29b25c8a2">562: DRAFT Overview of the TREC 2003 Question Answering Track</a></td>
</tr>
<tr>
<td>0</td>
<td>0.995887</td>
<td>0.990005</td>
<td><a href="https://www.semanticscholar.org/paper/1a5a60233da0feec4d6c3c22f9b3b8656d0dbd84">94: Overview of the TREC 2003 Question Answering Track</a></td>
</tr>
<tr>
<td>0</td>
<td>0.935751</td>
<td>0.126865</td>
<td>NA:215746886</td>
</tr>
<tr>
<td>1</td>
<td>0.915862</td>
<td>0.997359</td>
<td><a href="https://www.semanticscholar.org/paper/0d8bf6be792deb9b7e499b361a8332f0dce68089">525: Overview of the TREC 2002 Question Answering Track</a></td>
</tr>
<tr>
<td>0</td>
<td>0.875024</td>
<td>0.965839</td>
<td><a href="https://www.semanticscholar.org/paper/74e03acd5532fbad4c770e9293d2a788b11364f7">230: The TREC-8 Question Answering Track</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818258</td>
<td>0.952963</td>
<td><a href="https://www.semanticscholar.org/paper/a900b3a28337cae37126d7e538176e8c2af1b9ef">0: Evidence Gathering and Language Alignment in Question Answering...</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816001</td>
<td>0.701377</td>
<td><a href="https://www.semanticscholar.org/paper/8c4a62765385426bbdf2e41cb0cfbe2e291cf30e">8: Overview of the TREC 2016 LiveQA Track</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805352</td>
<td>0.942915</td>
<td><a href="https://www.semanticscholar.org/paper/238ced6e46b187b8a935b1ed3f9f0b14d29733a9">35: A Hybrid Question Answering System based on Information Retrieval and Answer Validation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801263</td>
<td>0.972460</td>
<td><a href="https://www.semanticscholar.org/paper/28d79fe5c22b2227f05fed9063534c3bdfdc80c6">1: Panel on Web-Based Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.797079</td>
<td>0.912116</td>
<td><a href="https://www.semanticscholar.org/paper/856af5c5e92f23e4e9dfb4660cf0ec19e908db8d">80: Overview of QA4MRE at CLEF 2011: Question Answering for Machine Reading Evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.434561</td>
<td>0.996699</td>
<td><a href="https://www.semanticscholar.org/paper/520028c1b1b6d47093d3e74ce35cd9c4fb4234d8">226: Overview of the TREC-9 Question Answering Track</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765654</td>
<td>0.995528</td>
<td><a href="https://www.semanticscholar.org/paper/f24e2d8df650e8c8b0bf61af8ce5aed83e476be4">111: Analyses for elucidating current question answering technology</a></td>
</tr>
<tr>
<td>0</td>
<td>0.668512</td>
<td>0.995483</td>
<td><a href="https://www.semanticscholar.org/paper/f4f274ed8b7ebab735e15ed98bb396e4979a1f9c">308: Question Answering in Webclopedia</a></td>
</tr>
<tr>
<td>0</td>
<td>0.725190</td>
<td>0.995075</td>
<td><a href="https://www.semanticscholar.org/paper/122ab8ab9a7661748ff8719c5f90df6ab279f738">183: High performance question/answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.660170</td>
<td>0.995039</td>
<td><a href="https://www.semanticscholar.org/paper/ae486b98c85d423d16679236f0dddd29f5c17675">233: IBM's Statistical Question Answering System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727135</td>
<td>0.995028</td>
<td><a href="https://www.semanticscholar.org/paper/c447d259ef71ef567f96faf406683a5d86a37084">110: SiteQ: Engineering High Performance QA System Using Lexico-Semantic Pattern Matching and Shallow NLP</a></td>
</tr>
<tr>
<td>0</td>
<td>0.886681</td>
<td>0.994522</td>
<td><a href="https://www.semanticscholar.org/paper/901e31635918310569ec0bddf23755154a6df829">107: Overview of the TREC 2006 Question Answering Track 99</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701898</td>
<td>0.994379</td>
<td><a href="https://www.semanticscholar.org/paper/e8f9537a6cfb1ba2501c1c6ac3b114c274534095">340: Web question answering: is more always better?</a></td>
</tr>
</table></html>
