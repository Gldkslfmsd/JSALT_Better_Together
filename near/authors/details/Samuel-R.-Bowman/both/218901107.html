<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/b1a71677a13299755a12375f0c982484088aa9ef">38: English Intermediate-Task Training Improves Zero-Shot Cross-Lingual Transfer Too</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812024</td>
<td>0.989003</td>
<td><a href="https://www.semanticscholar.org/paper/1bd735f3fdb89f6b5c4902caa645ce32f453bc00">21: Don't Use English Dev: On the Zero-Shot Cross-Lingual Evaluation of Contextual Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805299</td>
<td>0.957658</td>
<td><a href="https://www.semanticscholar.org/paper/9dc68f8362df16b2b7f17556a7728fe727055c6a">16: AmericasNLI: Evaluating Zero-shot Natural Language Understanding of Pretrained Multilingual Models in Truly Low-resource Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804414</td>
<td>0.977692</td>
<td><a href="https://www.semanticscholar.org/paper/e7a865ca5128c476c23de2e1a5505810d8085860">8: Exploring Fine-tuning Techniques for Pre-trained Cross-lingual Models via Continual Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801113</td>
<td>0.992856</td>
<td><a href="https://www.semanticscholar.org/paper/fb9ef188f4cffa8a790e10b5f3b94486d8048809">4: Studying Strategically: Learning to Mask for Closed-book QA</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800239</td>
<td>0.862970</td>
<td><a href="https://www.semanticscholar.org/paper/0027287f577e70b029203daaf9728e8f5fc33570">2: Soft Layer Selection with Meta-Learning for Zero-Shot Cross-Lingual Transfer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799111</td>
<td>0.927919</td>
<td><a href="https://www.semanticscholar.org/paper/19803adec3b97fb2e3c8097f17bf33fabf311795">27: Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792477</td>
<td>0.933200</td>
<td><a href="https://www.semanticscholar.org/paper/14147c2dd2de2a03870731bad996fa906061722c">1: Improving Word Translation via Two-Stage Contrastive Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.789714</td>
<td>0.812793</td>
<td><a href="https://www.semanticscholar.org/paper/90e01c837628a8398f15db608b1049d1beedbbe4">1: Cross-Lingual Transfer for Distantly Supervised and Low-resources Indonesian NER</a></td>
</tr>
<tr>
<td>1</td>
<td>0.785298</td>
<td>0.997099</td>
<td><a href="https://www.semanticscholar.org/paper/cbf98ebe967e0f3f3236e7932f37013b98244e94">22: ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.721601</td>
<td>0.998974</td>
<td><a href="https://www.semanticscholar.org/paper/965b05977be9177f6447cdfa5f0946b7622c9875">1: PAGnol: An Extra-Large French Generative Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674585</td>
<td>0.997865</td>
<td><a href="https://www.semanticscholar.org/paper/8c5694fb8de38d5538376c1b24e7564efa7731f4">0: Phylogeny-Inspired Adaptation of Multilingual Models to New Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752113</td>
<td>0.997526</td>
<td><a href="https://www.semanticscholar.org/paper/750274c61a0936c9c9db32da659cddbcb227cf32">27: MKQA: A Linguistically Diverse Benchmark for Multilingual Open Domain Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.755359</td>
<td>0.997422</td>
<td><a href="https://www.semanticscholar.org/paper/10efdde1ae3a9d359ac1aae0bd5ef7bfd68810dd">9: DICT-MLM: Improved Multilingual Pre-Training using Bilingual Dictionaries</a></td>
</tr>
<tr>
<td>0</td>
<td>0.642878</td>
<td>0.997047</td>
<td><a href="https://www.semanticscholar.org/paper/83d373dc961122d207de17bf78b359c04fa489bd">0: A N E XPLORATION OF V OCABULARY S IZE AND T RANSFER E FFECTS IN M ULTILINGUAL L ANGUAGE M ODELS FOR A FRICAN L ANGUAGES</a></td>
</tr>
<tr>
<td>0</td>
<td>0.750032</td>
<td>0.996743</td>
<td><a href="https://www.semanticscholar.org/paper/192534be208e99174ee83fccabf8457bb8bfb9c5">15: BARThez: a Skilled Pretrained French Sequence-to-Sequence Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.659547</td>
<td>0.996552</td>
<td><a href="https://www.semanticscholar.org/paper/8e8952e2d7440798275619d1a4716461f2bd8d76">0: Language Representation in Multilingual BERT and its applications to improve Cross-lingual Generalization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.647075</td>
<td>0.996478</td>
<td><a href="https://www.semanticscholar.org/paper/302face5b5a0944cab13665a2d4e07ef3aaf5240">68: AmbigQA: Answering Ambiguous Open-domain Questions</a></td>
</tr>
</table></html>
