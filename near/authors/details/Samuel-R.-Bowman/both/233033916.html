<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/a62bbc8ec3de4108a31b3fcc3403b659e7de5116">43: What Will it Take to Fix Benchmarking in Natural Language Understanding?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.819208</td>
<td>0.987876</td>
<td><a href="https://www.semanticscholar.org/paper/868966e2a7641c2305b2efe4d4b83d5ee44ab8bc">0: How Does Data Corruption Affect Natural Language Understanding Models? A Study on GLUE datasets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803122</td>
<td>0.949686</td>
<td><a href="https://www.semanticscholar.org/paper/497d29459a894ac38a48ed58753976ccbf2aa433">21: Intrinsic Bias Metrics Do Not Correlate with Application Bias</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800761</td>
<td>0.993008</td>
<td><a href="https://www.semanticscholar.org/paper/8eda3fd907afcbad277fa3e3bf7f23e3cbfbbc84">315: Adversarial NLI: A New Benchmark for Natural Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791727</td>
<td>0.990825</td>
<td><a href="https://www.semanticscholar.org/paper/9fec5868542b4d9070306f1418d1d21666226e90">66: Evaluating NLP Models via Contrast Sets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791161</td>
<td>-0.003767</td>
<td><a href="https://www.semanticscholar.org/paper/5f77157038dc7f189db7e72ea58567039222d9df">0: Examining Single Sentence Label Leakage in Natural Language Inference Datasets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784427</td>
<td>0.960213</td>
<td><a href="https://www.semanticscholar.org/paper/40e15fb91532bfbc3fa8f2a6c97f2a3b05287008">6: HardEval: Focusing on Challenging Tokens to Assess Robustness of NER</a></td>
</tr>
<tr>
<td>0</td>
<td>0.779455</td>
<td>0.965717</td>
<td><a href="https://www.semanticscholar.org/paper/9fcbaa38ea24193d78bbe461569cbcf572318c89">4: Bend but Donâ€™t Break? Multi-Challenge Stress Test for QA Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.778072</td>
<td>0.925342</td>
<td><a href="https://www.semanticscholar.org/paper/80e34f2b7f816113130c536dddd8aa980c95dfd2">8: Interpreting Predictions of NLP Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.775891</td>
<td>0.492630</td>
<td><a href="https://www.semanticscholar.org/paper/b7e5e316ebc2499a2364b6b79c5243f806c8b1f9">44: Improving the Reliability of Deep Neural Networks in NLP: A Review</a></td>
</tr>
<tr>
<td>0</td>
<td>0.644376</td>
<td>0.997717</td>
<td><a href="https://www.semanticscholar.org/paper/d25bb256e5b69f769a429750217b0d9ec1cf4d86">15: Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800294</td>
<td>0.997088</td>
<td><a href="https://www.semanticscholar.org/paper/693cce5d9764f9e9e0c9c583bf840ac019e2179f">50: Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.776389</td>
<td>0.997057</td>
<td><a href="https://www.semanticscholar.org/paper/c5e4eafd85949e6aac9d8e98d5e03b2acf444046">10: On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study</a></td>
</tr>
<tr>
<td>0</td>
<td>0.754234</td>
<td>0.996415</td>
<td><a href="https://www.semanticscholar.org/paper/1a21ed83b4c06d96db34e35df8b2db24fbdc4c26">4: Mitigating harm in language models with conditional-likelihood filtration</a></td>
</tr>
<tr>
<td>0</td>
<td>0.646766</td>
<td>0.996355</td>
<td><a href="https://www.semanticscholar.org/paper/1adadbfa95e43a70fcd17e6ce947a0652b86bfc3">25: Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767690</td>
<td>0.996182</td>
<td><a href="https://www.semanticscholar.org/paper/805af32422768436b5e3d9a4dea1f8b0811280e7">6: Analyzing Dynamic Adversarial Training Data in the Limit</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804843</td>
<td>0.996165</td>
<td><a href="https://www.semanticscholar.org/paper/d65a064eb837f838faf6ff67781b62450b92b159">13: CommonsenseQA 2.0: Exposing the Limits of AI through Gamification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.741666</td>
<td>0.996000</td>
<td><a href="https://www.semanticscholar.org/paper/5a6f6f44a2e05709d81245526786f8dc8f8ab263">0: Relation Leakage in Elicited Natural Language Inference Datasets</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.995892</td>
<td><a href="https://www.semanticscholar.org/paper/d0960dab84785ad826cb6a2bafb087d7f9347c5d">19: Trick Me If You Can: Human-in-the-loop Generation of Adversarial Question Answering Examples</a></td>
</tr>
</table></html>
