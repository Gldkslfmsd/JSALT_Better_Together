<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/ab70d071223476265d7b077f290c6133a96ef677">25: Towards Realistic Practices In Low-Resource Natural Language Processing: The Development Set</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803092</td>
<td>0.881927</td>
<td><a href="https://www.semanticscholar.org/paper/b2474a00d7de3373bab934c09acef1994fa82207">13: Small Data? No Problem! Exploring the Viability of Pretrained Multilingual Language Models for Low-resourced Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800496</td>
<td>0.932186</td>
<td><a href="https://www.semanticscholar.org/paper/5e8180e2ceddaab161e9be55bd81d8f911967302">0: Model Selection for Cross-lingual Transfer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799633</td>
<td>0.966316</td>
<td><a href="https://www.semanticscholar.org/paper/04748a086d709d7c15cf9704efd75df09cfff44e">5: An Exploratory Study on Multilingual Quality Estimation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795286</td>
<td>0.533452</td>
<td><a href="https://www.semanticscholar.org/paper/27c15021fa3a13407fb2425bbf59ca77f7933b3e">36: Creating language resources for under-resourced languages: methodologies, and experiments with Arabic</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792649</td>
<td>0.864135</td>
<td><a href="https://www.semanticscholar.org/paper/07f27adafa381c4105deb2a02f8a80f74fa705b8">22: Neural machine translation for low-resource languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.789250</td>
<td>0.766199</td>
<td><a href="https://www.semanticscholar.org/paper/47218a6934cd785612774f9772e39fcfdcd6b971">0: Domain Adaptation for Sparse-Data Settings: What Do We Gain by Not Using Bert?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.789123</td>
<td>0.961985</td>
<td><a href="https://www.semanticscholar.org/paper/48925fef94500cf19ee220ed74217816f1ab5e60">536: Phrase-Based & Neural Unsupervised Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785779</td>
<td>0.871978</td>
<td><a href="https://www.semanticscholar.org/paper/31682ab9ee03f9086467c2bfc329c938095553cf">0: Using Transfer Learning to Automatically Mark L2 Writing Texts</a></td>
</tr>
<tr>
<td>0</td>
<td>0.783967</td>
<td>0.000265</td>
<td>NA:247975147</td>
</tr>
<tr>
<td>0</td>
<td>0.724083</td>
<td>0.985468</td>
<td><a href="https://www.semanticscholar.org/paper/ebd93312743ddbc8f01394f7b03f8313e673ff5e">3: Meta Learning to Classify Intent and Slot Labels with Noisy Few Shot Examples</a></td>
</tr>
<tr>
<td>0</td>
<td>0.707505</td>
<td>0.983961</td>
<td><a href="https://www.semanticscholar.org/paper/638ac2f2188bf71d82a1d13bdbeba1b5a72d1a47">31: Multi-lingual Intent Detection and Slot Filling in a Joint BERT-based Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.688940</td>
<td>0.983300</td>
<td><a href="https://www.semanticscholar.org/paper/7495f9a7f17a2fb63b7776650efe453405aa8933">15: Hierarchical Pre-training for Sequence Labelling in Spoken Dialog</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742176</td>
<td>0.983119</td>
<td><a href="https://www.semanticscholar.org/paper/7cdb46dd8ba4440a8e3859a001fd38da93fbba4a">12: Language Modeling Teaches You More than Translation Does : Lessons Learned Through Auxiliary Task Analysis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.678755</td>
<td>0.982747</td>
<td><a href="https://www.semanticscholar.org/paper/a1e79bc3717486b311488bc67b319b3f6a44da14">53: Self-Training for Jointly Learning to Ask and Answer Questions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.724440</td>
<td>0.982482</td>
<td><a href="https://www.semanticscholar.org/paper/3012f85c312412a6ac665cb1cc5180ad194332c8">30: Multi-Task Self-Supervised Learning for Disfluency Detection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737226</td>
<td>0.982227</td>
<td><a href="https://www.semanticscholar.org/paper/c33f0885e2e51cf12adc08e21a4d948e52f51fad">15: Multi-Head Multi-Layer Attention to Deep Language Representations for Grammatical Error Detection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691974</td>
<td>0.981725</td>
<td><a href="https://www.semanticscholar.org/paper/1f3e14c58d86b44fcc931cd0bdc0a8dfc7500701">6: Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue Response Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.667211</td>
<td>0.981642</td>
<td><a href="https://www.semanticscholar.org/paper/850232f59e25fc9a37ba72f0738126503c4040bb">4: Zero-Shot Cross-lingual Semantic Parsing</a></td>
</tr>
</table></html>
