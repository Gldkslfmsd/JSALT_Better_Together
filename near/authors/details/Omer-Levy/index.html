<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Query</th>
</tr>
<tr>
<td><a href="both/198953378.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/077f8329a7b6fa3b7c877a57b81eb6c18b5f87de">6919: RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></td>
</tr>
<tr>
<td><a href="both/204960716.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/395de0bd3837fdf4b4b5e5f04835bcc69c279481">2258: BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></td>
</tr>
<tr>
<td><a href="both/5034059.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/93b8da28d006415866bf48f9a6e06b5242129195">2544: GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</a></td>
</tr>
<tr>
<td><a href="both/1190093.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/f4c018bcc8ea707b83247866bdc8ccb87cd9f5da">1561: Neural Word Embedding as Implicit Matrix Factorization</a></td>
</tr>
<tr>
<td><a href="both/12890187.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/2012f32199adc88747d5a1b47c7b4ba1cb3cb995">1184: word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method</a></td>
</tr>
<tr>
<td><a href="both/5159281.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/6aa3d8bcca2ebdc52ef7cd786204c338f9d609f2">1171: Improving Distributional Similarity with Lessons Learned from Word Embeddings</a></td>
</tr>
<tr>
<td><a href="both/198229624.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/81f5810fbbab9b7203b9556f4ce3c741875407bc">854: SpanBERT: Improving Pre-training by Representing and Predicting Spans</a></td>
</tr>
<tr>
<td><a href="both/143424870.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/d9f6ada77448664b71128bb19df15765336974a6">797: SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems</a></td>
</tr>
<tr>
<td><a href="both/184486746.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/95a251513853c6032bdecebd4b74e15795662986">736: What Does BERT Look at? An Analysis of BERTâ€™s Attention</a></td>
</tr>
<tr>
<td><a href="both/2107337.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/0183b3e9d84c15c7048e6c2149ed86257ccdc6cb">824: Dependency-Based Word Embeddings</a></td>
</tr>
<tr>
<td><a href="both/4537113.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/2997b26ffb8c291ce478bd8a6e47979d5a55c466">662: Annotation Artifacts in Natural Language Inference Data</a></td>
</tr>
<tr>
<td><a href="both/4710028.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/73bade9162bc4df6ca6c9ab8a7eb2d54d35acad2">539: code2vec: learning distributed representations of code</a></td>
</tr>
<tr>
<td><a href="both/12730203.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/500d570ce02abf42bc1bc535620741d4c5665e6a">625: Linguistic Regularities in Sparse and Explicit Word Representations</a></td>
</tr>
<tr>
<td><a href="both/166227946.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/b03c7ff961822183bab66b2e594415e585d3fd09">390: Are Sixteen Heads Really Better than One?</a></td>
</tr>
<tr>
<td><a href="both/51926976.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/98d1307bed619b58b4a44acd8e65ac58495776c2">341: code2seq: Generating Sequences from Structured Representations of Code</a></td>
</tr>
<tr>
<td><a href="both/793385.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/fa025e5d117929361bcf798437957762eb5bb6d4">324: Zero-Shot Relation Extraction via Reading Comprehension</a></td>
</tr>
<tr>
<td><a href="both/202538740.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/5efadc9019ce3378a0eb6c8f939cdde6c8918b1e">244: Mask-Predict: Parallel Decoding of Conditional Masked Language Models</a></td>
</tr>
<tr>
<td><a href="both/207870430.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/bb6317bbd2c4a81e94cf3d7eb1b73da246a022db">169: Generalization through Memorization: Nearest Neighbor Language Models</a></td>
</tr>
<tr>
<td><a href="both/201646551.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/127ffe6d21b75bd41dd808e3313bc392b9428346">174: BERT for Coreference Resolution: Baselines and Analysis</a></td>
</tr>
<tr>
<td><a href="both/747342.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/51c49cc4654dbce3c3de2919800da1e7477d88b3">215: Do Supervised Distributional Methods Really Learn Lexical Inference Relations?</a></td>
</tr>
<tr>
<td><a href="both/NA:249538544.html">both</a></td>
<td></td>
</tr>
<tr>
<td><a href="both/4383884.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/02b92dcc30865950517894d8adafd3bd4474b018">136: A general path-based representation for predicting program properties</a></td>
</tr>
<tr>
<td><a href="both/44152851.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/7442a18a55f257a68f21d0cbb8b1395f8915a452">151: Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling</a></td>
</tr>
<tr>
<td><a href="both/219315567.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/04ef54bd467d5e03dee7b0be601cf06d420bffa0">102: Emergent linguistic structure in artificial neural networks trained by self-supervision</a></td>
</tr>
<tr>
<td><a href="both/51540074.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/bcd857d75841aa3e92cd4284a8818aba9f6c0c3f">156: Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS</a></td>
</tr>
<tr>
<td><a href="both/49212016.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/4157834ed2d2fea6b6f652a72a9d0487edbc9f57">113: Ultra-Fine Entity Typing</a></td>
</tr>
<tr>
<td><a href="both/207847640.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/2cf3bd0cc1382f35384e259d99e4f9744eeaed28">83: Blockwise Self-Attention for Long Document Understanding</a></td>
</tr>
<tr>
<td><a href="both/2897037.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/7fead81d3655f52a221ef8738216ab8826019897">102: A Simple Word Embedding Model for Lexical Substitution</a></td>
</tr>
<tr>
<td><a href="both/21663989.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/efef34c1caef102ad5cc052642d75beaaf5adcaf">82: Deep RNNs Encode Soft Hierarchical Syntax</a></td>
</tr>
<tr>
<td><a href="both/31816657.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/26953cc3d09920b54071b73866f85d6bb1a6184c">78: Simulating Action Dynamics with Neural Process Networks</a></td>
</tr>
<tr>
<td><a href="both/59604474.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/0b9ac1035918823ffca1c6f55ec316b42d4e033f">65: Training on Synthetic Noise Improves Robustness to Natural Noise in Machine Translation</a></td>
</tr>
<tr>
<td><a href="both/229923720.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/4a54d58a4b20e4f3af25cea3c188a12082a95e02">32: Transformer Feed-Forward Layers Are Key-Value Memories</a></td>
</tr>
<tr>
<td><a href="both/214795061.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/3f11a2124af139af7c6f17eccab5149d759d7f52">51: Aligned Cross Entropy for Non-Autoregressive Machine Translation</a></td>
</tr>
<tr>
<td><a href="both/11525632.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/2e2577b1eb44340dcd420b88b30f2775be8634a5">62: Named Entity Disambiguation for Noisy Text</a></td>
</tr>
<tr>
<td><a href="both/17708014.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/a53815cf0c9cbb54a23b11f73c7d532910afa750">67: The Excitement Open Platform for Textual Inferences</a></td>
</tr>
<tr>
<td><a href="both/211066355.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/db392858262b17aa9c8ff8659738f68fbf832ebe">46: Structural Language Models of Code</a></td>
</tr>
<tr>
<td><a href="both/16479424.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/0e91275210db9fe154139930af2c0f42878771bb">57: A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments</a></td>
</tr>
<tr>
<td><a href="both/247316687.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/b4206dd288958affeb314aee0ec1397de5c74c23">3: Shared computational principles for language processing in humans and deep language models</a></td>
</tr>
<tr>
<td><a href="both/207853045.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/3ff8d265f4351e4b1fdac5b586466bee0b5d6fff">37: Improving Transformer Models by Reordering their Sublayers</a></td>
</tr>
<tr>
<td><a href="both/230433978.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/06047017f7a2b4dee6d8078786a21c8f67590a22">32: Few-Shot Question Answering by Pretraining Span Selection</a></td>
</tr>
<tr>
<td><a href="both/210911571.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/7b28577ed96bd1b76bbe79859b3222604b2dc369">40: Semi-Autoregressive Training Improves Mask-Predict Decoding</a></td>
</tr>
<tr>
<td><a href="both/53046959.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/5f6a87289ef0977073e49aa4460f6018de89e14c">41: pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence Inference</a></td>
</tr>
<tr>
<td><a href="both/7149590.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/8cef20c98d41018c44c78772424112c5b5679144">44: Focused Entailment Graphs for Open IE Propositions</a></td>
</tr>
<tr>
<td><a href="both/225062157.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/ecb2b0859bab2761be397804516b8de3983366e8">24: The Turking Test: Can Language Models Understand Instructions?</a></td>
</tr>
<tr>
<td><a href="both/233289750.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/7694aae9766d5f1fe74d900cd82aee898cb6e8e9">11: How to Train BERT with an Academic Budget</a></td>
</tr>
<tr>
<td><a href="both/230435783.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/3029263ca51e6c2907f9f99277083cf6afb1adb7">12: Coreference Resolution without Span Representations</a></td>
</tr>
<tr>
<td><a href="both/18966761.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/4f866ba2fff36a055bff201ac35f7629c8251b50">32: Recognizing Partial Textual Entailment</a></td>
</tr>
<tr>
<td><a href="both/5779308.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/ecaf00a0464ef619890e46962b17ce838f3587d0">29: Recurrent Additive Networks</a></td>
</tr>
<tr>
<td><a href="both/127955230.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/1a98ce71556e4602b313d424b3d689e026ca4706">32: Constant-Time Machine Translation with Conditional Masked Language Models</a></td>
</tr>
<tr>
<td><a href="both/245144844.html">both</a></td>
<td><a href="https://www.semanticscholar.org/paper/aaea853381050b4456d0d8e2e4b0c282391e41dc">6: Learning to Retrieve Passages without Supervision</a></td>
</tr>
</table></html>
