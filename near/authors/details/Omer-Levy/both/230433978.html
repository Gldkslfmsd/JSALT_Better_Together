<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/06047017f7a2b4dee6d8078786a21c8f67590a22">32: Few-Shot Question Answering by Pretraining Span Selection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.836134</td>
<td>0.984154</td>
<td><a href="https://www.semanticscholar.org/paper/c435fdeff9d3b30c3bece24429123d23da147992">4: RECONSIDER: Improved Re-Ranking using Span-Focused Cross-Attention for Open Domain Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.833256</td>
<td>0.984563</td>
<td><a href="https://www.semanticscholar.org/paper/db95ba221305a3aa2ec8bbc78de0f42485c63c12">30: Generalizing Question Answering System with Pre-trained Language Model Fine-tuning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830408</td>
<td>0.989459</td>
<td><a href="https://www.semanticscholar.org/paper/0cf535110808d33fdf4db3ffa1621dea16e29c0d">107: Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825239</td>
<td>0.871026</td>
<td><a href="https://www.semanticscholar.org/paper/354ec86839539390a148ed41054eb68e0b8caa85">8: BERTSel: Answer Selection with Pre-trained Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.808907</td>
<td>0.995375</td>
<td><a href="https://www.semanticscholar.org/paper/a5584d2d9b0de9e1692241d46d0c70942919cd60">0: Answer-level Calibration for Free-form Multiple Choice Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.808709</td>
<td>0.837287</td>
<td><a href="https://www.semanticscholar.org/paper/deb3abca05151e477971f6340e761cf80d0a7fd6">0: CS224n Final Project: SQuAD 2.0 with BERT</a></td>
</tr>
<tr>
<td>0</td>
<td>0.808231</td>
<td>0.667500</td>
<td><a href="https://www.semanticscholar.org/paper/78ca8ed2c9fc1c2865c6020ee6da1f655462fd1c">3: A Language Prior Based Focal Loss for Visual Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806483</td>
<td>0.970467</td>
<td><a href="https://www.semanticscholar.org/paper/d0af89ae70c723f78ddcca04df299933e1396c7e">0: Robust Question-Answering with Data Augmentation and Self-Supervised Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806020</td>
<td>0.932299</td>
<td><a href="https://www.semanticscholar.org/paper/8c3a05b80ddc2c3acbf6a5900871c484db3db96d">0: How State-Of-The-Art Models Can Deal With Long-Form Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.703404</td>
<td>0.998496</td>
<td><a href="https://www.semanticscholar.org/paper/e6f94081276a7a5e6aef34a080cb3d3a4b1b9c20">3: Rethinking Why Intermediate-Task Fine-Tuning Works</a></td>
</tr>
<tr>
<td>0</td>
<td>0.690342</td>
<td>0.998461</td>
<td><a href="https://www.semanticscholar.org/paper/a4e22f986a59488e5658116aa818594caa100551">7: Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval</a></td>
</tr>
<tr>
<td>0</td>
<td>0.616428</td>
<td>0.998450</td>
<td><a href="https://www.semanticscholar.org/paper/2fb0c1b3fe91203ca3c8c80bd314671cf6c48ace">0: Evaluation of Intermediate Pre-training for the Detection of Offensive Language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705480</td>
<td>0.998325</td>
<td><a href="https://www.semanticscholar.org/paper/ed0b09e170b960a84a4cd88a1a9031b7e234a4de">0: Go Beyond Plain Fine-Tuning: Improving Pretrained Models for Social Commonsense</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820409</td>
<td>0.998165</td>
<td><a href="https://www.semanticscholar.org/paper/cb58542c94ce83b09f5d3809e69518ba52709c92">86: Question and Answer Test-Train Overlap in Open-Domain Question Answering Datasets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795371</td>
<td>0.998121</td>
<td><a href="https://www.semanticscholar.org/paper/6fc4a39bb4697a21286bb1cf503ecf17407aeae2">1: An Empirical Study on Few-shot Knowledge Probing for Pretrained Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.761602</td>
<td>0.998048</td>
<td><a href="https://www.semanticscholar.org/paper/5aec43e6d48c1b187778ee3beb6e8e3d41267077">3: CCQA: A New Web-Scale Question Answering Dataset for Model Pre-Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791315</td>
<td>0.997831</td>
<td><a href="https://www.semanticscholar.org/paper/c132c485fe164f54dc8bdbe9a228500174badd5e">24: Domain-matched Pre-training Tasks for Dense Retrieval</a></td>
</tr>
<tr>
<td>0</td>
<td>0.776785</td>
<td>0.997735</td>
<td><a href="https://www.semanticscholar.org/paper/bde0c85ed3d61de2a8874ddad70497b3d68bc8ad">178: Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering</a></td>
</tr>
</table></html>
