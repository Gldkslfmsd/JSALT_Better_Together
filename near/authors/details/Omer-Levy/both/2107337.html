<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/0183b3e9d84c15c7048e6c2149ed86257ccdc6cb">824: Dependency-Based Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829605</td>
<td>0.983138</td>
<td><a href="https://www.semanticscholar.org/paper/26c9e9eac8b794bb6a2b9574fdf2c1405d5c0cac">89: Learning Context-Sensitive Word Embeddings with Neural Tensor Skip-Gram Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.828164</td>
<td>0.970645</td>
<td><a href="https://www.semanticscholar.org/paper/84849edea0f03c02f152faada63e602e64739531">22: Context Representation with Word Embeddings for WSD</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823410</td>
<td>0.982329</td>
<td><a href="https://www.semanticscholar.org/paper/1ba89d99a0e8075a4a69ae03e05835fb5a9ca925">12: Different Contexts Lead to Different Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823003</td>
<td>0.980400</td>
<td><a href="https://www.semanticscholar.org/paper/275a6dd72ca2dbeb81150b634ea967fc6e7bbb94">85: A Word Embedding Approach to Predicting the Compositionality of Multiword Expressions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820171</td>
<td>0.982431</td>
<td><a href="https://www.semanticscholar.org/paper/ba9769758c577ad3474785e070156365c2ede09e">93: Factors Influencing the Surprising Instability of Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816356</td>
<td>0.896936</td>
<td><a href="https://www.semanticscholar.org/paper/d44fdde76605fddd1c411f4aa13126b65cd98bb5">86: Dynamic Meta-Embeddings for Improved Sentence Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813957</td>
<td>0.910865</td>
<td><a href="https://www.semanticscholar.org/paper/7561db6ffcb837e6133104ca6d0478416e776ff8">0: Incremental Sense Weight Training for In-Depth Interpretation of Contextualized Word Embeddings (Student Abstract)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812950</td>
<td>0.921421</td>
<td><a href="https://www.semanticscholar.org/paper/34a88cf6dc32ed7d1fdebe282461ebb5c6288ac5">1: Syntree2Vec - An algorithm to augment syntactic hierarchy into word embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812207</td>
<td>0.980230</td>
<td><a href="https://www.semanticscholar.org/paper/309c5b65760919f3086af0d9e2c492c4b3e6b896">117: Making Sense of Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.684388</td>
<td>0.997239</td>
<td><a href="https://www.semanticscholar.org/paper/c4fd9c86b2b41df51a6fe212406dda81b1997fd4">3019: Linguistic Regularities in Continuous Space Word Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.817794</td>
<td>0.996323</td>
<td><a href="https://www.semanticscholar.org/paper/c8dfdb6bc17094fc1c35757a0020dea8d813b7b6">288: Improving Lexical Embeddings with Semantic Knowledge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.713239</td>
<td>0.996106</td>
<td><a href="https://www.semanticscholar.org/paper/500d570ce02abf42bc1bc535620741d4c5665e6a">625: Linguistic Regularities in Sparse and Explicit Word Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774815</td>
<td>0.996080</td>
<td><a href="https://www.semanticscholar.org/paper/a41b880cdd9646578ab13e6e0b5356a0c4370811">462: Evaluation methods for unsupervised word embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.647079</td>
<td>0.995991</td>
<td><a href="https://www.semanticscholar.org/paper/7926dc0a05b9478194e876ada4260b8c04821338">74: Word Representations in Vector Space and their Applications for Arabic</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793808</td>
<td>0.995794</td>
<td><a href="https://www.semanticscholar.org/paper/cf9830bf8d2babc3c32d192cdccb27aeaf46a048">106: The Role of Context Types and Dimensionality in Learning Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738181</td>
<td>0.995505</td>
<td><a href="https://www.semanticscholar.org/paper/e9fad5d68cefe975c1bf56695c61c816be7d3136">126: Learning Semantic Word Embeddings based on Ordinal Knowledge Constraints</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738548</td>
<td>0.995064</td>
<td><a href="https://www.semanticscholar.org/paper/a9f6b9fb8bfeb25c9833d68944f6d33d0ec8c4b7">127: Revisiting Embedding Features for Simple Semi-supervised Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767752</td>
<td>0.994978</td>
<td><a href="https://www.semanticscholar.org/paper/47291646a01c8786abd1b168cb78e6af575f9318">278: AutoExtend: Extending Word Embeddings to Embeddings for Synsets and Lexemes</a></td>
</tr>
</table></html>
