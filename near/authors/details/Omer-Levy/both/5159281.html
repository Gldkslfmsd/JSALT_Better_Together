<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/6aa3d8bcca2ebdc52ef7cd786204c338f9d609f2">1171: Improving Distributional Similarity with Lessons Learned from Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.832183</td>
<td>0.921052</td>
<td><a href="https://www.semanticscholar.org/paper/d75c36ce468396f3bf78775ac525bf0b1a48bf2e">1: Challenges and Solutions with Alignment and Enrichment of Word Embedding Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831433</td>
<td>0.944470</td>
<td><a href="https://www.semanticscholar.org/paper/b7ec73da32f5552f1cb5725f814efb9d586ded36">20: Better Word Embeddings by Disentangling Contextual n-Gram Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825386</td>
<td>0.921795</td>
<td><a href="https://www.semanticscholar.org/paper/1b637f4e626f38aaf4e560947500b910a21f9a13">9: Wan2vec: Embeddings learned on word association norms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818064</td>
<td>0.003156</td>
<td><a href="https://www.semanticscholar.org/paper/0f72134af490072ff2a34d7917dbc410661d3ff1">0: A Simple Fully Connected Network for Composing Word Embeddings from Characters</a></td>
</tr>
<tr>
<td>0</td>
<td>0.814209</td>
<td>0.862638</td>
<td><a href="https://www.semanticscholar.org/paper/7a3646407dd0f411db7ec75c2a286d2b34976248">2: Investigating Different Context Types and Representations for Learning Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809565</td>
<td>0.974841</td>
<td><a href="https://www.semanticscholar.org/paper/275a6dd72ca2dbeb81150b634ea967fc6e7bbb94">85: A Word Embedding Approach to Predicting the Compositionality of Multiword Expressions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809463</td>
<td>0.946004</td>
<td><a href="https://www.semanticscholar.org/paper/85de75a77c7bbf091f9315e88fcee7c32e5b399c">12: Semantic Information Extraction for Improved Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800899</td>
<td>0.948540</td>
<td><a href="https://www.semanticscholar.org/paper/638a7d74ea0d76440db2c6bf4c59fc8ce31f29c0">28: Revisiting Correlations between Intrinsic and Extrinsic Evaluations of Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800724</td>
<td>0.925806</td>
<td><a href="https://www.semanticscholar.org/paper/cefe1e8659ac629d0e80f35e87921c5ea27c8056">2: Addressing Low-Resource Scenarios with Character-aware Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795057</td>
<td>0.998667</td>
<td><a href="https://www.semanticscholar.org/paper/500d570ce02abf42bc1bc535620741d4c5665e6a">625: Linguistic Regularities in Sparse and Explicit Word Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792318</td>
<td>0.996772</td>
<td><a href="https://www.semanticscholar.org/paper/a41b880cdd9646578ab13e6e0b5356a0c4370811">462: Evaluation methods for unsupervised word embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.757423</td>
<td>0.996366</td>
<td><a href="https://www.semanticscholar.org/paper/3cfbb77e5a0e24772cfdb2eb3d4f35dead54b118">1303: Donâ€™t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.827684</td>
<td>0.995867</td>
<td><a href="https://www.semanticscholar.org/paper/34e1c23ccf3bbff0199c39c6c845cce866a91f78">17: Predicting Word Embeddings Variability</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772069</td>
<td>0.995266</td>
<td><a href="https://www.semanticscholar.org/paper/6a9b5bcafc5e88d731f644cf7ea59547df20495a">44: Online Learning of Interpretable Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.755239</td>
<td>0.995149</td>
<td><a href="https://www.semanticscholar.org/paper/808a225d7a943041612411b23c0b68f63b89a437">95: Word Embedding-based Antonym Detection using Thesauri and Distributional Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.835391</td>
<td>0.994822</td>
<td><a href="https://www.semanticscholar.org/paper/0183b3e9d84c15c7048e6c2149ed86257ccdc6cb">824: Dependency-Based Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727542</td>
<td>0.994459</td>
<td><a href="https://www.semanticscholar.org/paper/b1061b980da1b5bc32f317f66ed2baf69257401c">3: Determining Domain-Specific Differences of Polysemous Words Using Context Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.708826</td>
<td>0.993872</td>
<td><a href="https://www.semanticscholar.org/paper/6cca04a2ddc6d2a98e519b43cab8dfacf870b427">89: Adapting word2vec to Named Entity Recognition</a></td>
</tr>
</table></html>
