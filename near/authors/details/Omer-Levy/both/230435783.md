<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/3029263ca51e6c2907f9f99277083cf6afb1adb7">12: Coreference Resolution without Span Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.857306</td>
<td>0.940665</td>
<td><a href="https://www.semanticscholar.org/paper/8ae1af4a424f5e464d46903bc3d18fe1cf1434ff">589: End-to-end Neural Coreference Resolution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.851291</td>
<td>0.981750</td>
<td><a href="https://www.semanticscholar.org/paper/52bac58192c806f7fd8dea804b457b7a06f293fe">14: Incremental Neural Coreference Resolution in Constant Memory</a></td>
</tr>
<tr>
<td>0</td>
<td>0.840483</td>
<td>-0.016453</td>
<td><a href="https://www.semanticscholar.org/paper/b7811ba5831d64c654b2a1b6fa14ac2ac3ffe0ae">0: Chinese Coreference Resolution via Bidirectional LSTMs using Word and Token Level Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802219</td>
<td>0.747586</td>
<td><a href="https://www.semanticscholar.org/paper/c5db886ea95aa06b83e78bbb1e7cdd0e3f580cd5">4: The Hard-CoRe Coreference Corpus: Removing Gender and Number Cues for Difficult Pronominal Anaphora Resolution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784284</td>
<td>0.938089</td>
<td><a href="https://www.semanticscholar.org/paper/25ecc4cce21ec05093664b63a0189a4685ded316">1: Integrating Task Specific Information into Pretrained Language Models for Low Resource Fine Tuning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782666</td>
<td>0.669548</td>
<td><a href="https://www.semanticscholar.org/paper/bc0a618cc570551a13b337804c49a86e339add43">11: A Tree-to-Sequence Model for Neural NLG in Task-Oriented Dialog</a></td>
</tr>
<tr>
<td>0</td>
<td>0.779378</td>
<td>0.739665</td>
<td><a href="https://www.semanticscholar.org/paper/b5502e49ad932c5de90ef666a84b7016e4ce199a">9: Neural Coreference Resolution with Limited Lexical Context and Explicit Mention Detection for Oral French</a></td>
</tr>
<tr>
<td>0</td>
<td>0.777862</td>
<td>0.564363</td>
<td><a href="https://www.semanticscholar.org/paper/6541e569a8b5ea40c24ec27bcc18218928fe9e45">2: A Deep Context-wise Method for Coreference Detection in Natural Language Requirements</a></td>
</tr>
<tr>
<td>0</td>
<td>0.775721</td>
<td>0.593085</td>
<td><a href="https://www.semanticscholar.org/paper/957fa0f56dbe644e10ce82195a4115387c10941d">4: CORBON 2017 Shared Task: Projection-Based Coreference Resolution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.721071</td>
<td>0.997468</td>
<td><a href="https://www.semanticscholar.org/paper/38a142d34ebfcf5bacc1a8742771ce477a177ae4">5: Answer Sentence Selection Using Local and Global Context in Transformer Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.676622</td>
<td>0.997311</td>
<td><a href="https://www.semanticscholar.org/paper/0cf535110808d33fdf4db3ffa1621dea16e29c0d">107: Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736745</td>
<td>0.997273</td>
<td><a href="https://www.semanticscholar.org/paper/634e8fbeba53d45828846dd541ce0a0078c57b68">12: Syntax-Enhanced Pre-trained Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.744693</td>
<td>0.997222</td>
<td><a href="https://www.semanticscholar.org/paper/c4b95abe16439fddd1db33e9aa386bec8a667e39">2: mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.628906</td>
<td>0.997079</td>
<td><a href="https://www.semanticscholar.org/paper/11adf5397466ecbec178f01ef644143d43138d09">16: Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text</a></td>
</tr>
<tr>
<td>0</td>
<td>0.678507</td>
<td>0.997037</td>
<td><a href="https://www.semanticscholar.org/paper/4ae2960d3c6ac489b3b072666fb0b91d0480a170">97: A Span-Extraction Dataset for Chinese Machine Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772978</td>
<td>0.996990</td>
<td><a href="https://www.semanticscholar.org/paper/86ea4ec36431c0ac888b30002bdf088c41a19fd2">2: SILT: Efficient transformer training for inter-lingual inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.629881</td>
<td>0.996744</td>
<td><a href="https://www.semanticscholar.org/paper/1715aa36ccc851310308630d4db61dcecf49a50d">56: Knowledge Guided Text Retrieval and Reading for Open Domain Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.671979</td>
<td>0.996435</td>
<td><a href="https://www.semanticscholar.org/paper/d1eb4dfe24dd4009f6cb53bc089e3f43ee4678e2">6: On the Evaluation of Contextual Embeddings for Zero-Shot Cross-Lingual Transfer Learning</a></td>
</tr>
</table></html>
