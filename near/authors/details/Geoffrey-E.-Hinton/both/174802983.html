<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/f8de25118af2abc4c48afb947d6ec298e05ef1e5">611: When Does Label Smoothing Help?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.864712</td>
<td>0.929547</td>
<td><a href="https://www.semanticscholar.org/paper/38c4cb182910e1e4be0a401c0da23c173cef7a0e">0: To Smooth or Not? When Label Smoothing Meets Noisy Labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.862025</td>
<td>0.929793</td>
<td><a href="https://www.semanticscholar.org/paper/563f36269489f187e0dfe40e4794cb02125d59e1">5: Understanding (Generalized) Label Smoothing when Learning with Noisy Labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.815262</td>
<td>0.911322</td>
<td><a href="https://www.semanticscholar.org/paper/77e3c48aa10535276e7f570a3af594ba63de7d65">655: Training Deep Neural Networks on Noisy Labels with Bootstrapping</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807562</td>
<td>0.618556</td>
<td><a href="https://www.semanticscholar.org/paper/1bf011a0a5c471d98c26134a2e67d573b8601c8f">1: Transfer of Pretrained Model Weights Substantially Improves Semi-supervised Image Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799487</td>
<td>0.912976</td>
<td><a href="https://www.semanticscholar.org/paper/568675640f381fbc13998015c2854298877b7aa0">251: How does Disagreement Help Generalization against Label Corruption?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798423</td>
<td>0.060003</td>
<td>NA:231925665</td>
</tr>
<tr>
<td>0</td>
<td>0.795552</td>
<td>0.406444</td>
<td><a href="https://www.semanticscholar.org/paper/8e71988fbf01df00e69a0734c721a990817a9c10">2: Exploiting Context for Robustness to Label Noise in Active Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.783772</td>
<td>0.939225</td>
<td><a href="https://www.semanticscholar.org/paper/4f48c8653cd38cd18f08924c9304bc02ed7ea492">361: Learning from Noisy Labels with Distillation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.783078</td>
<td>0.782952</td>
<td><a href="https://www.semanticscholar.org/paper/eadb933f331696b5fe26a875a3868d95f5bf8ede">2: Weakly Supervised Representation Learning with Coarse Labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.726792</td>
<td>0.987472</td>
<td><a href="https://www.semanticscholar.org/paper/2444be7584d1f5a7e2aa9f65078de09154f14ea1">500: Born Again Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766573</td>
<td>0.974295</td>
<td><a href="https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19">8429: Distilling the Knowledge in a Neural Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.739611</td>
<td>0.971297</td>
<td><a href="https://www.semanticscholar.org/paper/2bdfc6d8f6d03b38b80b8aa4112088323b6b552f">27: Self-Distillation as Instance-Specific Label Smoothing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.698756</td>
<td>0.968381</td>
<td><a href="https://www.semanticscholar.org/paper/5baa3e00d66bc42db7e3908f0b70875cff9d0193">105: What is being transferred in transfer learning?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.672515</td>
<td>0.966212</td>
<td><a href="https://www.semanticscholar.org/paper/99716c3a0bcd2f587e3605f09888dcdcd3b4076e">51: Understanding and Improving Knowledge Distillation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.648297</td>
<td>0.963176</td>
<td><a href="https://www.semanticscholar.org/paper/1e3d18beaf3921f561e1b999780f29f2b23f3b7d">381: Large Batch Training of Convolutional Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.640199</td>
<td>0.962582</td>
<td><a href="https://www.semanticscholar.org/paper/42a7015e48a1e00b70ebb442a82afb4b10017c0b">47: When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.693559</td>
<td>0.961555</td>
<td><a href="https://www.semanticscholar.org/paper/43497fe8aa7c730e075b08facc2aa560a6d4dd85">164: Meta Pseudo Labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.725209</td>
<td>0.959932</td>
<td><a href="https://www.semanticscholar.org/paper/0495d9df8eb84dcdab4e5536179823cd26279949">447: Big Transfer (BiT): General Visual Representation Learning</a></td>
</tr>
</table></html>
