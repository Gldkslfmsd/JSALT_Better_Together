<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb">932: A Scalable Hierarchical Distributed Language Model</a></td>
</tr>
<tr>
<td>1</td>
<td>0.846829</td>
<td>0.991404</td>
<td><a href="https://www.semanticscholar.org/paper/c19fbefdeead6a4154a22a9c8551a18b1530033a">940: Hierarchical Probabilistic Neural Network Language Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805907</td>
<td>0.605953</td>
<td><a href="https://www.semanticscholar.org/paper/cd887a465e92aef2a8364945422ffeaffe0400a7">3: Verifying the long-range dependency of RNN language models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802054</td>
<td>0.671023</td>
<td><a href="https://www.semanticscholar.org/paper/1453892cf162d193e58912caf67e191485a65b03">8: Temporal hierarchies in multilayer gated recurrent neural networks for language models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.777597</td>
<td>0.793530</td>
<td><a href="https://www.semanticscholar.org/paper/a65c9dd6b2ce1159187b25fd3c2c79649e255fce">0: PAID I A SURVEY ON LANGUAGE MODELING USING NEURAL NETWORKS</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768780</td>
<td>0.762974</td>
<td><a href="https://www.semanticscholar.org/paper/96484cf289d3dbc723ecc9784d2b411e9bd7acae">4: Self-organized Hierarchical Softmax</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768400</td>
<td>0.665779</td>
<td><a href="https://www.semanticscholar.org/paper/7284e1b540a5c6e368c6616866d5068516c33eeb">1: Language Modeling with Shared Grammar</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768243</td>
<td>0.947941</td>
<td><a href="https://www.semanticscholar.org/paper/1bdf8961c427a77662b457b38f2057b12d9e4d07">36: A Spectral Algorithm for Learning Class-Based n-gram Models of Natural Language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768146</td>
<td>0.718252</td>
<td><a href="https://www.semanticscholar.org/paper/162db03ef3cb50a07ff54ae4a1d4ea120e4162f2">121: Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766284</td>
<td>0.330514</td>
<td><a href="https://www.semanticscholar.org/paper/f53c13e55c7a3ecae15481dfead058f346cb4e39">0: The Importance of Context in Very Low Resource Language Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768708</td>
<td>0.991967</td>
<td><a href="https://www.semanticscholar.org/paper/5eb1a272f9933a11d113cf63fe659e073942bce5">551: Neural Probabilistic Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766425</td>
<td>0.990042</td>
<td><a href="https://www.semanticscholar.org/paper/bd7d93193aad6c4b71cc8942e808753019e87706">605: Three new graphical models for statistical language modelling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.755160</td>
<td>0.987592</td>
<td><a href="https://www.semanticscholar.org/paper/7fefba4d85d8eb32efe43fd54a13c9b396ac19dc">84: Neural network based language models for highly inflective languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.578171</td>
<td>0.987437</td>
<td><a href="https://www.semanticscholar.org/paper/893c2f504877e4878b93f5f7b907ae497f95e3db">156: Semantic Clustering and Convolutional Neural Network for Short Text Categorization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.707541</td>
<td>0.986170</td>
<td><a href="https://www.semanticscholar.org/paper/e89f679710507e239775a1e9c81988c3f928cbed">239: Word Embeddings through Hellinger PCA</a></td>
</tr>
<tr>
<td>0</td>
<td>0.698197</td>
<td>0.986050</td>
<td><a href="https://www.semanticscholar.org/paper/dac72f2c509aee67524d3321f77e97e8eff51de6">2148: Word Representations: A Simple and General Method for Semi-Supervised Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.690637</td>
<td>0.984542</td>
<td><a href="https://www.semanticscholar.org/paper/0679bcb9eca1e0d73a8d72f6f7f0e4cd9ba6557b">62: Learning Word Representation Considering Proximity and Ambiguity</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691241</td>
<td>0.983589</td>
<td><a href="https://www.semanticscholar.org/paper/6a4007e60346e4501acc936b49b7a476e73afa1e">37: Learning Multilingual Word Representations using a Bag-of-Words Autoencoder</a></td>
</tr>
</table></html>
