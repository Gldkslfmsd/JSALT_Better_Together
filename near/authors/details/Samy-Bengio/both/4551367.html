<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/ca5642f522cd2cd44948c7e9f337c91e5f26fdcf">187: Adversarial Attacks and Defences Competition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.836155</td>
<td>0.980360</td>
<td><a href="https://www.semanticscholar.org/paper/a4f5a3467de3e8e5b949dcd4eca7e8f98fe5d9de">0: Defending against adversarial attacks in deep neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823582</td>
<td>0.995663</td>
<td><a href="https://www.semanticscholar.org/paper/4deba3f41da26653f7764813af261b85d8d88b78">89: Extending Defensive Distillation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818233</td>
<td>0.955934</td>
<td><a href="https://www.semanticscholar.org/paper/15bbec7d9cab1d3fcf197088e5547caf5c11ec85">0: Adversarial Machine Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.815270</td>
<td>0.949860</td>
<td><a href="https://www.semanticscholar.org/paper/eaf8e121d73e3363e885e7cad7de8f73f6e8e16c">0: Developing and Defeating Adversarial Examples</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800572</td>
<td>0.947611</td>
<td><a href="https://www.semanticscholar.org/paper/e24b8a9531573d284647239affc6c855505b0de4">728: Adversarial Machine Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796323</td>
<td>0.983465</td>
<td><a href="https://www.semanticscholar.org/paper/972936a14e6c3eb620e52b747139bae21da1d16d">0: Improving robustness of neural networks against adversarial examples</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794998</td>
<td>0.599348</td>
<td><a href="https://www.semanticscholar.org/paper/b1fe450bb0b0ccac0dc0b485961b62cbb5e86189">1: Adversarial Machine Learning for Protecting Against Online Manipulation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790833</td>
<td>0.988001</td>
<td><a href="https://www.semanticscholar.org/paper/d2f6218969180c24ccbcefe916afa9447810e975">0: Adversarial Attack with Pattern Replacement</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788077</td>
<td>0.991184</td>
<td><a href="https://www.semanticscholar.org/paper/e33853a2dc15ed914e19e0ccd4c63957a2ef7dc6">2: L1-norm double backpropagation adversarial defense</a></td>
</tr>
<tr>
<td>0</td>
<td>0.741887</td>
<td>0.998823</td>
<td><a href="https://www.semanticscholar.org/paper/ca9c1224636b0a7dd37340a4691c34a9914b5af8">495: Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser</a></td>
</tr>
<tr>
<td>0</td>
<td>0.761478</td>
<td>0.998747</td>
<td><a href="https://www.semanticscholar.org/paper/8e37a3b227b68953f8067215828dc8b8714cb21b">1089: Boosting Adversarial Attacks with Momentum</a></td>
</tr>
<tr>
<td>0</td>
<td>0.698207</td>
<td>0.998667</td>
<td><a href="https://www.semanticscholar.org/paper/3ecda636a99ec93acc941c0217a65c9a3af9562f">67: ADef: an Iterative Algorithm to Construct Adversarial Deformations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.739506</td>
<td>0.998218</td>
<td><a href="https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827">1852: Adversarial Machine Learning at Scale</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734442</td>
<td>0.998113</td>
<td><a href="https://www.semanticscholar.org/paper/7557a6512295ab7cfe8332b1d53ae40e675c9750">123: NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.733789</td>
<td>0.998005</td>
<td><a href="https://www.semanticscholar.org/paper/45a710be199c8eb43f465c88fc4b343267c35d38">78: Cascade Adversarial Machine Learning Regularized with a Unified Embedding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.654289</td>
<td>0.997903</td>
<td><a href="https://www.semanticscholar.org/paper/c00f744f103a528f5b45bf0482f54b5e6a9f7740">290: A study of the effect of JPG compression on adversarial images</a></td>
</tr>
<tr>
<td>0</td>
<td>0.631778</td>
<td>0.997898</td>
<td><a href="https://www.semanticscholar.org/paper/59d9318f07331ec15e54fe2a4218bc4a5c247a38">300: Foolbox: A Python toolbox to benchmark the robustness of machine learning models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.688263</td>
<td>0.997873</td>
<td><a href="https://www.semanticscholar.org/paper/1b225474e7a5794f98cdfbde8b12ccbc56799409">627: Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models</a></td>
</tr>
</table></html>
