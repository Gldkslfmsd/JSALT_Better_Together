<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/b0316d17fef2a42fba426426e5ea090a83205aaa">79: An Exploration of Dropout with LSTMs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809904</td>
<td>0.932140</td>
<td><a href="https://www.semanticscholar.org/paper/c0abe84cf60eb2aebf4fc4d4e8185cc98b5e7747">1: Empirical Evaluation of A New Approach to Simplifying Long Short-term Memory (LSTM)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804069</td>
<td>0.963405</td>
<td><a href="https://www.semanticscholar.org/paper/165e1d2def3e2f14396f20e046b73ca13935b68d">147: Automatic language identification using long short-term memory recurrent neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.789956</td>
<td>0.874217</td>
<td><a href="https://www.semanticscholar.org/paper/8390c96f0b2ff3b36b232f7f9918401e51632f4e">1: Workshop Track -iclr 2016 Visualizing and Understanding Recurrent Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.787242</td>
<td>0.778934</td>
<td><a href="https://www.semanticscholar.org/paper/269e673ddfb627f26ace74a4b7a790dcf9f909df">1: BINING RECENT INSIGHTS FOR LSTMS</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785839</td>
<td>0.651320</td>
<td><a href="https://www.semanticscholar.org/paper/cb7f54d75d9f07e2d648f0c1e5ccb3c57652bf37">41: Named Entity Recognition with Stack Residual LSTM and Trainable Bias Decoding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.780652</td>
<td>0.013811</td>
<td>NA:7433001</td>
</tr>
<tr>
<td>0</td>
<td>0.779111</td>
<td>0.540591</td>
<td><a href="https://www.semanticscholar.org/paper/59ed57c0c5e6e0b1ba7d99c4526e0ff59a738570">20: Distributed Deep Learning Strategies for Automatic Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.777493</td>
<td>0.866802</td>
<td><a href="https://www.semanticscholar.org/paper/6a94f7bccd51fb3607d314ab7371bdc8c5c400f5">4: Factorized Hidden Variability Learning for Adaptation of Short Duration Language Identification Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772314</td>
<td>0.686002</td>
<td><a href="https://www.semanticscholar.org/paper/b09cee645bd2c87769362c79fd20e37d5d6ac9aa">7: Product Categorization with LSTMs and Balanced Pooling Views</a></td>
</tr>
<tr>
<td>0</td>
<td>0.724722</td>
<td>0.990078</td>
<td><a href="https://www.semanticscholar.org/paper/fa7d8aadf92fa9761506780a72f8992ec8504fc0">161: Learning acoustic frame labeling for speech recognition with recurrent neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.749643</td>
<td>0.989776</td>
<td><a href="https://www.semanticscholar.org/paper/d155d64bdd86edf33f4395c5aec0388ffed69f99">72: An empirical exploration of CTC acoustic models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.631340</td>
<td>0.989505</td>
<td><a href="https://www.semanticscholar.org/paper/9650d995b5f599abc15ca5627e70d5816e55371d">8: End-to-End-Based Tibetan Multitask Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736797</td>
<td>0.988784</td>
<td><a href="https://www.semanticscholar.org/paper/500d00e75f2c346a924f2eb004a170bc4d5d8130">4: Multi-view Frequency LSTM: An Efficient Frontend for Automatic Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705436</td>
<td>0.988617</td>
<td><a href="https://www.semanticscholar.org/paper/39562f94f8cb0469ce3a7febbbca7887b577efb3">6: End-to-End Speech Recognition in Agglutinative Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.568786</td>
<td>0.986924</td>
<td><a href="https://www.semanticscholar.org/paper/64d24c7e3506f824a4860359f25e3382af6a6db0">12: Minimum Bayes risk training of CTC acoustic models in maximum a posteriori based decoding framework</a></td>
</tr>
<tr>
<td>0</td>
<td>0.680743</td>
<td>0.986788</td>
<td><a href="https://www.semanticscholar.org/paper/ef15b6697b1f51b876f28e5d3da9eab0520c3e42">18: End-to-End Mandarin Speech Recognition Combining CNN and BLSTM</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717187</td>
<td>0.986693</td>
<td><a href="https://www.semanticscholar.org/paper/fab90790ab3a3880e6fec274b3760f4417e76f0b">22: End-to-End Training of Acoustic Models for Large Vocabulary Continuous Speech Recognition with TensorFlow</a></td>
</tr>
<tr>
<td>0</td>
<td>0.641750</td>
<td>0.986033</td>
<td><a href="https://www.semanticscholar.org/paper/4ffa3bdfb89903dae1c49df56711799ec6b632b8">51: Multi-accent speech recognition with hierarchical grapheme based models</a></td>
</tr>
</table></html>
