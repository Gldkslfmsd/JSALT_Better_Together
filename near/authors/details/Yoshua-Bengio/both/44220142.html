<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/c3955d74f2a084a8ddcbd7e73952c326e81804b2">499: Mutual Information Neural Estimation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772178</td>
<td>0.650214</td>
<td><a href="https://www.semanticscholar.org/paper/1b53e8652676a1806d0d2abc5d7abcd212709046">8: Estimating informativeness of samples with Smooth Unique Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738839</td>
<td>0.537876</td>
<td><a href="https://www.semanticscholar.org/paper/86f62cb363a849d58202303919d2de1c2aef63a5">2: Reve: Regularizing Deep Learning with Variational Entropy Bound</a></td>
</tr>
<tr>
<td>0</td>
<td>0.735287</td>
<td>0.487728</td>
<td><a href="https://www.semanticscholar.org/paper/bb1f066a540164c48f8ab92889daaec20ba7c968">0: Low Intrinsic Dimension Implies Generalization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.728544</td>
<td>0.292995</td>
<td><a href="https://www.semanticscholar.org/paper/4c1d1ab8a669175b0b2682b550ec3d7d0accca63">9: Maximum Entropy Learning with Deep Belief Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719048</td>
<td>0.912292</td>
<td><a href="https://www.semanticscholar.org/paper/61b1c85aeebe5713637853db520eb49e277e0f76">0: Variational Fair Information Bottleneck</a></td>
</tr>
<tr>
<td>0</td>
<td>0.707713</td>
<td>0.348722</td>
<td><a href="https://www.semanticscholar.org/paper/616cdedd45ca46a671ed43400305359319224e70">7: On the Generalization Properties of Adversarial Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705315</td>
<td>0.374485</td>
<td><a href="https://www.semanticscholar.org/paper/35da7a5bf40fc103af0df3c94ce215b6548834e9">0: Deep Minimax Probability Machine</a></td>
</tr>
<tr>
<td>0</td>
<td>0.703293</td>
<td>0.826834</td>
<td><a href="https://www.semanticscholar.org/paper/52ffd166f61c164d03a9f5a252bdc0976f8bf51b">6: Information Theoretic Meta Learning with Gaussian Processes</a></td>
</tr>
<tr>
<td>0</td>
<td>0.693145</td>
<td>0.726377</td>
<td><a href="https://www.semanticscholar.org/paper/4c652487e44f88939451455852aba30e93824fac">5: Semi-Supervised learning using adversarial networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.850017</td>
<td>0.988922</td>
<td><a href="https://www.semanticscholar.org/paper/372bf2716c53e353be6c3f027493f1a40edb6640">383: MINE: Mutual Information Neural Estimation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.687845</td>
<td>0.986151</td>
<td><a href="https://www.semanticscholar.org/paper/41382835ae60fb3280ea9a5b3004a236af1eb01b">51: CLUB: A Contrastive Log-ratio Upper Bound of Mutual Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.780138</td>
<td>0.985419</td>
<td><a href="https://www.semanticscholar.org/paper/7a70764c4e1173ceab983a759ac3c665a88f2195">88: Understanding the Limitations of Variational Mutual Information Estimators</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760104</td>
<td>0.982246</td>
<td><a href="https://www.semanticscholar.org/paper/4aea3547974399a32d7aa7c007b10bd665e93fab">329: On Variational Bounds of Mutual Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812731</td>
<td>0.967090</td>
<td><a href="https://www.semanticscholar.org/paper/1731951b00c42c08d32001b4e311bb3e13d7ce18">2: Regularized Mutual Information Neural Estimation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738010</td>
<td>0.966867</td>
<td><a href="https://www.semanticscholar.org/paper/bca06eff83fb757fbfe2b0a9d574dd1b4cc5920a">60: Wasserstein Dependency Measure for Representation Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767422</td>
<td>0.966491</td>
<td><a href="https://www.semanticscholar.org/paper/7ca01f2cc5516f868c5806bc7f5763abf9e6b9f8">36: On variational lower bounds of mutual information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.687084</td>
<td>0.966215</td>
<td><a href="https://www.semanticscholar.org/paper/47cdca894ee2aa08d080321849dbb8644e30232d">0: Estimating Total Correlation with Mutual Information Bounds</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691121</td>
<td>0.963098</td>
<td><a href="https://www.semanticscholar.org/paper/2b2cf76246466c266f9c9fe9bbfd43d918514e55">118: Formal Limitations on the Measurement of Mutual Information</a></td>
</tr>
</table></html>
