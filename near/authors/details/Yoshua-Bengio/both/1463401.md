<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/65eee67dee969fdf8b44c87c560d66ad4d78e233">432: Hierarchical Multiscale Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830135</td>
<td>0.891406</td>
<td><a href="https://www.semanticscholar.org/paper/b0b33aaed1d408d04fadf9ff2a080e47ef8cb7b1">394: Training and Analysing Deep Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794425</td>
<td>0.855618</td>
<td><a href="https://www.semanticscholar.org/paper/51cf822dfe458ca182332b0c8696adbb1b7e37de">0: Recurrent Neural Networks with Mixed Hierarchical Structures and EM Algorithm for Natural Language Processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.789719</td>
<td>0.752466</td>
<td><a href="https://www.semanticscholar.org/paper/f05d8eacc1469439bb04f2768fd68878c982e636">298: Sequential Neural Models with Stochastic Layers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788531</td>
<td>0.960104</td>
<td><a href="https://www.semanticscholar.org/paper/11dfd8cbb70c54277dcfea7e17ece2297610b0bb">3: Temporal Pyramid Recurrent Neural Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788489</td>
<td>0.886463</td>
<td><a href="https://www.semanticscholar.org/paper/41621f06c2d262f12a59b5f0472080dd9e9afc53">7: Non-Local Recurrent Neural Memory for Supervised Sequence Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772447</td>
<td>0.663690</td>
<td><a href="https://www.semanticscholar.org/paper/d86bd86e8d6d5d246d7824c202138a549fad391c">0: On the Utility of Combining Topic Models and Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.763067</td>
<td>-0.015900</td>
<td><a href="https://www.semanticscholar.org/paper/382bd2bfb036c8d678ca42b3d57e015c31182085">0: Recent Advances and the Future of Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762323</td>
<td>0.889190</td>
<td><a href="https://www.semanticscholar.org/paper/4e08218c8bf847733a85328b66649c13aa189ac2">3: Stochastic Recurrent Neural Network for Multistep Time Series Forecasting</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751644</td>
<td>0.212492</td>
<td><a href="https://www.semanticscholar.org/paper/0d1bd5e2831f9182c7b218d289920bb00e460cee">7: Engineering recurrent neural networks from task-relevant manifolds and dynamics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.686258</td>
<td>0.990032</td>
<td><a href="https://www.semanticscholar.org/paper/608e4bbe7a2d6f04d68b5747d9d0778d5fce47df">119: Learning Longer-term Dependencies in RNNs with Auxiliary Losses</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740378</td>
<td>0.988869</td>
<td><a href="https://www.semanticscholar.org/paper/136cf66392f1d6bf42da4cc070888996dc472b91">130: On Multiplicative Integration with Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.749623</td>
<td>0.986123</td>
<td><a href="https://www.semanticscholar.org/paper/6746a18b2820f757334f75bc95428b3ea58d6603">45: Variable Computation in Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.703802</td>
<td>0.985519</td>
<td><a href="https://www.semanticscholar.org/paper/72ebf25c2d0aff183e61d4e60f6f484767a2de36">33: When Recurrent Models Don't Need To Be Recurrent</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674632</td>
<td>0.983718</td>
<td><a href="https://www.semanticscholar.org/paper/87a913817503379547bec61a5f010abac5b0f76b">64: Fast-Slow Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748081</td>
<td>0.982471</td>
<td><a href="https://www.semanticscholar.org/paper/2dad7e558a1e2982d0d42042021f4cde4af04abf">173: Dilated Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.695959</td>
<td>0.979730</td>
<td><a href="https://www.semanticscholar.org/paper/e837b79de602c69395498c1fbbe39bbb4e6f75ad">257: Learning to Transduce with Unbounded Memory</a></td>
</tr>
<tr>
<td>0</td>
<td>0.563667</td>
<td>0.978398</td>
<td><a href="https://www.semanticscholar.org/paper/c3823aacea60bc1f2cabb9283144690a3d015db5">1627: Neural Turing Machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.647653</td>
<td>0.978258</td>
<td><a href="https://www.semanticscholar.org/paper/9f0687bcd0a7d7fc91b8c5d36c003a38b8853105">263: Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations</a></td>
</tr>
</table></html>
