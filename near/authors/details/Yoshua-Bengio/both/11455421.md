<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/5ddd38a5df945e4afee68d96ed51fd6ca1f7d4cf">821: A Closer Look at Memorization in Deep Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823115</td>
<td>0.849090</td>
<td><a href="https://www.semanticscholar.org/paper/c83068abb364c3d3d3bfd47528f210f0c8f60e9d">0: On the Memorization Properties of Contrastive Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.822380</td>
<td>0.957085</td>
<td><a href="https://www.semanticscholar.org/paper/5a41802f417aa7e55d76bfe5a61dae2141a7131b">13: On the geometry of generalization and memorization in deep neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805828</td>
<td>0.958329</td>
<td><a href="https://www.semanticscholar.org/paper/54ddb00fa691728944fd8becea90a373d21597cf">3442: Understanding deep learning requires rethinking generalization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798527</td>
<td>0.961004</td>
<td><a href="https://www.semanticscholar.org/paper/d5fc1374bfb839a65e928c8554ec09421739c2b7">11: Robust Training with Ensemble Consensus</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786328</td>
<td>0.828662</td>
<td><a href="https://www.semanticscholar.org/paper/6a09a5ec482275141f304c251fc9a563c149cb1a">4: Towards Understanding Learning in Neural Networks with Linear Teachers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.778590</td>
<td>0.858941</td>
<td><a href="https://www.semanticscholar.org/paper/a7865ea4962fdfe6d7351127235a5807b056fd9b">0: Assessing Unintended Memorization in Neural Discriminative Sequence Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.773054</td>
<td>0.848778</td>
<td><a href="https://www.semanticscholar.org/paper/dd51c24c0c8d9a54ac2c792aa7f45a1beb5d3c87">53: Understanding training and generalization in deep learning by Fourier analysis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766496</td>
<td>0.844755</td>
<td><a href="https://www.semanticscholar.org/paper/086b44520511e1d9a17052fd6a5b9890729e0be8">44: Gradient Descent Quantizes ReLU Network Features</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766471</td>
<td>0.845952</td>
<td><a href="https://www.semanticscholar.org/paper/4873c78f0cd5a1fad96300e49e196af75800a24e">115: Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.617145</td>
<td>0.986452</td>
<td><a href="https://www.semanticscholar.org/paper/8bc63c8bd96b40d8d0f5329e06e0a96eaf214c7f">12: Combining Ensembles and Data Augmentation can Harm your Calibration</a></td>
</tr>
<tr>
<td>0</td>
<td>0.632165</td>
<td>0.985954</td>
<td><a href="https://www.semanticscholar.org/paper/29891cba979efd7a5a332f2210a3a9aa5192a805">6: Noise against noise: stochastic label noise helps combat inherent label noise</a></td>
</tr>
<tr>
<td>0</td>
<td>0.750699</td>
<td>0.985492</td>
<td><a href="https://www.semanticscholar.org/paper/560c7437538dbadbb1e3e27e309945f2befd521f">23: Improving Generalization by Controlling Label-Noise Information in Neural Network Weights</a></td>
</tr>
<tr>
<td>0</td>
<td>0.743940</td>
<td>0.984091</td>
<td><a href="https://www.semanticscholar.org/paper/bafb088c459188fd22fc20eb3af6b731d4856629">47: Robust early-learning: Hindering the memorization of noisy labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691112</td>
<td>0.982522</td>
<td><a href="https://www.semanticscholar.org/paper/622727f595542afa3caf8802927d880818ddb17a">242: Dimensionality-Driven Learning with Noisy Labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.694286</td>
<td>0.982415</td>
<td><a href="https://www.semanticscholar.org/paper/77c474e38d2833cfa0edaf4a6098e413a76557c5">93: Combating Label Noise in Deep Learning Using Abstention</a></td>
</tr>
<tr>
<td>0</td>
<td>0.708332</td>
<td>0.981276</td>
<td><a href="https://www.semanticscholar.org/paper/5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e">162: Learning from Noisy Labels with Deep Neural Networks: A Survey</a></td>
</tr>
<tr>
<td>0</td>
<td>0.663410</td>
<td>0.980983</td>
<td><a href="https://www.semanticscholar.org/paper/38268657b2aedf37adc7863aea2e8df0a39be4cb">15: Uncertainty Based Detection and Relabeling of Noisy Image Labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.599992</td>
<td>0.980769</td>
<td><a href="https://www.semanticscholar.org/paper/2c4a569830bbf74af447842359882a14f840e803">3: Improving Classifier Confidence using Lossy Label-Invariant Transformations</a></td>
</tr>
</table></html>
