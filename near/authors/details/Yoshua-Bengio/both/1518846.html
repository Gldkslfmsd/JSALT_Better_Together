<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/a5733ff08daff727af834345b9cfff1d0aa109ec">2076: BinaryConnect: Training Deep Neural Networks with binary weights during propagations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.858860</td>
<td>0.841539</td>
<td><a href="https://www.semanticscholar.org/paper/fdc8505d076c7a2ad162510bde93e4e62bac655d">3: Transfer Learning with Binary Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.837022</td>
<td>0.936262</td>
<td><a href="https://www.semanticscholar.org/paper/f8f4b2da9c1f94fe0665fbc14fb4b700fb7b30fc">13: Flexpoint: Predictive Numerics for Deep Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830971</td>
<td>0.958603</td>
<td><a href="https://www.semanticscholar.org/paper/3a7d74982073cccb179c771b158fbc98dda94449">0: Flexpoint : Predictive Numerics for Deep Learning ( Invited Paper )</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830872</td>
<td>0.871349</td>
<td><a href="https://www.semanticscholar.org/paper/35223dd8ba667313de234f1e6a1ec928183286e3">3: MAERI</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829605</td>
<td>0.802487</td>
<td><a href="https://www.semanticscholar.org/paper/687403b9f9d17fada91edacb4e9b4b4860a0d80a">0: ISyNet: Convolutional Neural Networks design for AI accelerator</a></td>
</tr>
<tr>
<td>0</td>
<td>0.826801</td>
<td>0.784546</td>
<td><a href="https://www.semanticscholar.org/paper/269b35999a89dc97cc238b28b5bf8ad1e9b28b22">0: From DNNs to GANs: Review of efficient hardware architectures for deep learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821887</td>
<td>0.962914</td>
<td><a href="https://www.semanticscholar.org/paper/57713f4b3b9fbe6ceddfa8c26b4e1b99ad50a9b7">114: Ristretto: Hardware-Oriented Approximation of Convolutional Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813151</td>
<td>0.709502</td>
<td><a href="https://www.semanticscholar.org/paper/036010e5afc249590c06ab1e4b5faf71dff27f42">0: Representation range needs for 16-bit neural network training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811191</td>
<td>0.931986</td>
<td><a href="https://www.semanticscholar.org/paper/6e6f92a1eded19388301983f8d3bdb6cd20b8c48">91: Rethinking floating point for deep learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.844507</td>
<td>0.999222</td>
<td><a href="https://www.semanticscholar.org/paper/6eecc808d4c74e7d0d7ef6b8a4112c985ced104d">1696: Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.994824</td>
<td><a href="https://www.semanticscholar.org/paper/db55998b130cc5020e3f83e45192bfdfbe92d6e3">629: XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803839</td>
<td>0.994292</td>
<td><a href="https://www.semanticscholar.org/paper/28135fd3e80dda50a673cd556f10b9b972005d27">1236: Binarized Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799786</td>
<td>0.994249</td>
<td><a href="https://www.semanticscholar.org/paper/d2e4147eecae6f914e9e1e9aece8fdd2eaed809f">1251: Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762452</td>
<td>0.994243</td>
<td><a href="https://www.semanticscholar.org/paper/33da17e0070dfceed05aec1602a7d1e3284cf715">600: Fixed Point Quantization of Deep Convolutional Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768842</td>
<td>0.993128</td>
<td><a href="https://www.semanticscholar.org/paper/d5710bce2dda5d01cb14644281731394ff719265">94: The Power of Sparsity in Convolutional Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719559</td>
<td>0.993038</td>
<td><a href="https://www.semanticscholar.org/paper/03b2c22acd32931a5b2b80649d604de42c40f371">14: On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.769239</td>
<td>0.991927</td>
<td><a href="https://www.semanticscholar.org/paper/75dd30fde950bc8996b5105fff6f9fc3c1d2dbae">185: How to Train a Compact Binary Neural Network with High Accuracy?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.814988</td>
<td>0.991761</td>
<td><a href="https://www.semanticscholar.org/paper/710bcef2c7c2e6a1ba455c136cb0aaa5580fb8e5">239: Model Compression and Acceleration for Deep Neural Networks: The Principles, Progress, and Challenges</a></td>
</tr>
</table></html>
