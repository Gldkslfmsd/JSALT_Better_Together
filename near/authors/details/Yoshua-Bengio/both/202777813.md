<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/37e52ff4714c7a08900b518127e438a195b84611">346: MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.896378</td>
<td>0.959756</td>
<td><a href="https://www.semanticscholar.org/paper/4e468d3da1797d791db8d514d695b183acb027ee">223: HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.878838</td>
<td>0.982945</td>
<td><a href="https://www.semanticscholar.org/paper/46a34e4239adfe222bdad453821372904b5d0b40">13: Unconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.856168</td>
<td>0.970587</td>
<td><a href="https://www.semanticscholar.org/paper/581ac1e3568b8d632c2cdbef3bf91acb803b78f2">2: RAVE: A variational autoencoder for fast and high-quality neural audio synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.853344</td>
<td>0.945343</td>
<td><a href="https://www.semanticscholar.org/paper/e6ac42702b5d12d4d8eed856230127cafaa7e766">22: GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-spectrogram</a></td>
</tr>
<tr>
<td>1</td>
<td>0.852551</td>
<td>0.993326</td>
<td><a href="https://www.semanticscholar.org/paper/5299f6f6b496ef7f08328e4c3dbbd82441748a1c">13: StyleMelGAN: An Efficient High-Fidelity Adversarial Vocoder with Temporal Adaptive Normalization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.850406</td>
<td>0.947816</td>
<td><a href="https://www.semanticscholar.org/paper/0d3bbe47fe67e5a125a2547913ac0e4a30f18c8d">312: Adversarial Audio Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.849758</td>
<td>0.940184</td>
<td><a href="https://www.semanticscholar.org/paper/f8d43ff00585c53f65eb04e15477113c2d2b758b">701: SEGAN: Speech Enhancement Generative Adversarial Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.849209</td>
<td>0.940780</td>
<td><a href="https://www.semanticscholar.org/paper/50b4da711035e5ef155f176cb53c19274609b922">1: RefineGAN: Universally Generating Waveform Better than Ground Truth with Highly Accurate Pitch and Intensity Responses</a></td>
</tr>
<tr>
<td>0</td>
<td>0.839127</td>
<td>0.921962</td>
<td><a href="https://www.semanticscholar.org/paper/b3c9b0788e7dd0944047ef50e4c369cf237ba5ea">0: SE-MelGAN - Speaker Agnostic Rapid Speech Enhancement</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784642</td>
<td>0.997330</td>
<td><a href="https://www.semanticscholar.org/paper/54c0f3213921a7e2ce35b8b6afefaaa9fd036d11">172: Zero-Shot Voice Style Transfer with Only Autoencoder Loss</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823971</td>
<td>0.996384</td>
<td><a href="https://www.semanticscholar.org/paper/4cd2c3440b3c770ce3e1e75a0371a892bdb30945">34: VocGAN: A High-Fidelity Real-time Vocoder with a Hierarchically-nested Adversarial Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738891</td>
<td>0.995578</td>
<td><a href="https://www.semanticscholar.org/paper/97cc958a940a1b33241da612745c8347d7acf6d7">65: Multi-Band Melgan: Faster Waveform Generation For High-Quality Text-To-Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.775571</td>
<td>0.994710</td>
<td><a href="https://www.semanticscholar.org/paper/1ee20991b5b3441bb14badbadc4d61d7ed33752f">5: GAN Vocoder: Multi-Resolution Discriminator Is All You Need</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781947</td>
<td>0.994663</td>
<td><a href="https://www.semanticscholar.org/paper/39b11c504dd62f8c57f492f54d5b2e219f955d12">48: WaveFlow: A Compact Flow-based Model for Raw Audio</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782405</td>
<td>0.994496</td>
<td><a href="https://www.semanticscholar.org/paper/52eac03a7f65224db8c357199d6ae211230813db">5: Glow-WaveGAN: Learning Speech Representations from GAN-based Variational Auto-Encoder For High Fidelity Flow-based Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782821</td>
<td>0.994188</td>
<td><a href="https://www.semanticscholar.org/paper/10ae9a3d1e0874a50820766bd414f98e095cdd8a">11: WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.878358</td>
<td>0.993284</td>
<td><a href="https://www.semanticscholar.org/paper/85381e0e89e98ea1ed8bd3dfa533d911263757df">121: High Fidelity Speech Synthesis with Adversarial Networks</a></td>
</tr>
</table></html>
