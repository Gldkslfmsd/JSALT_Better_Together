<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/0ae4e3325e9d18f933c6399fff0dce975de5aebd">31: The Third DIHARD Diarization Challenge</a></td>
</tr>
<tr>
<td>1</td>
<td>0.923345</td>
<td>0.992604</td>
<td><a href="https://www.semanticscholar.org/paper/ff88699c6bac1b289272c445581541ad66848044">103: The Second DIHARD Diarization Challenge: Dataset, task, and baselines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.848673</td>
<td>0.981538</td>
<td><a href="https://www.semanticscholar.org/paper/580b7f070ddd82d754cbd8267abc4700bc826692">21: Third DIHARD Challenge Evaluation Plan</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805858</td>
<td>0.937638</td>
<td><a href="https://www.semanticscholar.org/paper/1ca5d9b69d419f9b6345ca4bc52bcc80c4e4a05b">7: The Speed Submission to DIHARD II: Contributions & Lessons Learned</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792299</td>
<td>0.924811</td>
<td><a href="https://www.semanticscholar.org/paper/1497028daa5146959d2a556ec51f98d1eb3fff1f">1: The DKU-Duke-Lenovo System Description for the Third DIHARD Speech Diarization Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785540</td>
<td>0.468979</td>
<td><a href="https://www.semanticscholar.org/paper/4794a61be8c750018176fa2639352d0e7f6b9c5e">192: Approaches and applications of audio diarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774541</td>
<td>0.938352</td>
<td><a href="https://www.semanticscholar.org/paper/984cba97eaf27ff2c9c931e6c0c509abbefab195">0: Chronological Self-Training for Real-Time Speaker Diarization</a></td>
</tr>
<tr>
<td>1</td>
<td>0.764951</td>
<td>0.989823</td>
<td><a href="https://www.semanticscholar.org/paper/ba4b6b439cbcf81c035875a4b6b6dcf904545054">2: Scenario-Dependent Speaker Diarization for DIHARD-III Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.763941</td>
<td>0.761225</td>
<td><a href="https://www.semanticscholar.org/paper/3c609eb879eb9721e1fd72160c2a04a230d2c483">4: Experiments with Segmentation in an Online Speaker Diarization System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.763891</td>
<td>0.621001</td>
<td><a href="https://www.semanticscholar.org/paper/21776da76c5a877dae9101cc07d4aa5034926003">4: Comparison of Diarization Tools for Building Speaker Database</a></td>
</tr>
<tr>
<td>0</td>
<td>0.598256</td>
<td>0.989197</td>
<td><a href="https://www.semanticscholar.org/paper/55277df8e04cc75d46470318d9ffbffe365527ee">42: Bayesian HMM Based x-Vector Clustering for Speaker Diarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794990</td>
<td>0.988057</td>
<td><a href="https://www.semanticscholar.org/paper/be06d5fcaa3587ddb6ca3950561ec3d6ad95bf54">44: BUT System for DIHARD Speech Diarization Challenge 2018</a></td>
</tr>
<tr>
<td>0</td>
<td>0.587315</td>
<td>0.987884</td>
<td><a href="https://www.semanticscholar.org/paper/80d4aeb2fd8441d39d42037019df89c2de236c4a">0: Online Speaker Diarization with Graph-based Label Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.637788</td>
<td>0.987809</td>
<td><a href="https://www.semanticscholar.org/paper/eeddc26f17f2ed10b47da2f1d390333437b60480">2: Overlap-Aware Low-Latency Online Speaker Diarization Based on End-to-End Local Segmentation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.647734</td>
<td>0.987694</td>
<td><a href="https://www.semanticscholar.org/paper/181e1d4b08dc62237277a6a743576facd8c5e572">6: Target-Speaker Voice Activity Detection with Improved i-Vector Estimation for Unknown Number of Speaker</a></td>
</tr>
<tr>
<td>0</td>
<td>0.755274</td>
<td>0.986511</td>
<td><a href="https://www.semanticscholar.org/paper/8aa2c8f9d34db72d12ea99a38d4a3d9d528337ea">30: But System for the Second Dihard Speech Diarization Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.712494</td>
<td>0.984417</td>
<td><a href="https://www.semanticscholar.org/paper/e171ed4c7e19fdb5f6f9333ab5d6bd2ed9bdab2d">0: Multi-scale Speaker Diarization with Dynamic Scale Weighting</a></td>
</tr>
</table></html>
