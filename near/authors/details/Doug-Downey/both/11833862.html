<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/4596b094ccaa39b366a634d1b27bf3f1f82552fb">11: Efficient Methods for Inferring Large Sparse Topic Hierarchies</a></td>
</tr>
<tr>
<td>0</td>
<td>0.859768</td>
<td>-0.051000</td>
<td>NA:558833</td>
</tr>
<tr>
<td>0</td>
<td>0.836734</td>
<td>0.885769</td>
<td><a href="https://www.semanticscholar.org/paper/ad4b09832454a821e925e45e96e769f0c01bd3d6">24: Sparse Word Graphs: A Scalable Algorithm for Capturing Word Correlations in Topic Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834988</td>
<td>0.928059</td>
<td><a href="https://www.semanticscholar.org/paper/f5306f4cefdabd5227e7c38e1a1074da447fc3f7">66: Learning Topic Models by Belief Propagation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831639</td>
<td>0.978937</td>
<td><a href="https://www.semanticscholar.org/paper/7e499ef94e4d9a46eef2f09097ef1c6e285a18b7">119: Full-Text or Abstract? Examining Topic Coherence Scores Using Latent Dirichlet Allocation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831619</td>
<td>0.940594</td>
<td><a href="https://www.semanticscholar.org/paper/3cb9b14ae00cec3c1a8389cc9e2e50bcae303f0c">25: Independent factor topic models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829680</td>
<td>0.958268</td>
<td><a href="https://www.semanticscholar.org/paper/900706b995f69cb71af6673cfca0beaf5199f14d">0: Label Dependencies using a Tree-structured Hierarchy</a></td>
</tr>
<tr>
<td>0</td>
<td>0.824928</td>
<td>-0.051000</td>
<td>NA:206454775</td>
</tr>
<tr>
<td>0</td>
<td>0.821133</td>
<td>0.966731</td>
<td><a href="https://www.semanticscholar.org/paper/b3ff64377bcaa614319c20b77139bf6fb2dbbd4b">9: A Biterm-based Dirichlet Process Topic Model for Short Texts</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821072</td>
<td>0.916203</td>
<td><a href="https://www.semanticscholar.org/paper/072644f11e60babfa5c1bb24b96239c417a153ea">47: Fully Sparse Topic Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752082</td>
<td>0.993858</td>
<td><a href="https://www.semanticscholar.org/paper/d7e32ea5284034c2bbf26497668de29a1a460bef">30: MetaLDA: A Topic Model that Efficiently Incorporates Meta Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731146</td>
<td>0.993212</td>
<td><a href="https://www.semanticscholar.org/paper/b6f5ea77bfbebdcd08160145525a819d76f265c6">2: The Evolution of Topic Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760973</td>
<td>0.993154</td>
<td><a href="https://www.semanticscholar.org/paper/66e14c474ee1cde6de29379c04ca577d7d989402">13: Leveraging external information in topic modelling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.238645</td>
<td>0.992400</td>
<td><a href="https://www.semanticscholar.org/paper/5a60b8987f4c5765a343f7ee88d54bbf844d51ab">0: Что имеет большее значение? Сравнение влияния концептуальных и документальных отношений в тематических моделях</a></td>
</tr>
<tr>
<td>0</td>
<td>0.787076</td>
<td>0.991463</td>
<td><a href="https://www.semanticscholar.org/paper/c5c5281d1e3155363d691911a686267ef184fd10">2: Collaboratively Modeling and Embedding of Latent Topics for Short Texts</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758050</td>
<td>0.991141</td>
<td><a href="https://www.semanticscholar.org/paper/86425d891bdf861a3368c288bdee8d98d843c216">149: Short and Sparse Text Topic Modeling via Self-Aggregation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731017</td>
<td>0.991055</td>
<td><a href="https://www.semanticscholar.org/paper/39e3dbb9451b84bb2e27cdbc04899519e6360818">14: An Automatic Approach for Document-level Topic Model Evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774411</td>
<td>0.990978</td>
<td><a href="https://www.semanticscholar.org/paper/a7a288d230b0e761d239b7eb233fbd5cb316369e">122: Topic Modeling of Short Texts: A Pseudo-Document View</a></td>
</tr>
<tr>
<td>0</td>
<td>0.699200</td>
<td>0.990614</td>
<td><a href="https://www.semanticscholar.org/paper/1db09382df9f7495a71a0c9dd82bf9091e3f7f0d">2: Leveraging Meta Information in Short Text Aggregation</a></td>
</tr>
</table></html>
