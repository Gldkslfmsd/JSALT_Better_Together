<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/be18e1f566baeffb71fc4eed24f79dc8724879d4">65: Definition Modeling: Learning to Define Word Embeddings in Natural Language</a></td>
</tr>
<tr>
<td>1</td>
<td>0.899937</td>
<td>0.985095</td>
<td><a href="https://www.semanticscholar.org/paper/2e55cff6d5c73403d304b48ba8b8396676cd6c15">5: Improving Interpretability of Word Embeddings by Generating Definition and Usage</a></td>
</tr>
<tr>
<td>0</td>
<td>0.875390</td>
<td>0.799785</td>
<td><a href="https://www.semanticscholar.org/paper/189d46110b866e4c9a75e4c1f54cd261f47912b1">1: A Framework for Learning Knowledge-Powered Word Embedding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.874125</td>
<td>0.864225</td>
<td><a href="https://www.semanticscholar.org/paper/ecae66d66d2167267a892d2768f9cb43912427ae">1: Analyzing Structures in the Semantic Vector Space: A Framework for Decomposing Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.862844</td>
<td>0.954193</td>
<td><a href="https://www.semanticscholar.org/paper/45e47427e87525e3244d12f147915a3aad2d676f">5: Multi-sense Definition Modeling using Word Sense Decompositions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.860168</td>
<td>-0.024828</td>
<td><a href="https://www.semanticscholar.org/paper/f6ff54a82509f48847025621a4fa543902116f2b">0: Towards a Theoretical Understanding of Word and Relation Representation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.859098</td>
<td>0.883349</td>
<td><a href="https://www.semanticscholar.org/paper/dac731a9bf707b35ed351950740654184db83938">0: Beyond Context: A New Perspective for Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.858791</td>
<td>0.896463</td>
<td><a href="https://www.semanticscholar.org/paper/f4e3799a0bf6ec855eed4bddebdf526cf315a812">15: Character and Subword-Based Word Representation for Neural Language Modeling Prediction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.857147</td>
<td>0.910272</td>
<td><a href="https://www.semanticscholar.org/paper/f61564026e37722b7c27fc09af53026b3336cda6">0: Word Embeddings for Constructive Comments Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.854366</td>
<td>0.777295</td>
<td><a href="https://www.semanticscholar.org/paper/511ea834f4815ad2ec61b159773c66f2eef5f21e">1: Extracting Word Embeddings via Joint Learning of Syntagmatic and Paradigmatic Structure</a></td>
</tr>
<tr>
<td>0</td>
<td>0.666246</td>
<td>0.987684</td>
<td><a href="https://www.semanticscholar.org/paper/b4a7cc73e795ba19706a79ca3aabdf8747a2df30">54: A Neural Local Coherence Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805293</td>
<td>0.986544</td>
<td><a href="https://www.semanticscholar.org/paper/61d0e65485e05cb5e8ffe65002cf6c816514eaa4">45: Investigating Language Universal and Specific Properties in Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.679127</td>
<td>0.985946</td>
<td><a href="https://www.semanticscholar.org/paper/6cf767e3afcea890e759d4f07fd1620b3f3684c7">83: Discourse Parsing with Attention-based Hierarchical Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.684269</td>
<td>0.984378</td>
<td><a href="https://www.semanticscholar.org/paper/6d6697d412cee05e3b23687e5db09ced5bf2b3b1">52: Transition-based Neural RST Parsing with Implicit Syntax Features</a></td>
</tr>
<tr>
<td>0</td>
<td>0.704138</td>
<td>0.984250</td>
<td><a href="https://www.semanticscholar.org/paper/a778ac269e7cdf744cf7ec3ba363232c18325bb0">34: Improving Implicit Discourse Relation Classification by Modeling Inter-dependencies of Discourse Units in a Paragraph</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772102</td>
<td>0.983064</td>
<td><a href="https://www.semanticscholar.org/paper/70d3d2e0a8f34d6c3cb7890e249e2ed6a574ce50">166: Neural Semantic Role Labeling with Dependency Path Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781125</td>
<td>0.982893</td>
<td><a href="https://www.semanticscholar.org/paper/941e42ee75fc2bf07078bcfbd14bdf9ca7fe99ff">97: Cross-Lingual Word Embeddings for Low-Resource Language Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.744539</td>
<td>0.982485</td>
<td><a href="https://www.semanticscholar.org/paper/a4dd3beea286a20c4e4f66436875932d597190bc">364: Deep Semantic Role Labeling: What Works and What's Next</a></td>
</tr>
</table></html>
