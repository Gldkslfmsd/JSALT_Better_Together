<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/7345843e87c81e24e42264859b214d26042f8d51">421: Recurrent Neural Network Grammars</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829808</td>
<td>0.856470</td>
<td><a href="https://www.semanticscholar.org/paper/d8ac015407cf68c695043b23d905cddd880e5844">15: Generative Incremental Dependency Parsing with Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.822246</td>
<td>0.564012</td>
<td><a href="https://www.semanticscholar.org/paper/80bdbeada0d969188c0cf1664a60932b4e5e8439">1: Structural Bias in Inducing Representations for Probabilistic Natural Language Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.787214</td>
<td>0.676164</td>
<td><a href="https://www.semanticscholar.org/paper/452391ddfacf6ffabe62f7ca34feceba1d87806e">11: Inducing Regular Grammars Using Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768958</td>
<td>0.165940</td>
<td><a href="https://www.semanticscholar.org/paper/20e5fbc3d44bc69009b0ed935303f43a5a53676f">14: Connectionist Approaches to Language Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768777</td>
<td>0.159790</td>
<td><a href="https://www.semanticscholar.org/paper/87504e99d54f9481b9cd37f0f0563befcc68e209">7: Dynamic Grammatical Representations in Guided Propagation Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.761204</td>
<td>0.920204</td>
<td><a href="https://www.semanticscholar.org/paper/94960fcdf0ea3b346fca77ae8c63ae7943eb0d28">60: Easy-First Dependency Parsing with Hierarchical Tree LSTMs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758559</td>
<td>0.438082</td>
<td><a href="https://www.semanticscholar.org/paper/a64ca771a733d58dcbf8f7a3fe65a09310424bf8">215: Induction of Finite-State Languages Using Second-Order Recurrent Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.755830</td>
<td>0.397083</td>
<td><a href="https://www.semanticscholar.org/paper/4969e8034de8eebbe0738e42639a67c5921a3936">0: Inference of Stochastic Regular Languages through Simple Recurrent Networks with Time Delays</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751731</td>
<td>0.374207</td>
<td><a href="https://www.semanticscholar.org/paper/9b0bf4ef287a2794332d8df22b6820d5f0f49a35">36: Incremental Parsing by Modular Recurrent Connectionist Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796825</td>
<td>0.994081</td>
<td><a href="https://www.semanticscholar.org/paper/39f1b108687f643015f96a0c800585a44621f99c">95: Parsing as Language Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768743</td>
<td>0.991768</td>
<td><a href="https://www.semanticscholar.org/paper/f1cbf097ce436f7304a1984f4a29ab41f75ebfe3">131: Neural Language Modeling by Jointly Learning Syntax and Lexicon</a></td>
</tr>
<tr>
<td>0</td>
<td>0.770633</td>
<td>0.991346</td>
<td><a href="https://www.semanticscholar.org/paper/fce10a1a9727cbda33d44b62409e303f1009417a">126: What Do Recurrent Neural Network Grammars Learn About Syntax?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.697538</td>
<td>0.988836</td>
<td><a href="https://www.semanticscholar.org/paper/8f46c21fef31a4cdf7b1808e67171466a9317882">106: Do latent tree learning models identify meaningful structure in sentences?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.709456</td>
<td>0.988761</td>
<td><a href="https://www.semanticscholar.org/paper/43c2ca65595c732ad299db5b6ead7afd88012e36">12: An Empirical Study of Building a Strong Baseline for Constituency Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.670190</td>
<td>0.988363</td>
<td><a href="https://www.semanticscholar.org/paper/2cd7c3ed5a06c461b259694376820dcfcfbe94a9">41: Effective Inference for Generative Neural Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.503347</td>
<td>0.988201</td>
<td><a href="https://www.semanticscholar.org/paper/260d7e3448774e48f016dc6ad0d2cda0e76e46c4">48: Training Data Augmentation for Low-Resource Morphological Inflection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.623057</td>
<td>0.987830</td>
<td><a href="https://www.semanticscholar.org/paper/09f2d3f3e38b84c11c24f77b838e87dc4feffb7d">1: In-Order Chart-Based Constituent Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.574906</td>
<td>0.987052</td>
<td><a href="https://www.semanticscholar.org/paper/47a4d9486a9c5ed43f9f917dc8008dc0945e71ef">4: Enriched In-Order Linearization for Faster Sequence-to-Sequence Constituent Parsing</a></td>
</tr>
</table></html>
