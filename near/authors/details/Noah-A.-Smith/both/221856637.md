<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/ee5fff85d3ec62698eddba162f054b7e73670b2a">84: Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.741638</td>
<td>0.061129</td>
<td><a href="https://www.semanticscholar.org/paper/c70b0eb6f8a32efa540dddac44339f3fa0ea5675">2: Core Clustering as a Tool for Tackling Noise in Cluster Labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.729153</td>
<td>0.000183</td>
<td><a href="https://www.semanticscholar.org/paper/55ae29319b2477a5912ceaa77f9826aecad567b1">1: Semi-Supervised Approach to Predictive Analysis Using Temporal Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723070</td>
<td>0.088012</td>
<td><a href="https://www.semanticscholar.org/paper/6f61d293e1268bd6b21ef3de41352bad83e4e7e1">0: A confidence-prioritisation approach for learning noisy data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719421</td>
<td>0.419415</td>
<td><a href="https://www.semanticscholar.org/paper/6e98155a85d64e28f41655c2b7468a690551ae28">47: VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719014</td>
<td>0.118671</td>
<td><a href="https://www.semanticscholar.org/paper/7561f28a9d063c3275a3b416fe09da1d645e5ede">47: Generation and evaluation of synthetic patient data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.715461</td>
<td>-0.078279</td>
<td><a href="https://www.semanticscholar.org/paper/5f61527398d3e8b1087d18c5e8818502d607c916">33: Empirical data analysis: A new tool for data analytics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.713422</td>
<td>0.267981</td>
<td><a href="https://www.semanticscholar.org/paper/b5c09079d9432c0318475d61f27efb6323c642b7">0: XAI Beyond Classification: Interpretable Neural Clustering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.713332</td>
<td>0.462673</td>
<td><a href="https://www.semanticscholar.org/paper/536d12bdbdaf5d9425d43f2c00642eba2e8c0226">1: Combatting out-of-distribution errors using model-agnostic meta-learning for digital pathology</a></td>
</tr>
<tr>
<td>0</td>
<td>0.713275</td>
<td>0.113953</td>
<td><a href="https://www.semanticscholar.org/paper/46fe9ac16a012843891a3b4bbdee0950b6239850">0: Representation learning in multi-dimensional clinical timeseries for risk and event prediction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.698482</td>
<td>0.987347</td>
<td><a href="https://www.semanticscholar.org/paper/a6449a63008bdc7d18db330322b3de293426f53b">0: Towards Improving Selective Prediction Ability of NLP Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.662443</td>
<td>0.986297</td>
<td><a href="https://www.semanticscholar.org/paper/1d938731dfad31c09b2f58c365f630c640f2ca1a">1: ATM: An Uncertainty-aware Active Self-training Framework for Label-efficient Text Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.635793</td>
<td>0.985806</td>
<td><a href="https://www.semanticscholar.org/paper/bebb3a214c9c0eab2099f1b7f5824bbf73726ec7">1: Self-training with Few-shot Rationalization: Teacher Explanations Aid Student in Few-shot NLU</a></td>
</tr>
<tr>
<td>0</td>
<td>0.653586</td>
<td>0.985121</td>
<td><a href="https://www.semanticscholar.org/paper/7dc93d32613e8277eca1fdd8f414703f8969c132">0: Model Uncertainty-Aware Knowledge Amalgamation for Pre-Trained Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.658817</td>
<td>0.984805</td>
<td><a href="https://www.semanticscholar.org/paper/bcfe1c99b6108a52d4c6be30514ae4ada266ab1e">0: Self-training with Few-shot Rationalization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.683088</td>
<td>0.983522</td>
<td><a href="https://www.semanticscholar.org/paper/1f0e1657063ea38cf225eaf1c1187ae7b2e4a0e0">16: Increasing Robustness to Spurious Correlations using Forgettable Examples</a></td>
</tr>
<tr>
<td>0</td>
<td>0.682542</td>
<td>0.982248</td>
<td><a href="https://www.semanticscholar.org/paper/4b5e4948a572bd8d5045fdb532fa1391cb0b51eb">2: Dynamic Knowledge Distillation for Pre-trained Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.660681</td>
<td>0.982030</td>
<td><a href="https://www.semanticscholar.org/paper/1013750582c20bbdf1164127b5f26b1e06e817e3">11: MixKD: Towards Efficient Distillation of Large-scale Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.663552</td>
<td>0.981500</td>
<td><a href="https://www.semanticscholar.org/paper/e29d45aa2e86f7504718a879f71df5266d5ef4c7">0: Capture Human Disagreement Distributions by Calibrated Networks for Natural Language Inference</a></td>
</tr>
</table></html>
