<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/24741d280869ad9c60321f5ab6e5f01b7852507d">1503: Deep Speech: Scaling up end-to-end speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.858244</td>
<td>0.762316</td>
<td><a href="https://www.semanticscholar.org/paper/678cba6df672a9160085b75d4e4294165e4bbed8">68: Recognizing Long-Form Speech Using Streaming End-to-End Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.852086</td>
<td>0.755242</td>
<td><a href="https://www.semanticscholar.org/paper/12a628c04b8ee59c1893607469c6343ace6bb67c">0: Controlling the Noise Robustness of End-to-End Automatic Speech Recognition Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.842889</td>
<td>0.782220</td>
<td><a href="https://www.semanticscholar.org/paper/c6b61535f1544835cca3851ceb34222ebc5b4377">816: State-of-the-Art Speech Recognition with Sequence-to-Sequence Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.841411</td>
<td>0.822071</td>
<td><a href="https://www.semanticscholar.org/paper/af1047d15c7f60ece1c477cf7b860f13390fe5d3">1: End-to-End Deep Learning Speech Recognition Model for Silent Speech Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.838874</td>
<td>0.554761</td>
<td><a href="https://www.semanticscholar.org/paper/bc5249c2040d187e9dce01c76aa4687fb13d1ce7">1: Supervised Adaptation of Sequence-to-Sequence Speech Recognition Systems using Batch-Weighting</a></td>
</tr>
<tr>
<td>0</td>
<td>0.838513</td>
<td>0.643027</td>
<td><a href="https://www.semanticscholar.org/paper/d2a7a05cb01cf49a5cfc774f1a2962bcd6e1fe77">1: Dynamic Acoustic Unit Augmentation with BPE-Dropout for Low-Resource End-to-End Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.836055</td>
<td>0.694024</td>
<td><a href="https://www.semanticscholar.org/paper/d17089d9e1101ce54b4d1c54d888f769bea38803">0: Text and Synthetic Data for Domain Adaptation in End-to-End Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831053</td>
<td>0.712537</td>
<td><a href="https://www.semanticscholar.org/paper/db9c40b82875340dcbe95e5c68bd49ab4059ee7a">62: Wide Residual BLSTM Network with Discriminative Speaker Adaptation for Robust Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830083</td>
<td>0.814454</td>
<td><a href="https://www.semanticscholar.org/paper/4857da9c34e7374103c31b4d41414bcd82a4c2ae">3: Recent progress in deep end-to-end models for spoken language processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.877420</td>
<td>0.974770</td>
<td><a href="https://www.semanticscholar.org/paper/8ff840a40d3f1557c55c19d4d636da77103168ce">2179: Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin</a></td>
</tr>
<tr>
<td>0</td>
<td>0.773808</td>
<td>0.973225</td>
<td><a href="https://www.semanticscholar.org/paper/579e0077a3810510a7965224a8782ecc01766ea0">479: Achieving Human Parity in Conversational Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768597</td>
<td>0.955564</td>
<td><a href="https://www.semanticscholar.org/paper/edb1e4bd20731b292e36df7f80dc5c1ad61febb6">73: Transferring knowledge from a RNN to a DNN</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786120</td>
<td>0.952444</td>
<td><a href="https://www.semanticscholar.org/paper/5a7f3f0fdbdc29fddc7a41098ee8bbc3f7cfd1a1">132: Toward Human Parity in Conversational Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.777968</td>
<td>0.951683</td>
<td><a href="https://www.semanticscholar.org/paper/ac94ef90be9b0c3bf744d6744e47b38855f9a4c7">278: The microsoft 2016 conversational speech recognition system</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801866</td>
<td>0.949090</td>
<td><a href="https://www.semanticscholar.org/paper/e0b207e96351671453aa8bf05b7225c8a340a0b2">290: Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.695692</td>
<td>0.948767</td>
<td><a href="https://www.semanticscholar.org/paper/4b538a007f31c9ae884f24bd487f62784ed2d359">12: Neuron Activation Profiles for Interpreting Convolutional Speech Recognition Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.749242</td>
<td>0.941041</td>
<td><a href="https://www.semanticscholar.org/paper/da1231a3a7536010ddb6ef5e163a785d03974af1">58: Residual Convolutional CTC Networks for Automatic Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793973</td>
<td>0.939726</td>
<td><a href="https://www.semanticscholar.org/paper/6d1c0e1fb4b4c83e95b469a3f18695d96e5e8bfe">8: Towards End-to-End Speech Recognition with Deep Multipath Convolutional Neural Networks</a></td>
</tr>
</table></html>
