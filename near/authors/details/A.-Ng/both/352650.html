<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/80e9e3fc3670482c1fee16b2542061b779f47c4f">2412: Multimodal Deep Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.838097</td>
<td>0.589955</td>
<td><a href="https://www.semanticscholar.org/paper/4b8f5c922932377dd21d804183c2a870b6d628bc">2: Multimodal Co-learning: Challenges, Applications with Datasets, Recent Advances and Future Directions</a></td>
</tr>
<tr>
<td>1</td>
<td>0.823604</td>
<td>0.975492</td>
<td><a href="https://www.semanticscholar.org/paper/64bfeb1ddd35838706e4fffc469234cc2f215631">160: Improved Multimodal Deep Learning with Variation of Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.819117</td>
<td>0.854403</td>
<td><a href="https://www.semanticscholar.org/paper/544eac9bfda56052d3a996546f464618b34c2a0d">8: Cross-Modality Feature Learning via Convolutional Autoencoder</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790585</td>
<td>0.577380</td>
<td><a href="https://www.semanticscholar.org/paper/a243ee80146ca37fc296bc67043ea2a67222de68">11: Coordinated Joint Multimodal Embeddings for Generalized Audio-Visual Zero-shot Classification and Retrieval of Videos</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788801</td>
<td>0.582876</td>
<td><a href="https://www.semanticscholar.org/paper/243c42e3ab45dab37d6f05e90bb6ea44eebfc1d4">30: Deep Learning for Single-View Instance Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786735</td>
<td>0.812370</td>
<td><a href="https://www.semanticscholar.org/paper/41e6abf0d3607345949004521c301eaf52c26533">14: Deep Triplet Neural Networks with Cluster-CCA for Audio-Visual Cross-Modal Retrieval</a></td>
</tr>
<tr>
<td>0</td>
<td>0.749112</td>
<td>0.519476</td>
<td><a href="https://www.semanticscholar.org/paper/7bf4168f696923ea5566d3a1ced37772897e24bd">10: Surprising Effectiveness of Few-Image Unsupervised Feature Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.749107</td>
<td>0.433604</td>
<td><a href="https://www.semanticscholar.org/paper/fe591ed44d1cb10aee5a99cb4dcdca20aabcb3a5">7: Crossmodal learning for audio-visual speech event localization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.745679</td>
<td>0.542855</td>
<td><a href="https://www.semanticscholar.org/paper/016cbdf15b68692e8c47cd57f94fd8b03073bcc0">0: FusiformNet: Extracting Discriminative Facial Features on Different Levels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.839287</td>
<td>0.980983</td>
<td><a href="https://www.semanticscholar.org/paper/5726c7b40fcc454b77d989656c085520bf6c15fa">1481: Multimodal learning with deep Boltzmann machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.776969</td>
<td>0.954814</td>
<td><a href="https://www.semanticscholar.org/paper/c80d8286e8e50e832d4c7f39de84ed47b57a0fb6">172: Learning Representations for Multimodal Data with Deep Belief Nets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.708974</td>
<td>0.923789</td>
<td><a href="https://www.semanticscholar.org/paper/ca52604845b36d61be6b30f9b481f9136f202932">67: Multi-task deep neural network for multi-label learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803633</td>
<td>0.922850</td>
<td><a href="https://www.semanticscholar.org/paper/22f8a6b42f0ea6b7997d01d5e82d1b49bce1c613">8: Learning Joint Multimodal Representation Based on Multi-fusion Deep Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774630</td>
<td>0.913511</td>
<td><a href="https://www.semanticscholar.org/paper/512688b0b730a6083a282e52c6304d6f33b406b4">40: MDL-CW: A Multimodal Deep Learning Framework with CrossWeights</a></td>
</tr>
<tr>
<td>0</td>
<td>0.685104</td>
<td>0.913418</td>
<td><a href="https://www.semanticscholar.org/paper/39f525f231ea7c9ae335ffdd411c0a59bdf9c9e8">115: Correlational Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.620095</td>
<td>0.912736</td>
<td><a href="https://www.semanticscholar.org/paper/e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6">1198: Deep Canonical Correlation Analysis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758924</td>
<td>0.912000</td>
<td><a href="https://www.semanticscholar.org/paper/aced38f6fde9ecee39b545a05d9370ea8b86b658">11: Multimodal Learning via Exploring Deep Semantic Similarity</a></td>
</tr>
</table></html>
