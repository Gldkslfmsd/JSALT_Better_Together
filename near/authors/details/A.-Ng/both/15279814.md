<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>0</td>
<td>1.000000</td>
<td>0.979773</td>
<td><a href="https://www.semanticscholar.org/paper/7d2c07c0a2ce91ab9036cf7d1d7e577b7f00a391">6: An Application of Reinforcement Learning to Aerobatic Helicopter Flight</a></td>
</tr>
<tr>
<td>0</td>
<td>0.822245</td>
<td>0.986535</td>
<td><a href="https://www.semanticscholar.org/paper/2e4719a84d2a75421af5991d8c223c301401fdeb">14: Reinforcement Learning Applied to a Quadrotor Guidance Law in Autonomous Flight</a></td>
</tr>
<tr>
<td>0</td>
<td>0.822222</td>
<td>0.988213</td>
<td><a href="https://www.semanticscholar.org/paper/b6af99d5a7d0e39e8127089d248222b6432c83f2">15: Intelligent Control of a Quadrotor with Proximal Policy Optimization Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.819686</td>
<td>0.812364</td>
<td><a href="https://www.semanticscholar.org/paper/ad6e02ac7d26242197201f150737c2b7341501f3">0: Autonomous Acrobatic Flight Based on Feedforward Sequence Control for Small Unmanned Helicopter</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807038</td>
<td>0.951278</td>
<td><a href="https://www.semanticscholar.org/paper/47ae72d87889914f43910473ee0dda7f3241e562">3: Reinforcement learning for autonomous dynamic soaring in shear winds</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802393</td>
<td>0.931608</td>
<td><a href="https://www.semanticscholar.org/paper/073ff94af7c7df548482498f483bacbf47db0d3f">5: Reinforcement learning based neuro-control systems for an unmanned helicopter</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799530</td>
<td>0.540037</td>
<td><a href="https://www.semanticscholar.org/paper/1b812d6dc5059afec3998bb8be615ec703734a79">191: Adaptive Flight Control for an Autonomous Unmanned Helicopter</a></td>
</tr>
<tr>
<td>0</td>
<td>0.787827</td>
<td>0.988309</td>
<td><a href="https://www.semanticscholar.org/paper/b223b7d1dc76be5591bc261e9550ae4d168b6222">153: Reinforcement Learning for UAV Attitude Control</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784493</td>
<td>0.022822</td>
<td><a href="https://www.semanticscholar.org/paper/da3380eeb1a9e5a5314facc5e8d95bd0dac2ad10">0: From Demonstration to Flight: Realization of Autonomous Aerobatic Maneuvers for Fast, Miniature Fixed-Wing UAVs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781286</td>
<td>0.022822</td>
<td>NA:207550814</td>
</tr>
<tr>
<td>0</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/0bfbdafdfbcc268860fe54ae4d8f08d487bcc762">612: An Application of Reinforcement Learning to Aerobatic Helicopter Flight</a></td>
</tr>
<tr>
<td>0</td>
<td>0.886811</td>
<td>0.997739</td>
<td><a href="https://www.semanticscholar.org/paper/5e405b71a021238cb612bfc65b77baa09a245073">564: Autonomous Inverted Helicopter Flight via Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.648678</td>
<td>0.997327</td>
<td><a href="https://www.semanticscholar.org/paper/30d8e493ae35a64b2bebbe6ec90dc190488f82fa">230: Using inaccurate models in reinforcement learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.687985</td>
<td>0.996394</td>
<td><a href="https://www.semanticscholar.org/paper/17237d9d360d93f8ad80efd4d9a78e0a16d268a4">45: Real-World Reinforcement Learning via Multifidelity Simulators</a></td>
</tr>
<tr>
<td>0</td>
<td>0.699934</td>
<td>0.995923</td>
<td><a href="https://www.semanticscholar.org/paper/e5e2d2228a01b889cc836bd153cde3e933fc2b68">16: Hierarchical Reinforcement Learning for Robot Navigation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756455</td>
<td>0.995915</td>
<td><a href="https://www.semanticscholar.org/paper/84b23b154ef3083839a4da8c460a1e1c110ea63b">305: Autonomous helicopter control using reinforcement learning policy search methods</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705198</td>
<td>0.995874</td>
<td><a href="https://www.semanticscholar.org/paper/9d50ac653101495d289d436d9feba29ac17bb6c7">66: Policy search via the signed derivative</a></td>
</tr>
<tr>
<td>0</td>
<td>0.667104</td>
<td>0.995709</td>
<td><a href="https://www.semanticscholar.org/paper/65438e0ba226c1f97bd8a36333ebc3297b1a32fd">2073: Reinforcement learning in robotics: A survey</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829785</td>
<td>0.995551</td>
<td><a href="https://www.semanticscholar.org/paper/13e2d5c4d39bc58b42f9004e5b03905f847dfa0f">336: Autonomous Helicopter Flight via Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.572538</td>
<td>0.994438</td>
<td><a href="https://www.semanticscholar.org/paper/936a67aad36a9d9a7799237f0499d2f588d6e8ba">246: A comparison of direct and model-based reinforcement learning</a></td>
</tr>
</table></html>
