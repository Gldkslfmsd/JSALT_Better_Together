<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/10ae9a3d1e0874a50820766bd414f98e095cdd8a">11: WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804513</td>
<td>0.864045</td>
<td><a href="https://www.semanticscholar.org/paper/b04cd1045a10d054c110aa2e35832545115e4857">24: DurIAN: Duration Informed Attention Network for Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798768</td>
<td>0.906520</td>
<td><a href="https://www.semanticscholar.org/paper/72fc727e37d45fdbe61c6218cb2712a006b91697">28: Sequence-to-Sequence Singing Synthesis Using the Feed-Forward Transformer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.778954</td>
<td>0.270034</td>
<td><a href="https://www.semanticscholar.org/paper/aec10828eb24e3f4f4b19fe8cd954195f8af1df9">0: Automatic parameterization with WLP-based GIF-techniques</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772609</td>
<td>0.409908</td>
<td><a href="https://www.semanticscholar.org/paper/4eedfdbcc8c2ab493384b86f06aa931b782107a7">0: Towards Integrated Acoustic Models for Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767174</td>
<td>0.923884</td>
<td><a href="https://www.semanticscholar.org/paper/d9210563b5b6ce3186f05e5f68fe72f87cd8841f">18: Voice Conversion with Cyclic Recurrent Neural Network and Fine-tuned Wavenet Vocoder</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766678</td>
<td>0.441347</td>
<td><a href="https://www.semanticscholar.org/paper/678cba6df672a9160085b75d4e4294165e4bbed8">68: Recognizing Long-Form Speech Using Streaming End-to-End Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762827</td>
<td>-0.017098</td>
<td><a href="https://www.semanticscholar.org/paper/02732830418fadb28fc77b70fe1a7fe6100a05b1">0: MIST-Tacotron: End-to-End Emotional Speech Synthesis Using Mel-Spectrogram Image Style Transfer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762602</td>
<td>-0.017098</td>
<td><a href="https://www.semanticscholar.org/paper/ed86dd325d12c0e6916befc0fb1e30b89a95eec7">0: A novel framework for high-quality voice source analysis and synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756802</td>
<td>0.229575</td>
<td><a href="https://www.semanticscholar.org/paper/de5f88d3a965c260155f86facadabc817db27a20">19: Polyphonic Pitch Tracking with Deep Layered Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.780674</td>
<td>0.996980</td>
<td><a href="https://www.semanticscholar.org/paper/97cc958a940a1b33241da612745c8347d7acf6d7">65: Multi-Band Melgan: Faster Waveform Generation For High-Quality Text-To-Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.776034</td>
<td>0.995606</td>
<td><a href="https://www.semanticscholar.org/paper/250894a2b60ceeddb58ead4552fe782769e6e0b7">0: Guided-TTS: Text-to-Speech with Untranscribed Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738905</td>
<td>0.994411</td>
<td><a href="https://www.semanticscholar.org/paper/17a315a84390052433c541f68ef1606dd1d0b404">7: LVCNet: Efficient Condition-Dependent Modeling Network for Waveform Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782821</td>
<td>0.994188</td>
<td><a href="https://www.semanticscholar.org/paper/37e52ff4714c7a08900b518127e438a195b84611">346: MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734775</td>
<td>0.992976</td>
<td><a href="https://www.semanticscholar.org/paper/b5ea2021423259773f164f7fc2f735bcc9936db5">0: Text-free non-parallel many-to-many voice conversion using normalising flows</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821849</td>
<td>0.992949</td>
<td><a href="https://www.semanticscholar.org/paper/39b11c504dd62f8c57f492f54d5b2e219f955d12">48: WaveFlow: A Compact Flow-based Model for Raw Audio</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701298</td>
<td>0.992947</td>
<td><a href="https://www.semanticscholar.org/paper/240d7b85c61e931baa2d05a43310398dd75f4707">0: Improving Adversarial Waveform Generation based Singing Voice Conversion with Harmonic Signals</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723435</td>
<td>0.992879</td>
<td><a href="https://www.semanticscholar.org/paper/9eb3efb04f29b56950ad2524aecc6c259eb16be6">0: Guided-TTS: A Diffusion Model for Text-to-Speech via Classifier Guidance</a></td>
</tr>
<tr>
<td>0</td>
<td>0.681141</td>
<td>0.992765</td>
<td><a href="https://www.semanticscholar.org/paper/17cb81590dde7f2a9c4bcf70dd8ec2b9da7f4a6e">14: Adversarially Trained Multi-Singer Sequence-To-Sequence Singing Synthesizer</a></td>
</tr>
</table></html>
