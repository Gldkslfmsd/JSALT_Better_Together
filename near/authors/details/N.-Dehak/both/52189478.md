<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/adea6f4107ae7a03048b6e3f6d47b93a9f3c2707">70: Emotion Identification from Raw Speech Signals Using DNNs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.868313</td>
<td>0.821042</td>
<td><a href="https://www.semanticscholar.org/paper/239386aef53893c026cf12ab932d89feee9b7bb6">7: Speech emotion recognition using autoencoder bottleneck features and LSTM</a></td>
</tr>
<tr>
<td>1</td>
<td>0.848602</td>
<td>0.967796</td>
<td><a href="https://www.semanticscholar.org/paper/de47fc09bc8dcd032c8b3450a0b2a816c376e07e">183: Efficient Emotion Recognition from Speech Using Deep Learning on Spectrograms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845499</td>
<td>0.883531</td>
<td><a href="https://www.semanticscholar.org/paper/f0354c09656fb20736a83205b19f0b6ad556774e">86: Speech emotion recognition with deep convolutional neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.838367</td>
<td>0.755167</td>
<td><a href="https://www.semanticscholar.org/paper/9d40061a4d226596ba544c4f4e9738b43c62baee">0: A DCRNN-based ensemble classifier for speech emotion recognition in Odia language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.837950</td>
<td>0.882624</td>
<td><a href="https://www.semanticscholar.org/paper/e4e4e1a7953a0b21eafd61e669cbb35fbba92771">1: Speech Emotion Recognition by Combining a Unified First-Order Attention Network With Data Balance</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834632</td>
<td>0.945634</td>
<td><a href="https://www.semanticscholar.org/paper/bae6af06f88868d100ed574a6ac5c46b1ee94849">5: An Efficient Temporal Modeling Approach for Speech Emotion Recognition by Mapping Varied Duration Sentences into Fixed Number of Chunks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834485</td>
<td>0.910030</td>
<td><a href="https://www.semanticscholar.org/paper/eeadeb945deb3ec2f5665958d58a24b1484ba4fb">3: A Method upon Deep Learning for Speech Emotion Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825698</td>
<td>0.068965</td>
<td><a href="https://www.semanticscholar.org/paper/43687b94fa210e2ec83b1deb642a96299869ecb8">0: Multi-distributed Speech Emotion Recognition Based on Mel Frequency Cepstogram and Parameter Transfer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821142</td>
<td>0.423774</td>
<td><a href="https://www.semanticscholar.org/paper/d14ca6a7a0b9422e1f5273e3864aeac761d1b948">38: Transfer Linear Subspace Learning for Cross-Corpus Speech Emotion Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830022</td>
<td>0.973109</td>
<td><a href="https://www.semanticscholar.org/paper/7405c4b7888ae37422a23b973b35ffa234fff46b">44: Emotion Recognition from Variable-Length Speech Segments Using Deep Learning on Spectrograms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830110</td>
<td>0.972732</td>
<td><a href="https://www.semanticscholar.org/paper/35d5e7c09d4b2d5356bc19027a85e2329f7434c0">4: A Transfer Learning Method for Speech Emotion Recognition from Automatic Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812286</td>
<td>0.972129</td>
<td><a href="https://www.semanticscholar.org/paper/e89f5f08c76ac4bb2253acb5e1b949fab4a9daca">2: Removing Bias with Residual Mixture of Multi-View Attention for Speech Emotion Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813290</td>
<td>0.968364</td>
<td><a href="https://www.semanticscholar.org/paper/ca7fb00692339f9704b4a5201604889994825a42">154: Attentive Convolutional Neural Network Based Speech Emotion Recognition: A Study on the Impact of Input Features, Signal Length, and Acted Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767144</td>
<td>0.967718</td>
<td><a href="https://www.semanticscholar.org/paper/1ba4627a8f2bb21d37e03b56ce96ca7828c1ce4e">41: Advanced LSTM: A Study About Better Time Dependency Modeling in Emotion Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774328</td>
<td>0.964554</td>
<td><a href="https://www.semanticscholar.org/paper/cc819d381d282c6c1aac1154d30bf79b76020016">44: Attention-augmented End-to-end Multi-task Learning for Emotion Prediction from Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816187</td>
<td>0.963976</td>
<td><a href="https://www.semanticscholar.org/paper/75a50e9343d10d94263f7e69bc7654f35330b05a">2: End-to-end speech emotion recognition using a novel context-stacking dilated convolution neural network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759502</td>
<td>0.963554</td>
<td><a href="https://www.semanticscholar.org/paper/38d4ff584e2a1fbf86a3a6def3fbb4a15d3abb06">17: Efficient Arabic Emotion Recognition Using Deep Neural Networks</a></td>
</tr>
</table></html>
