<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/740f94e0325b67e6ff5efba0f5112c977e21a75a">36: Punctuation Prediction Model for Conversational Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.895544</td>
<td>0.863909</td>
<td><a href="https://www.semanticscholar.org/paper/11d00193f64586234fc28810cd326896ed7b0c7d">7: Punctuation prediction using a bidirectional recurrent neural network with part-of-speech tagging</a></td>
</tr>
<tr>
<td>0</td>
<td>0.850910</td>
<td>0.775421</td>
<td><a href="https://www.semanticscholar.org/paper/eb4dcab8fef0ece3f30ed6661847e68d7e7af223">5: Low Latency MaxEnt- and RNN-Based Word Sequence Models for Punctuation Restoration of Closed Caption Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.846664</td>
<td>0.883487</td>
<td><a href="https://www.semanticscholar.org/paper/cad80d9a6ba7c943da74be90c7d3302a2f463099">0: Joint Prediction of Truecasing and Punctuation for Conversational Speech in Low-Resource Scenarios</a></td>
</tr>
<tr>
<td>0</td>
<td>0.839453</td>
<td>0.835982</td>
<td><a href="https://www.semanticscholar.org/paper/1a9add9545acb8aca08b39184ce75502222cc523">18: Combination of NN and CRF models for joint detection of punctuation and disfluencies</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821779</td>
<td>0.018395</td>
<td><a href="https://www.semanticscholar.org/paper/ff4ffaeb9f50ddb8f6007f1caa49eca45bb221f6">0: RelNet: Relevance-Based Punctuation Prediction Network in Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813804</td>
<td>0.898748</td>
<td><a href="https://www.semanticscholar.org/paper/781fcadf8f8aa1b48eeb1034221d5162ecdf1396">1: FullStop: Multilingual Deep Models for Punctuation Prediction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812702</td>
<td>0.806001</td>
<td><a href="https://www.semanticscholar.org/paper/e86cd4e4fc5932015dbdfc3258d301a6b62bba1b">3: Improving Vietnamese Named Entity Recognition from Speech Using Word Capitalization and Punctuation Recovery Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802694</td>
<td>0.867052</td>
<td><a href="https://www.semanticscholar.org/paper/539a1a2d53549f6962a5e4adb3387aa02793010c">5: Recovering Capitalization for Automatic Speech Recognition of Vietnamese using Transformer and Chunk Merging</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801552</td>
<td>0.469440</td>
<td><a href="https://www.semanticscholar.org/paper/abda4230a654c786e327e8831deff46ff124ac8a">0: Comparison of Phonemic and Graphemic Word to Sub-Word Unit Mappings for Lithuanian Phone-Level Speech Transcription</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723154</td>
<td>0.982924</td>
<td><a href="https://www.semanticscholar.org/paper/c0f2ce69250fb1c995fec0fb2567ac495e1aefe6">29: End-to-End Neural Transformer Based Spoken Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.716584</td>
<td>0.982295</td>
<td><a href="https://www.semanticscholar.org/paper/bfdb69a3060f6352edb063d9b4caf0cebc831ed2">100: From Audio to Semantics: Approaches to End-to-End Spoken Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813714</td>
<td>0.981684</td>
<td><a href="https://www.semanticscholar.org/paper/e834c0ada1d5badb2451fdadb378d8bf502bc3e8">30: Self-attention Based Model for Punctuation Prediction Using Word and Speech Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802998</td>
<td>0.980919</td>
<td><a href="https://www.semanticscholar.org/paper/8d2941bf9f1a2a57c9029bbbb45aa16bf40bb1ca">15: Efficient Automatic Punctuation Restoration Using Bidirectional Transformers with Robust Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731749</td>
<td>0.979537</td>
<td><a href="https://www.semanticscholar.org/paper/ae916205cdae8210b147d7637f74186e57d15973">139: Towards End-to-end Spoken Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740419</td>
<td>0.977619</td>
<td><a href="https://www.semanticscholar.org/paper/49e628b162d7be2157354953d717dbbfecdea615">1: Towards End-to-End Integration of Dialog History for Improved Spoken Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.579102</td>
<td>0.977574</td>
<td><a href="https://www.semanticscholar.org/paper/500d148924f640b148264912a6f7916171eace99">71: Spoken Language Understanding without Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.761765</td>
<td>0.977491</td>
<td><a href="https://www.semanticscholar.org/paper/a2e20c8691cfa357fcfd6eb853f3a2df0350ff13">2: FANS: Fusing ASR and NLU for on-device SLU</a></td>
</tr>
<tr>
<td>0</td>
<td>0.700603</td>
<td>0.976703</td>
<td><a href="https://www.semanticscholar.org/paper/ed6262b569c0a62c51d941228c54f34e563af022">458: Japanese and Korean voice search</a></td>
</tr>
</table></html>
