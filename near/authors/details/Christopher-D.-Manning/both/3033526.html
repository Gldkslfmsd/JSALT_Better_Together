<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/32de44f01a96d4473d21099d15e25bc2b9f08e2f">2474: Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845354</td>
<td>0.953275</td>
<td><a href="https://www.semanticscholar.org/paper/4b9af9b9ed1bfb6b0688019d9fa79875bbcd8f3f">64: Long Short-Term Memory Over Tree Structures</a></td>
</tr>
<tr>
<td>1</td>
<td>0.839741</td>
<td>0.989204</td>
<td><a href="https://www.semanticscholar.org/paper/1f600f213dbbd70f06093438855f39022957b4bf">255: Long Short-Term Memory Over Recursive Structures</a></td>
</tr>
<tr>
<td>0</td>
<td>0.824471</td>
<td>0.890831</td>
<td><a href="https://www.semanticscholar.org/paper/e5aa997d3d24fa6c89613d270aa12fb12bb58881">2: On Continuous Space Word Representations as Input of LSTM Language Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.819445</td>
<td>0.750116</td>
<td><a href="https://www.semanticscholar.org/paper/bd6e3c5b931d61e71696d10962855244e619ac4f">0: SLDP: Sequence learning dependency parsing model using long short-term memory</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816299</td>
<td>0.954393</td>
<td><a href="https://www.semanticscholar.org/paper/cff79255a94b9b05a4ce893eb403a522e0923f04">128: Neural Semantic Encoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803010</td>
<td>0.816147</td>
<td><a href="https://www.semanticscholar.org/paper/32944621816d2b70d80c573f2397848a722e0651">18: Experiment Segmentation in Scientific Discourse as Clause-level Structured Prediction using Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799062</td>
<td>0.807889</td>
<td><a href="https://www.semanticscholar.org/paper/45e0a172e8986226c847a5ed0843c9c080eb442b">3: Sequential Recurrent Neural Networks for Language Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798860</td>
<td>0.725256</td>
<td><a href="https://www.semanticscholar.org/paper/c0db083c2e3b862824f9d3eee6908ffce0bfb8fd">103: Understanding LSTM - a tutorial into Long Short-Term Memory Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.797448</td>
<td>0.784383</td>
<td><a href="https://www.semanticscholar.org/paper/4ecf4356c3b451b16780788a3f94e422d4deeda5">35: Tree-structured Attention with Hierarchical Accumulation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831158</td>
<td>0.990106</td>
<td><a href="https://www.semanticscholar.org/paper/6b8b2075319accc23fef43e4cf76bc3682189d82">1082: Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.739960</td>
<td>0.988545</td>
<td><a href="https://www.semanticscholar.org/paper/e28ab7c3b994dd4e30baac1eb67c7f87e40c2b7b">745: Recurrent Neural Network for Text Classification with Multi-Task Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.563722</td>
<td>0.987979</td>
<td><a href="https://www.semanticscholar.org/paper/172d8e5ec0d75c587c85b2bc6f3fdc003d77b877">18: Chinese text classification based on attention mechanism and feature-enhanced fusion neural network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.704053</td>
<td>0.987666</td>
<td><a href="https://www.semanticscholar.org/paper/5a6ad89fa96a09e4cb9bd9519f7e5e2e3e71899c">51: A Hybrid Framework for Text Modeling with Convolutional RNN</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717682</td>
<td>0.987599</td>
<td><a href="https://www.semanticscholar.org/paper/7f3ae283243e15e05f188a05779ccfae9a3567f4">744: ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732567</td>
<td>0.987080</td>
<td><a href="https://www.semanticscholar.org/paper/6dab1c6491929d396e9e5463bc2e87af88602aa2">580: Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.844471</td>
<td>0.986963</td>
<td><a href="https://www.semanticscholar.org/paper/c68ec24e2f97c6875cd006a9fa2f0fbe934e4ae0">214: Bidirectional Long Short-Term Memory Networks for Relation Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738244</td>
<td>0.986573</td>
<td><a href="https://www.semanticscholar.org/paper/bfccb2d6e3d9f9b6bd8b14b2d4c6efa36c79341b">379: LSTM-based Deep Learning Models for non-factoid answer selection</a></td>
</tr>
</table></html>
