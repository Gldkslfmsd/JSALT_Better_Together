<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/fa07fa673d8c908e91d22c4566572a72548ccee9">521: Summarization beyond sentence extraction: A probabilistic approach to sentence compression</a></td>
</tr>
<tr>
<td>1</td>
<td>0.967023</td>
<td>0.998485</td>
<td><a href="https://www.semanticscholar.org/paper/25f51f4132626a645924b3c8b3edcbdcc35c48a3">471: Statistics-Based Summarization - Step One: Sentence Compression</a></td>
</tr>
<tr>
<td>0</td>
<td>0.835924</td>
<td>0.986501</td>
<td><a href="https://www.semanticscholar.org/paper/9d08213ede54c4e205d18b4400288831af918ec8">238: Headline Generation Based on Statistical Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834690</td>
<td>0.755660</td>
<td><a href="https://www.semanticscholar.org/paper/6beecdef1a4fdffea7b588f80db8ee3393a21479">6: Abstractive Document Summarization without Parallel Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.824342</td>
<td>0.642960</td>
<td><a href="https://www.semanticscholar.org/paper/ed32242d76f0f52e3eace19b0314868f1d868b89">23: The Summary Loop: Learning to Write Abstractive Summaries Without Examples</a></td>
</tr>
<tr>
<td>0</td>
<td>0.817124</td>
<td>0.869283</td>
<td><a href="https://www.semanticscholar.org/paper/eaafff7e211d6c70ac2ca3aeca2e9f8de3db0e14">17: Extractive summarisation via sentence removal: condensing relevant sentences into a short summary</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809548</td>
<td>0.836017</td>
<td><a href="https://www.semanticscholar.org/paper/73f54d963c9a79b4732aa368fc6077f3023a8bcc">4: A Supervised Method for Extractive Single Document Summarization Based on Sentence Embeddings and Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803257</td>
<td>0.654353</td>
<td><a href="https://www.semanticscholar.org/paper/3736715a5b9f3383bd359c6e1ed79d3a4ea258f6">10: Toward Better Storylines with Sentence-Level Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802113</td>
<td>0.684850</td>
<td><a href="https://www.semanticscholar.org/paper/0a16757391d70b8dc9269bf8b95291f920344b7d">0: An Examination of the CNN / DailyMail Neural Summarization Task</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799418</td>
<td>0.770903</td>
<td><a href="https://www.semanticscholar.org/paper/abf5fd90416d5f797753b2102436d0ad9a3c55d6">5: Regularized and Retrofitted models for Learning Sentence Representation with Context</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756617</td>
<td>0.997241</td>
<td><a href="https://www.semanticscholar.org/paper/5f9623a2959117dc05f2af3b961fd035a3f22d41">291: Sentence Reduction for Automatic Text Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760250</td>
<td>0.994373</td>
<td><a href="https://www.semanticscholar.org/paper/a89ac9902ccb889d096ec74f980fe8fc00940390">170: Supervised and Unsupervised Learning for Sentence Compression</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785989</td>
<td>0.993831</td>
<td><a href="https://www.semanticscholar.org/paper/0d8e3db6fcd99313773fcaa16074f2cc76ce1fef">112: Syntactic Simplification for Improving Content Selection in Multi-Document Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795283</td>
<td>0.992372</td>
<td><a href="https://www.semanticscholar.org/paper/4f90d821c32c71b6c78381e2e92cda15b8d693d7">19: Using spoken utterance compression for meeting summarization: A pilot study</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796267</td>
<td>0.992312</td>
<td><a href="https://www.semanticscholar.org/paper/f9ad221c2627e2b0d16edfa05e65656447e00b77">156: Multi-candidate reduction: Sentence compression as a tool for document summarization tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765532</td>
<td>0.992196</td>
<td><a href="https://www.semanticscholar.org/paper/ee5699c3792c63757771bbe9bdfa6ce2a98f8895">2: Concatenate the Most Likelihood Substring for Generating Vietnamese Sentence Reduction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788229</td>
<td>0.991911</td>
<td><a href="https://www.semanticscholar.org/paper/013846a1e7ef8e4733496a6260096b70bd259f0e">20: A French Human Reference Corpus for Multi-Document Summarization and Sentence Compression</a></td>
</tr>
<tr>
<td>0</td>
<td>0.715538</td>
<td>0.991898</td>
<td><a href="https://www.semanticscholar.org/paper/3ced0fc0279e7acaebe1e9a28bc1b2067a9fa85e">2: TALAA-ATSF: A Global Operation-Based Arabic Text Summarization Framework</a></td>
</tr>
</table></html>
