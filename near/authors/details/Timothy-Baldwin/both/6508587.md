<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/6cdc8599faba233298888e46929186b9d8b5fcb6">196: Automatically Constructing a Normalisation Dictionary for Microblogs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801929</td>
<td>0.798750</td>
<td><a href="https://www.semanticscholar.org/paper/035d8c558bb1885d970330d6a5ec53d7386e497d">2: Short-Text Lexical Normalisation on Industrial Log Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.769158</td>
<td>0.801326</td>
<td><a href="https://www.semanticscholar.org/paper/65a458a56cf13710bbf22cefc97355a97ad2f714">38: Normalising Slovene data: historical texts vs. user-generated content</a></td>
</tr>
<tr>
<td>0</td>
<td>0.763956</td>
<td>0.839892</td>
<td><a href="https://www.semanticscholar.org/paper/789f607281d77cf312d938989c0c573b32cfbe1d">5: PtiClic : A Game for Vocabulary Assessment combining JeuxDeMots and LSA</a></td>
</tr>
<tr>
<td>0</td>
<td>0.761936</td>
<td>0.909935</td>
<td><a href="https://www.semanticscholar.org/paper/fed9c628ca20ee16014626f8791e9d3b90acd91e">0: Natural Language Feature Selection via Cooccurrence</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760847</td>
<td>0.089515</td>
<td>NA:248507538</td>
</tr>
<tr>
<td>0</td>
<td>0.753890</td>
<td>0.808608</td>
<td><a href="https://www.semanticscholar.org/paper/d34d53f86e58973a77db7047929dbd07292c27ca">0: Creating a phraseme matrix based on a Tertium Comparationis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751513</td>
<td>0.558689</td>
<td><a href="https://www.semanticscholar.org/paper/6cfa8bc5733ceec0ccb82053222b1a298ed6e130">3: A Global Dictionary Based Approach to Fast Similar Text Search in Document Repository</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751160</td>
<td>0.905176</td>
<td><a href="https://www.semanticscholar.org/paper/0dfc5deff331a1910e0ad0a60f885ce01b824c12">1: Mining historical texts for diachronic spelling variants</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748258</td>
<td>0.927169</td>
<td><a href="https://www.semanticscholar.org/paper/23f8fa0b4a2db78a7a8dcc78494df8385b670f60">80: Support Vector Machines for Paraphrase Identification and Corpus Construction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801729</td>
<td>0.995895</td>
<td><a href="https://www.semanticscholar.org/paper/3de7ef76a010e624b47255b93bffa1a7c48e35a9">533: Lexical Normalisation of Short Text Messages: Makn Sens a #twitter</a></td>
</tr>
<tr>
<td>0</td>
<td>0.779293</td>
<td>0.993705</td>
<td><a href="https://www.semanticscholar.org/paper/2a9d787cbe29806bc05f5b0085cd3680dddb0455">166: Lexical normalization for social media text</a></td>
</tr>
<tr>
<td>0</td>
<td>0.593487</td>
<td>0.992609</td>
<td><a href="https://www.semanticscholar.org/paper/06ec0f2c46b11ed3c8c9f3eeae207135ed6a5807">5: Named entity recognition and normalization in tweets towards text summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.697890</td>
<td>0.991531</td>
<td><a href="https://www.semanticscholar.org/paper/18c4764e6f01f473672469fe9ecb04f64a89e2e5">18: Lexical normalization of roman Urdu text</a></td>
</tr>
<tr>
<td>0</td>
<td>0.706791</td>
<td>0.988585</td>
<td><a href="https://www.semanticscholar.org/paper/8aa5973918d75e606d0e46a3964b2cbb429ebf82">2: Twitter Normalization via 1-to-N Recovering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.709733</td>
<td>0.987214</td>
<td><a href="https://www.semanticscholar.org/paper/31f68a564c3159d41ae8ede367e9ca7f7b9968aa">146: A Broad-Coverage Normalization System for Social Media Language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.651082</td>
<td>0.987135</td>
<td><a href="https://www.semanticscholar.org/paper/ca05f01d475a1172891b614c8f7e4d3ba72c1161">14: Bekli:A Simple Approach to Twitter Text Normalization.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.680867</td>
<td>0.986328</td>
<td><a href="https://www.semanticscholar.org/paper/acdf5b1c37bb44e27f3bbac26f454f42b292aa91">15: Part of Speech Tagging for French Social Media Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.764244</td>
<td>0.985722</td>
<td><a href="https://www.semanticscholar.org/paper/1741c93e4270019e368a3b93eee21174f6f34974">8: USZEGED: Correction Type-sensitive Normalization of English Tweets Using Efficiently Indexed n-gram Statistics</a></td>
</tr>
</table></html>
