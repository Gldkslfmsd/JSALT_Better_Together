{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from collections import defaultdict, namedtuple\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce8d03d",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ad0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://bert-gcn-for-paper-citation.s3.ap-northeast-2.amazonaws.com/PeerRead/full_context_PeerRead.csv',\n",
    "                           'full_context_PeerRead.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fb0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_context_PeerRead.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52fc622",
   "metadata": {},
   "source": [
    "## Resolve arXiv ids to Sem Scho Corpus IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b39c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "PeerRead_to_SemanticScholar_Ids = defaultdict(lambda: [None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_by_ids(ids):\n",
    "    r = requests.post(\n",
    "        'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "        params={'fields': 'referenceCount,citationCount,title,corpusId'},\n",
    "        json={\"ids\": ids}\n",
    "    )\n",
    "    \n",
    "    assert len(r.json()) == len(ids)\n",
    "    \n",
    "    semanticScholarIDs = [x[\"corpusId\"] if isinstance(x, dict) else None for x in r.json()]\n",
    "\n",
    "    return(semanticScholarIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82807757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map source papers to Corpus Ids\n",
    "for i in tqdm(range(0, len(df), 500), total=len(df)//500+1):\n",
    "\n",
    "    ids = ['ARXIV:'+x.replace('v1', '') for x in df['source_id'].iloc[i:i+500].tolist()]\n",
    "\n",
    "    semanticScholarIDs = get_paper_by_ids(ids)\n",
    "    for j in range(0, len(ids), 1):\n",
    "        PeerRead_to_SemanticScholar_Ids[i+j][0] = semanticScholarIDs[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e835e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map target papers to Corpus Ids\n",
    "for i in tqdm(range(0, len(df), 500), total=len(df)//500+1):\n",
    "\n",
    "    ids = ['ARXIV:'+x.replace('v1', '') for x in df['target_id'].iloc[i:i+500].tolist()]\n",
    "\n",
    "    semanticScholarIDs = get_paper_by_ids(ids)\n",
    "    for j in range(0, len(ids), 1):\n",
    "        PeerRead_to_SemanticScholar_Ids[i+j][1] = semanticScholarIDs[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to df\n",
    "srcSemanticScholarIds = [x[0] for x in PeerRead_to_SemanticScholar_Ids.values()]\n",
    "tgtSemanticScholarIds = [x[1] for x in PeerRead_to_SemanticScholar_Ids.values()]\n",
    "\n",
    "df['source_semscho_id'] = srcSemanticScholarIds\n",
    "df['target_semscho_id'] = tgtSemanticScholarIds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cc466",
   "metadata": {},
   "source": [
    "## Search any unmapped papers by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "missedsrc_idx_to_name = {}\n",
    "for idx, x in df[['source_title', 'source_semscho_id']].iterrows():\n",
    "    if isinstance(x['source_semscho_id'], float) and np.isnan(x['source_semscho_id']):\n",
    "        missedsrc_idx_to_name[idx] = x['source_title']\n",
    "    \n",
    "        \n",
    "missedtgt_idx_to_name = {}\n",
    "\n",
    "for idx, x in df[['target_title', 'target_semscho_id']].iterrows():\n",
    "    if isinstance(x['target_semscho_id'], float) and np.isnan(x['target_semscho_id']):\n",
    "        missedtgt_idx_to_name[idx] = x['target_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da604cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_missed_src = set(missedsrc_idx_to_name.values())\n",
    "unique_missed_tgt = set(missedtgt_idx_to_name.values())\n",
    "unique_missed_all = sorted(list(unique_missed_src.union(unique_missed_tgt)))\n",
    "missed_name_to_semid = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0627d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_by_name(paper_name):\n",
    "    url = 'https://api.semanticscholar.org/graph/v1/paper/search?query='\n",
    "    q_name = paper_name.replace('-', ' ')\n",
    "    fields = q_name.rstrip().split('\\t')\n",
    "    suffix = '\\t' + '\\t'.join(fields)\n",
    "    cmd = url + urllib.parse.quote(fields[0]) + '&limit=1'\n",
    "    j = requests.get(cmd).json()\n",
    "    return(j)\n",
    "    \n",
    "for name in tqdm([name for name in unique_missed_all if name not in missed_name_to_semid]):\n",
    "    if name in missed_name_to_semid:\n",
    "        continue\n",
    "    \n",
    "    while True:\n",
    "        j = get_paper_by_name(name)\n",
    "        \n",
    "        if 'data' in j and j['data']:\n",
    "            missed_name_to_semid[name] = j['data'][0]['paperId']\n",
    "            break\n",
    "            \n",
    "        elif 'code' in j and j['code'] == '429':\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            print(f'Failed to find Sem Scho mapping for {name}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08855ed6",
   "metadata": {},
   "source": [
    "## Sem Scho name search gives us ids, but we need CorpusIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ac01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "semhashes_to_resolve = list(missed_name_to_semid.values())\n",
    "semhashs_to_resolve_to_semids = {}\n",
    "\n",
    "for i in tqdm(range(0, len(semhashes_to_resolve), 100), total=len(semhashes_to_resolve)//100+1):\n",
    "\n",
    "    ids = [x for x in semhashes_to_resolve[i:i+100]]\n",
    "    \n",
    "    semanticScholarIDs = get_paper_by_ids(ids)\n",
    "    for j in range(0, len(ids), 1):\n",
    "        semhashs_to_resolve_to_semids[ids[j]] = semanticScholarIDs[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ad090",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in missedsrc_idx_to_name:\n",
    "    df.iloc[idx, df.columns.get_loc('source_semscho_id')] = semhashs_to_resolve_to_semids[missed_name_to_semid[missedsrc_idx_to_name[idx]]]\n",
    "\n",
    "for idx in missedtgt_idx_to_name:\n",
    "    df.iloc[idx, df.columns.get_loc('target_semscho_id')] = semhashs_to_resolve_to_semids[missed_name_to_semid[missedtgt_idx_to_name[idx]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afbfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'source_year': 'int32', 'source_semscho_id': 'int32', 'target_semscho_id': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0dbee",
   "metadata": {},
   "source": [
    "## Now run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers from https://github.com/kwchurch/JSALT_Better_Together/blob/main/src/create_rotation_matrix.py\n",
    "\n",
    "def record_size_from_dir(dir):\n",
    "    with open(dir + '/record_size', 'r') as fd:\n",
    "        return int(fd.read().split('\\t')[0])\n",
    "\n",
    "def map_from_dir(dir):\n",
    "    fn = dir + '/map.old_to_new.i'\n",
    "    fn_len = os.path.getsize(fn)\n",
    "    return np.memmap(fn, dtype=np.int32, shape=(int(fn_len/4)), mode='r')\n",
    "\n",
    "def embedding_from_dir(dir, K):\n",
    "    fn = dir + '/embedding.f'\n",
    "    fn_len = os.path.getsize(fn)\n",
    "    return np.memmap(fn, dtype=np.float32, shape=(int(fn_len/(4*K)), K), mode='r')\n",
    "\n",
    "def directory_to_config(dir):\n",
    "    K = record_size_from_dir(dir)\n",
    "    return { 'record_size' : K,\n",
    "             'dir' : dir,\n",
    "             'map' : map_from_dir(dir),\n",
    "             'embedding' : embedding_from_dir(dir, K)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa27d8",
   "metadata": {},
   "source": [
    "## Set paths to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "specter = '/data2/jsalt2023/data/semantic_scholar/embeddings/specter'\n",
    "proposed = '/data2/jsalt2023/data/semantic_scholar/embeddings/proposed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = specter, proposed\n",
    "\n",
    "configs = [directory_to_config(d) for d in inputs]\n",
    "\n",
    "map0 = configs[0]['map']\n",
    "emb0 = configs[0]['embedding']\n",
    "\n",
    "map1 = configs[1]['map']\n",
    "emb1 = configs[1]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91338c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "sample = namedtuple('sample', 'src tgt')\n",
    "# build a named_tuple of idx:[src, tgt]\n",
    "def sem_scho_ids_to_dataset(src_to_tgt_sem_scho_ids):\n",
    "    dataset = {}\n",
    "    for i, (src, tgt) in enumerate(src_to_tgt_sem_scho_ids.items()):\n",
    "        dataset[i] = sample(src, tgt)\n",
    "    return(dataset)\n",
    "\n",
    "small_index = namedtuple('small_index', 'index idx_to_semscho_id')\n",
    "# build a small index which contains all target semscho embs normed and a mapping from the semscho_id to the index\n",
    "def build_small_index(sem_sco_ids, map_, emb_):\n",
    "    semscho_ids_mapped = {i:map_[i] for i in sem_sco_ids if i < len(map_)}\n",
    "    semscho_ids_failed = [i for i in sem_sco_ids if i >= len(map_)]\n",
    "    \n",
    "    semscho_ids_to_local = {i:l for l,i in enumerate(semscho_ids_mapped.keys())}\n",
    "    local_to_semscho_ids = {l:i for i,l in semscho_ids_to_local.items()}\n",
    "\n",
    "    all_embs = [emb_[map_[local_to_semscho_ids[i]]] for i in range(len(local_to_semscho_ids))]\n",
    "    all_embs_normed = np.vstack([e/np.linalg.norm(e) for e in all_embs])\n",
    "    \n",
    "    return small_index(all_embs_normed, local_to_semscho_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635b00c",
   "metadata": {},
   "source": [
    "## From https://arxiv.org/pdf/1903.06464.pdf , test set is >= 2017 publication date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03525506",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['source_year']>=2017]\n",
    "src_to_tgt_sem_scho_ids = dict(zip(test_df.source_semscho_id, test_df.target_semscho_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method, use_map, use_emb in (('specter', map0, emb0), ('proposed', map1, emb1)):\n",
    "    dataset = sem_scho_ids_to_dataset(src_to_tgt_sem_scho_ids)\n",
    "    all_tgts = [s.tgt for s in dataset.values()]\n",
    "    smaller_index = build_small_index(all_tgts, use_map, use_emb)\n",
    "    \n",
    "    count = 0\n",
    "    top_1_score = 0\n",
    "    top_5_score = 0\n",
    "    top_10_score = 0\n",
    "\n",
    "    for idx, s in dataset.items():\n",
    "        try:\n",
    "            src_emb = use_emb[use_map[s.src]]\n",
    "            src_emb_normed = src_emb/np.linalg.norm(src_emb)\n",
    "            search = np.inner(smaller_index.index, src_emb_normed)\n",
    "            search_top_10 = np.argpartition(search, -10)[-10:]\n",
    "            search_top_10_sorted = search_top_10[np.argsort(search[search_top_10])][::-1]\n",
    "            search_top_10_sorted_mapped = [smaller_index.idx_to_semscho_id[i] for i in search_top_10_sorted]\n",
    "\n",
    "            top_1_name = df[df['target_semscho_id']==search_top_10_sorted_mapped[0]].iloc[0]['target_title']\n",
    "            y_name =  df[df['target_semscho_id']==s.tgt].iloc[0]['target_title']\n",
    "\n",
    "            top_1_score += s.tgt in search_top_10_sorted_mapped[:1]\n",
    "            top_5_score += s.tgt in search_top_10_sorted_mapped[:5]\n",
    "            top_10_score += s.tgt in search_top_10_sorted_mapped[:10]\n",
    "\n",
    "            count += 1\n",
    "        except:\n",
    "            print('failed with id:', sample.src)\n",
    "    print(f'With method {method}:')\n",
    "    print(f'R@1: {round(top_1_score/count, 3)}')\n",
    "    print(f'R@5: {round(top_5_score/count, 3)}')\n",
    "    print(f'R@10: {round(top_10_score/count, 3)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b9d87-b8e9-4824-97a8-510d89cbdee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0111c9c-0a75-4ea4-86ab-a1c89ff1d80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2136195-d826-465e-a53d-eecfa8fe0c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79788f40-55b8-411e-ad67-d07ef6d862b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
