<html><table><tr>
<th>Method</th>
<th>cosS</th>
<th>cosP</th>
<th>paper</th>
</tr>
<tr>
<td>Specter</td>
<td>1.000</td>
<td>1.000</td>
<td><a href="https://www.semanticscholar.org/paper/cc27ec53160d88c25fc5096c0df65536eb780de4">186: Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.882</td>
<td>0.922</td>
<td><a href="https://www.semanticscholar.org/paper/afc3b39d8aa0100d7aeb6123668a9bec9bd6c63e">20: Adapting Neural Single-Document Summarization Model for Abstractive Multi-Document Summarization: A Pilot Study</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.879</td>
<td>0.986</td>
<td><a href="https://www.semanticscholar.org/paper/6e6a2fe517b33e1f29d761ae31fb37ddccb9a213">27: A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.853</td>
<td>0.718</td>
<td><a href="https://www.semanticscholar.org/paper/1100064b1e68e15d4dfadfcaf1d0d037c5b3786d">45: Multi-Document Summarization Based on Two-Level Sparse Representation Model</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.851</td>
<td>0.991</td>
<td><a href="https://www.semanticscholar.org/paper/56214030211d3c0212fc0da9b97735ead9021cc5">17: Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.849</td>
<td>0.992</td>
<td><a href="https://www.semanticscholar.org/paper/438d06e0acd4eae9cbd04d097afcc0acbf4ce840">0: Read Top News First: A Document Reordering Approach for Multi-Document News Summarization</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.846</td>
<td>0.787</td>
<td><a href="https://www.semanticscholar.org/paper/8206e427d56419589a2eddaf9d64eecbbc6d3c59">11: Reader-Aware Multi-Document Summarization: An Enhanced Model and The First Dataset</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.838</td>
<td>0.977</td>
<td><a href="https://www.semanticscholar.org/paper/762566ed2d82a589602310ccda884899a333c2a7">0: HowSumm: A Multi-Document Summarization Dataset Derived from WikiHow Articles</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.837</td>
<td>0.915</td>
<td><a href="https://www.semanticscholar.org/paper/b83d4e448e5049c51b7746ac52f3cb3912be6a54">13: Unsupervised Aspect-Based Multi-Document Abstractive Summarization</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.834</td>
<td>0.687</td>
<td><a href="https://www.semanticscholar.org/paper/3d14419b1a75f19fe03b2972b913681a60f8fe11">2: Learning to Estimate the Importance of Sentences for Multi-Document Summarization</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.828</td>
<td>0.262</td>
<td><a href="https://www.semanticscholar.org/paper/b0087199f39f83b9387a66afd8fa6abd1bc83f7e">5: Multi-document summarization based on hierarchical topic model</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.828</td>
<td>-0.035</td>
<td><a href="https://www.semanticscholar.org/paper/d150a5fc6b342d91703e97cc7c298c68aac92656">0: A Systematic Survey on Multi-document Text Summarization</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.827</td>
<td>0.747</td>
<td><a href="https://www.semanticscholar.org/paper/bf2a8312cb8857690d2db741a26eb099c6badf4d">9: Extractive Summarization: Limits, Compression, Generalized Model and Heuristics</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.825</td>
<td>0.414</td>
<td><a href="https://www.semanticscholar.org/paper/c16734c811d6fc3e7f00947d5e1a112bff9fdcb8">3: Extraction Based Multi Document Summarization using Single Document Summary Cluster</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.825</td>
<td>0.798</td>
<td><a href="https://www.semanticscholar.org/paper/10a16c9c47b275c3ff5b5a28e268e1531d5cc2cd">13: Extractive Summarization: Limits, Compression, Generalized Model and Heuristics</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.824</td>
<td>0.807</td>
<td><a href="https://www.semanticscholar.org/paper/332c830987c32855c12be9d6d7a2a3ff3f84a294">7: Unity in Diversity: Learning Distributed Heterogeneous Sentence Representation for Extractive Summarization</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.824</td>
<td>0.763</td>
<td><a href="https://www.semanticscholar.org/paper/f8aa42ed529055ee728d7db6999c39968b364898">1: A Multi-View Abstractive Summarization Model Jointly Considering Semantics and Sentiment</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.822</td>
<td>0.991</td>
<td><a href="https://www.semanticscholar.org/paper/40345901fd28cbf65791c34671db6548b1089ed4">75: BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.821</td>
<td>0.968</td>
<td><a href="https://www.semanticscholar.org/paper/2fdf58255aa7d15635cd562ee0244fc802438d34">95: Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization</a></td>
</tr>
<tr>
<td>Specter</td>
<td>0.816</td>
<td>0.625</td>
<td><a href="https://www.semanticscholar.org/paper/df848352dd12699b9396b7813d0a810af51e4e9a">42: Combining Syntax and Semantics for Automatic Extractive Single-Document Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>1.000</td>
<td>1.000</td>
<td><a href="https://www.semanticscholar.org/paper/cc27ec53160d88c25fc5096c0df65536eb780de4">186: Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.727</td>
<td>0.999</td>
<td><a href="https://www.semanticscholar.org/paper/929b4775b6896634e11a8feb0ca4ca64ef7b3e24">136: Extractive Summarization as Text Matching</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.807</td>
<td>0.998</td>
<td><a href="https://www.semanticscholar.org/paper/853d4d94651c6d9f8ed4d114e1eb21f15f786daa">284: A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.767</td>
<td>0.997</td>
<td><a href="https://www.semanticscholar.org/paper/0ac7c7279f52e8cc98171254534276d9644cf92c">51: Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.797</td>
<td>0.997</td>
<td><a href="https://www.semanticscholar.org/paper/51955c4b4c659e30055653ac4c2ed9208c2a9c74">5: Text Summarization with Latent Queries</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.769</td>
<td>0.997</td>
<td><a href="https://www.semanticscholar.org/paper/aa28873534c24e4a8c5deb7bff723cd5fc69a6f0">39: QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.717</td>
<td>0.997</td>
<td><a href="https://www.semanticscholar.org/paper/8d89f85b5f8a1d65b4e93a7ebb793618641c3ece">71: Assessing The Factual Accuracy of Generated Text</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.776</td>
<td>0.996</td>
<td><a href="https://www.semanticscholar.org/paper/7d1ba1bf305081cdf89f885cb63cd0424b632179">1: Multi-Perspective Abstractive Answer Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.796</td>
<td>0.996</td>
<td><a href="https://www.semanticscholar.org/paper/7cc730da554003dda77796d2cb4f06da5dfd5592">169: Hierarchical Transformers for Multi-Document Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.695</td>
<td>0.996</td>
<td><a href="https://www.semanticscholar.org/paper/7f6a5c6fa60c8a3c02ce455dd932f0f452424259">1: Learning to Revise References for Faithful Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.835</td>
<td>0.996</td>
<td><a href="https://www.semanticscholar.org/paper/2e4139b609ef300b68aa52ebcf1dd217d71c2f2f">0: MiRANews: Dataset and Benchmarks for Multi-Resource-Assisted News Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.712</td>
<td>0.995</td>
<td><a href="https://www.semanticscholar.org/paper/367c41f623f86e75d3154f6cab5b749cb7eb06b5">73: Searching for Effective Neural Extractive Summarization: What Works and What’s Next</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.798</td>
<td>0.995</td>
<td><a href="https://www.semanticscholar.org/paper/76037594f29a663fbd2799de2e5c7463c02a8a1d">96: Discourse-Aware Neural Extractive Text Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.803</td>
<td>0.995</td>
<td><a href="https://www.semanticscholar.org/paper/08de75945cbaee6e11fb9636a12df81cafcef195">0: Improving Multi-Document Summarization through Referenced Flexible Extraction with Credit-Awareness</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.740</td>
<td>0.995</td>
<td><a href="https://www.semanticscholar.org/paper/203b543bfa1e564bb80ff4229b43174d7c71b0c0">202: HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.750</td>
<td>0.995</td>
<td><a href="https://www.semanticscholar.org/paper/cfa90e184cab9701a68e9b2fdd9222a1f508a354">21: Efficient Adaptation of Pretrained Transformers for Abstractive Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.691</td>
<td>0.995</td>
<td><a href="https://www.semanticscholar.org/paper/26225f6c964fdd61c6c127836ed1bb38e705a69a">0: The Right to Remain Plain: Summarization and Simplification of Legal Documents</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.783</td>
<td>0.995</td>
<td><a href="https://www.semanticscholar.org/paper/305b2cf37e5dece81e95c92883d5a6e28ac93b22">463: Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.823</td>
<td>0.995</td>
<td><a href="https://www.semanticscholar.org/paper/4e346eb1628df6a12c1a121f862fb3a16c6fec60">266: Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies</a></td>
</tr>
<tr>
<td>Proposed</td>
<td>0.804</td>
<td>0.994</td>
<td><a href="https://www.semanticscholar.org/paper/8668e48b0032664af00e58e0c7774ddde17ffd7e">0: Document Summarization with Latent Queries</a></td>
</tr>
</table></html>
