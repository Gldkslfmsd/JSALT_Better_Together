<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/02218fcd3aece5a7bd19255d74b12f63dfa5c1a7">48: ShapeWorld - A new test methodology for multimodal language understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810912</td>
<td>0.734786</td>
<td><a href="https://www.semanticscholar.org/paper/49f802f99abf9595b79ece192ba1eb31c9c9ab8c">0: Challenges in Procedural Multimodal Machine Comprehension: A Novel Way To Benchmark</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766760</td>
<td>0.888397</td>
<td><a href="https://www.semanticscholar.org/paper/6b4a24ee122cac55b3a8b6a1cf7080244cbdf4ba">1: A new dataset and model for learning to understand navigational instructions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759119</td>
<td>0.856040</td>
<td><a href="https://www.semanticscholar.org/paper/6ac33d3dcecbed17580509a34bccdff2425f7ed8">148: Learning Conditioned Graph Structures for Interpretable Visual Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.744268</td>
<td>0.202828</td>
<td><a href="https://www.semanticscholar.org/paper/14647b6fcc52f68fffc593070be7068fd3f57d7f">0: Contrastive Attribution with Feature Visualization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740051</td>
<td>0.769286</td>
<td><a href="https://www.semanticscholar.org/paper/69078af65fc934f81fd340e9d1323d6c08194548">0: Revisiting the Compositional Generalization Abilities of Neural Sequence Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737425</td>
<td>0.747950</td>
<td><a href="https://www.semanticscholar.org/paper/fe16c9d223dc09dc8e027d1b441f2845c00363a6">0: On Advances in Text Generation from Images Beyond Captioning: A Case Study in Self-Rationalization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736333</td>
<td>0.614557</td>
<td><a href="https://www.semanticscholar.org/paper/2cf6b719b5a0e7274864c427925a62e30de3fd0e">8: Evaluating neural network explanation methods using hybrid documents and morphological prediction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736215</td>
<td>0.961725</td>
<td><a href="https://www.semanticscholar.org/paper/90800d28c61854659fd8d813158ecac5653695fa">11: Object Ordering with Bidirectional Matchings for Visual Reasoning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.735677</td>
<td>0.667075</td>
<td><a href="https://www.semanticscholar.org/paper/0f22f4fa7aa9194615ebcd2960eca047e761486e">10: Using Paraphrasing and Memory-Augmented Models to Combat Data Sparsity in Question Interpretation with a Virtual Patient Dialogue System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734951</td>
<td>0.978763</td>
<td><a href="https://www.semanticscholar.org/paper/cef77310f326bd30b172459dbecaedf228fc7b23">45: Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719354</td>
<td>0.977005</td>
<td><a href="https://www.semanticscholar.org/paper/5a2c87cf55fd96a5ebac6b73ee8741b8bd7f8833">1: Neural Event Semantics for Grounded Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691767</td>
<td>0.974044</td>
<td><a href="https://www.semanticscholar.org/paper/c792eebc581a3acf387aaa13626173032f79b706">6: How clever is the FiLM model, and how clever can it be?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.729567</td>
<td>0.968993</td>
<td><a href="https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2">728: Neural Module Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.735017</td>
<td>0.966232</td>
<td><a href="https://www.semanticscholar.org/paper/302ae0d991d62dee82b63530b487a50469810af4">51: Learning Interpretable Spatial Operations in a Rich 3D Blocks World</a></td>
</tr>
<tr>
<td>0</td>
<td>0.695876</td>
<td>0.963693</td>
<td><a href="https://www.semanticscholar.org/paper/797a4a72d1e8ec301d64fbb0c643b56562cbb133">0: Neural Abstructions: Abstractions that Support Construction for Grounded Language Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.692602</td>
<td>0.963431</td>
<td><a href="https://www.semanticscholar.org/paper/83530220b52280e857a81cc9f8774e92bb6817c3">1: Learning Multi-Step Spatio-Temporal Reasoning with Selective Attention Memory Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.706657</td>
<td>0.962849</td>
<td><a href="https://www.semanticscholar.org/paper/c48f5af4fc9b858d25316fb04ca5b50b3090fa44">0: Obj 1 Obj 2 Obj 3 Obj 4 Sphere Concept Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752512</td>
<td>0.962310</td>
<td><a href="https://www.semanticscholar.org/paper/0d45e411a7b588b70b82f22b04c7ccfaef0e3fd7">0: SYSTEMATIC GENERALIZATION: WHAT IS REQUIRED</a></td>
</tr>
</table></html>
