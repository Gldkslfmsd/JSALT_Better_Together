<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/990a7b4eceedb6e053e6386269481bdfc42a1094">608: CoQA: A Conversational Question Answering Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.876814</td>
<td>0.993716</td>
<td><a href="https://www.semanticscholar.org/paper/bb77ab10ad9831fc9f1bb51a85006c50b7c1d643">3: BERT-CoQAC: BERT-Based Conversational Question Answering in Context</a></td>
</tr>
<tr>
<td>0</td>
<td>0.873696</td>
<td>0.990072</td>
<td><a href="https://www.semanticscholar.org/paper/a8c4ea447b6dc6a0963063f53579dfc5c5cabdfc">3: Conversational QA for FAQs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.859369</td>
<td>0.918054</td>
<td><a href="https://www.semanticscholar.org/paper/561564941c60a58bb277841090a7e2ac8c2309c4">21: Interconnected Question Generation with Coreference Alignment and Conversation Flow Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.846031</td>
<td>0.077198</td>
<td><a href="https://www.semanticscholar.org/paper/019f7f3ac989411c023ab02ca731fc13d9a9c447">186: Beyond Question-Answering.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845170</td>
<td>0.702878</td>
<td><a href="https://www.semanticscholar.org/paper/3b89354126a5353665cf27ea0e833bf6f31061cf">4: Learning to Align Question and Answer Utterances in Customer Service Conversation with Recurrent Pointer Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.844314</td>
<td>0.607802</td>
<td><a href="https://www.semanticscholar.org/paper/c2a9db214f2954109a1d45885a0fd87efb624685">10: Learning to Extract Conditional Knowledge for Question Answering using Dialogue</a></td>
</tr>
<tr>
<td>0</td>
<td>0.840524</td>
<td>0.986779</td>
<td><a href="https://www.semanticscholar.org/paper/97b35d9f40e30cafc5673a30f82c77d7af608f90">1: A Graph-guided Multi-round Retrieval Method for Conversational Open-domain Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.840233</td>
<td>0.392952</td>
<td><a href="https://www.semanticscholar.org/paper/20d57bad971bd113d605b19c15b5d69f7ce95343">1: Discourse Based Advancement On Question Answering System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831635</td>
<td>0.320272</td>
<td><a href="https://www.semanticscholar.org/paper/6689366257393fac671063b7f980d006f579db25">4: Evaluation Protocol and Tools for Question-Answering on Speech Transcripts</a></td>
</tr>
<tr>
<td>0</td>
<td>0.868683</td>
<td>0.999411</td>
<td><a href="https://www.semanticscholar.org/paper/39e734da43eb8c72e9549b42e96760545036f8e5">428: QuAC: Question Answering in Context</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799950</td>
<td>0.998251</td>
<td><a href="https://www.semanticscholar.org/paper/d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a">338: The NarrativeQA Reading Comprehension Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.718101</td>
<td>0.997906</td>
<td><a href="https://www.semanticscholar.org/paper/8f1c9b656157b1d851563fb42129245701d83175">70: Transforming Question Answering Datasets Into Natural Language Inference Datasets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758489</td>
<td>0.997843</td>
<td><a href="https://www.semanticscholar.org/paper/3eda43078ae1f4741f09be08c4ecab6229046a5c">579: NewsQA: A Machine Comprehension Dataset</a></td>
</tr>
<tr>
<td>0</td>
<td>0.671253</td>
<td>0.997654</td>
<td><a href="https://www.semanticscholar.org/paper/0a5606f0d56c618aa610cb1677e2788a3bd678fa">67: A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742003</td>
<td>0.997511</td>
<td><a href="https://www.semanticscholar.org/paper/3adff57fd09965224506a1bacc0579d9d3c8c11e">303: SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801099</td>
<td>0.997056</td>
<td><a href="https://www.semanticscholar.org/paper/b2821ea94b1a7645a8befabce3a161473eb2e965">78: Unsupervised Question Answering by Cloze Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809746</td>
<td>0.996901</td>
<td><a href="https://www.semanticscholar.org/paper/6ff68b34a5f78bdd14437fe5a79aebbc42c26467">134: DREAM: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804345</td>
<td>0.996764</td>
<td><a href="https://www.semanticscholar.org/paper/07ded4cf00095d91e8689a0a52d9e20eb64aca0b">55: MuTual: A Dataset for Multi-Turn Dialogue Reasoning</a></td>
</tr>
</table></html>
