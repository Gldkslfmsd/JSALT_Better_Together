<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/e18cc99b5be0aa29592038dcea7c966211c84922">93: The CoNLL–SIGMORPHON 2018 Shared Task: Universal Morphological Reinflection</a></td>
</tr>
<tr>
<td>1</td>
<td>0.831386</td>
<td>0.986293</td>
<td><a href="https://www.semanticscholar.org/paper/d74d92b130669536458289fb5f3d2526d3340c6a">23: IIT(BHU)–IIITH at CoNLL–SIGMORPHON 2018 Shared Task on Universal Morphological Reinflection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.769856</td>
<td>-0.039315</td>
<td><a href="https://www.semanticscholar.org/paper/44004b64b5b4cc0f7f2277f4dda18605308f1590">0: Automated Multi-task Learning - eScholarship</a></td>
</tr>
<tr>
<td>0</td>
<td>0.746074</td>
<td>0.779443</td>
<td><a href="https://www.semanticscholar.org/paper/0a110d4b6ed2eb2567d1fdfdc74ee6ec5e570156">8: Empirical evaluation of multi-task learning in deep neural networks for natural language processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731293</td>
<td>0.691187</td>
<td><a href="https://www.semanticscholar.org/paper/d0cda85c030711aaa5383c80d5928a4d22f8d3bf">93: How Can We Accelerate Progress Towards Human-like Linguistic Generalization?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.728580</td>
<td>0.735015</td>
<td><a href="https://www.semanticscholar.org/paper/2e8a4bfe3312375b03deeddc79128cc4b4e87caf">2: Experiments from LIMSI at the French Named Entity Recognition Coarse-grained Task</a></td>
</tr>
<tr>
<td>0</td>
<td>0.711642</td>
<td>0.930388</td>
<td><a href="https://www.semanticscholar.org/paper/b42bc67755b0e2c2ca85b22cff6a88f201b3f80e">2: Effort-Aware Neural Automatic Post-Editing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.711482</td>
<td>0.328496</td>
<td><a href="https://www.semanticscholar.org/paper/898353e177d69ec399612b53319850e61b64958b">5: UMCC_DLSI_SemSim: Multilingual System for Measuring Semantic Textual Similarity</a></td>
</tr>
<tr>
<td>0</td>
<td>0.703787</td>
<td>0.711492</td>
<td><a href="https://www.semanticscholar.org/paper/b1a71677a13299755a12375f0c982484088aa9ef">38: English Intermediate-Task Training Improves Zero-Shot Cross-Lingual Transfer Too</a></td>
</tr>
<tr>
<td>0</td>
<td>0.694623</td>
<td>0.747224</td>
<td><a href="https://www.semanticscholar.org/paper/a5ef23c229a43dc0ecaecab9985aa21a114ef751">0: Ensemble ALBERT on SQuAD 2.0 (Option 3)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.548017</td>
<td>0.987763</td>
<td><a href="https://www.semanticscholar.org/paper/7ae976870e17ed36dc41bfd7fcc13e6860573340">136: Learning to Parse and Translate Improves Neural Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834467</td>
<td>0.987748</td>
<td><a href="https://www.semanticscholar.org/paper/39f81aef964e076d7a089f597e8028b43b5675cf">66: The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and Cross-Lingual Transfer for Inflection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.541303</td>
<td>0.987534</td>
<td><a href="https://www.semanticscholar.org/paper/d19b712f90cde698cc96ebd5fe291b410e3f0f9c">56: The Neural Noisy Channel</a></td>
</tr>
<tr>
<td>0</td>
<td>0.625981</td>
<td>0.986822</td>
<td><a href="https://www.semanticscholar.org/paper/c6cd38528339a6a7df44419272161457e2012582">7: Data Augmentation for Transformer-based G2P</a></td>
</tr>
<tr>
<td>0</td>
<td>0.668772</td>
<td>0.985187</td>
<td><a href="https://www.semanticscholar.org/paper/629aedaaa0507ae4231d6e6230b8aee9ec2bdba6">13: Higher-Order Syntactic Attention Network for Longer Sentence Compression</a></td>
</tr>
<tr>
<td>0</td>
<td>0.630535</td>
<td>0.985069</td>
<td><a href="https://www.semanticscholar.org/paper/b8bc86a1bc281b15ce45e967cbdd045bcf23a952">369: Fully Character-Level Neural Machine Translation without Explicit Segmentation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.635530</td>
<td>0.984748</td>
<td><a href="https://www.semanticscholar.org/paper/6dd717779a2efda7b13bc9860e541bf508394e23">33: A Bag of Useful Tricks for Practical Neural Machine Translation: Embedding Layer Initialization and Large Batch Size</a></td>
</tr>
<tr>
<td>0</td>
<td>0.670917</td>
<td>0.984635</td>
<td><a href="https://www.semanticscholar.org/paper/fc4c18024ab61a8ca11a5259782fc4986810e920">10: Source-side Prediction for Neural Headline Generation</a></td>
</tr>
</table></html>
