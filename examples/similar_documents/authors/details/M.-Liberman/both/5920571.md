<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/651737be048cc570fe7a2a420b3f478ff0a2b52a">31: Robust speaking rate estimation using broad phonetic class recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830116</td>
<td>0.896105</td>
<td><a href="https://www.semanticscholar.org/paper/223a77fc6767dd0720f122ee77a7e4c5ffa163e0">3: A comparison of broad phonetic and acoustic units for noise robust segment-based phonetic recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823703</td>
<td>0.682592</td>
<td><a href="https://www.semanticscholar.org/paper/e01db07b17ef4aaa060f3a16f624e44a0f8f4ddb">2: Extraction and evaluation of phonetic-acoustic rules for continuous speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.814949</td>
<td>0.735400</td>
<td><a href="https://www.semanticscholar.org/paper/27b118e408a521090b15b3adec06e9ed8b161fcb">7: Phoneme classification using Markov models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809263</td>
<td>0.761932</td>
<td><a href="https://www.semanticscholar.org/paper/52b4197f117470b645dbe0f999b690ed4fa05844">7: Similarity measure for automatic speech and speaker recognition.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806933</td>
<td>0.930661</td>
<td><a href="https://www.semanticscholar.org/paper/7e0e2b67f2aaafe9e83ecd7b3d84eb8b1c61e9a7">65: Syllable detection in read and spontaneous speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802876</td>
<td>0.893461</td>
<td><a href="https://www.semanticscholar.org/paper/3369bc502c6a6a96463000989b2db7c31e010e85">2: Making Automatic Speech Recognition More Robust to Fast Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801913</td>
<td>0.799258</td>
<td><a href="https://www.semanticscholar.org/paper/a49f58b7215ba57ee4066de805fe4f424d75376b">43: Improved MLLR speaker adaptation using confidence measures for conversational speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800834</td>
<td>0.761282</td>
<td><a href="https://www.semanticscholar.org/paper/c88cb58136ec675c4366855e50a714c7323a6915">4: Modeling Consistency in a Speaker Independent Continuous Speech Recognition System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796327</td>
<td>0.891385</td>
<td><a href="https://www.semanticscholar.org/paper/2864baa6bdbb7bdfd8eb30c27cf812fd70ab5a01">3: Exploiting phonetic and phonological similarities as a first step for robust speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.715597</td>
<td>0.975666</td>
<td><a href="https://www.semanticscholar.org/paper/a0cda163c4c193cd68af0abafe7cb59673a4dc78">15: A mode-shape classification technique for robust speech rate estimation and syllable nuclei detection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802694</td>
<td>0.975477</td>
<td><a href="https://www.semanticscholar.org/paper/dee187941d3ea5408e743b119f1b282b4ecc50a7">72: Estimating the speaking rate by vowel detection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.684998</td>
<td>0.973779</td>
<td><a href="https://www.semanticscholar.org/paper/386e9af6ad91025d71e599b778d4362359c1a2e2">35: Speech rhythm guided syllable nuclei detection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723868</td>
<td>0.972247</td>
<td><a href="https://www.semanticscholar.org/paper/4b105fa5846bb50ce27434bc1b04cb2f0b31a8e6">26: Speech rate estimation via temporal correlation and selected sub-band correlation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705382</td>
<td>0.970187</td>
<td><a href="https://www.semanticscholar.org/paper/af9b27e7b6936ec79126facd8d681cd3c7ce0ce8">14: Syllable nuclei detection using perceptually significant features</a></td>
</tr>
<tr>
<td>0</td>
<td>0.747345</td>
<td>0.968159</td>
<td><a href="https://www.semanticscholar.org/paper/a0327d34bd56429bbd6b4ec7e9ca7f022b96b7de">16: A comparative study of speech rate estimation techniques</a></td>
</tr>
<tr>
<td>0</td>
<td>0.664527</td>
<td>0.967095</td>
<td><a href="https://www.semanticscholar.org/paper/200bb5b8b88c8b6e96f921df224a30fb54db2ac1">0: Pitch Contour Stylization by Marking Voice Intonation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756045</td>
<td>0.966200</td>
<td><a href="https://www.semanticscholar.org/paper/15b8576bf70d4987844e1dc4b0d1cfb7772c0148">67: Speaker-independent phoneme alignment using transition-dependent states</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701641</td>
<td>0.966110</td>
<td><a href="https://www.semanticscholar.org/paper/101076fd90aed1952928cd24e0716ab8dfa15ccd">6: A robust speech rate estimation based on the activation profile from the selected acoustic unit dictionary</a></td>
</tr>
</table></html>
