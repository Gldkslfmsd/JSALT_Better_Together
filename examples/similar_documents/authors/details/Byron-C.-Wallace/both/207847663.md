<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/642038c7a49caa9f0ac5b37b01fab5b2b8d981d5">209: ERASER: A Benchmark to Evaluate Rationalized NLP Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.844324</td>
<td>0.081535</td>
<td><a href="https://www.semanticscholar.org/paper/bc9a108f5a1fc85b55ccee768b75d8a73a28a288">0: ER-TEST: Evaluating Explanation Regularization Methods for NLP Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.838172</td>
<td>0.969138</td>
<td><a href="https://www.semanticscholar.org/paper/27df491cf85fcfab89b845327dca8afcddb35770">2: Can Rationalization Improve Robustness?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818791</td>
<td>0.985588</td>
<td><a href="https://www.semanticscholar.org/paper/ddd27dba038d0ed14c48cd027812df58a902ece2">69: AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807153</td>
<td>0.970293</td>
<td><a href="https://www.semanticscholar.org/paper/f0d6db2186d8bf2d8530f01de6c6518bb9711392">26: Interpretability and Analysis in Neural NLP</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803524</td>
<td>0.950045</td>
<td><a href="https://www.semanticscholar.org/paper/e3bba08dc07c5f1372b78450990ba0ef305a834c">12: Can NLI Models Verify QA Systems' Predictions?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795283</td>
<td>0.978261</td>
<td><a href="https://www.semanticscholar.org/paper/361c883ce860c1235768ea424a91d501b2b1def1">2: What to Learn, and How: Toward Effective Learning from Rationales</a></td>
</tr>
<tr>
<td>0</td>
<td>0.787739</td>
<td>0.959182</td>
<td><a href="https://www.semanticscholar.org/paper/8710ae72078e2b0cd9b6e7a27d93f39ec82ee747">8: CS-NLP Team at SemEval-2020 Task 4: Evaluation of State-of-the-art NLP Deep Learning Architectures on Commonsense Reasoning Task</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785995</td>
<td>0.910665</td>
<td><a href="https://www.semanticscholar.org/paper/c6dc2f21e943c5a1dd35fb3d6ff18525c9c86ca0">17: Infusing Finetuning with Semantic Dependencies</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785558</td>
<td>0.917298</td>
<td><a href="https://www.semanticscholar.org/paper/7f0ef8999164c71b98ef18da15d7acc2c56ea5c7">3: UIUC_BioNLP at SemEval-2021 Task 11: A Cascade of Neural Models for Structuring Scholarly NLP Contributions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798683</td>
<td>0.996926</td>
<td><a href="https://www.semanticscholar.org/paper/922e6e3bafe38a712597c05d3a907bd10763b427">65: Learning to Faithfully Rationalize by Construction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.761285</td>
<td>0.993326</td>
<td><a href="https://www.semanticscholar.org/paper/2f48729f670b4bef6ed43e8d7471373c37a219ce">0: UNIREX: A Unified Learning Framework for Language Model Rationale Extraction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.689052</td>
<td>0.992510</td>
<td><a href="https://www.semanticscholar.org/paper/73d5439f91fd3333d8b9c05600ae0ecea9fd4c31">2: Benchmarking Post-Hoc Interpretability Approaches for Transformer-based Misogyny Detection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.707169</td>
<td>0.991418</td>
<td><a href="https://www.semanticscholar.org/paper/2a456fd1d47a396feef9a1a2cf140a71bbc78ad4">4: Connecting Attributions and QA Model Behavior on Realistic Counterfactuals</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798200</td>
<td>0.990996</td>
<td><a href="https://www.semanticscholar.org/paper/343e06bae852f74a98573e798b501f6003bcb1c0">35: Measuring Association Between Labels and Free-Text Rationales</a></td>
</tr>
<tr>
<td>0</td>
<td>0.569024</td>
<td>0.990987</td>
<td><a href="https://www.semanticscholar.org/paper/2232808cf3161ca4c434126e35f47ee33c0c8219">40: Evaluating Explanations: How Much Do Explanations from the Teacher Aid Students?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758268</td>
<td>0.990720</td>
<td><a href="https://www.semanticscholar.org/paper/311e48e1c4a0dcd65a6699376ffc85a24a333a56">2: Enjoy the Salience: Towards Better Transformer-based Faithful Explanations with Word Salience</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767877</td>
<td>0.990501</td>
<td><a href="https://www.semanticscholar.org/paper/c9aeb7e31b16b7273a80ae748b3ff48105928147">37: An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.770429</td>
<td>0.990355</td>
<td><a href="https://www.semanticscholar.org/paper/1a3a0047d74639784e7a7450854c28c9e7bdaf0a">37: Teach Me to Explain: A Review of Datasets for Explainable NLP</a></td>
</tr>
</table></html>
