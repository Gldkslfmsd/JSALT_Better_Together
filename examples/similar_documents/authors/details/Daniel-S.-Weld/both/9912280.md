<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/ffa46a3ca4a6bca9bfe338bde6dcf141c36706f7">247: Cascade: crowdsourcing taxonomy creation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748805</td>
<td>0.783185</td>
<td><a href="https://www.semanticscholar.org/paper/f2413a484f6b6818da9395511154ae207593e1ff">0: Crowdsourced Joins for Filter Queries</a></td>
</tr>
<tr>
<td>0</td>
<td>0.743541</td>
<td>0.896738</td>
<td><a href="https://www.semanticscholar.org/paper/318f5f1afcdf6e9e99a0ab132caf58897e31a536">4: Designing Complex Crowdsourcing Applications Covering Multiple Platforms and Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742275</td>
<td>0.751566</td>
<td><a href="https://www.semanticscholar.org/paper/491abbf8e7f77268ed0537f475b26fed88f3cd68">2: Aggregating Unstructured Submissions for Reliable Answers in Crowdsourcing Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.726649</td>
<td>0.684042</td>
<td><a href="https://www.semanticscholar.org/paper/bf4540beb38eab763f29a2ab5ba2b353635eb3c4">23: Active learning with confidence-based answers for crowdsourcing labeling tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.708294</td>
<td>0.549481</td>
<td><a href="https://www.semanticscholar.org/paper/03e5c724531321a9d383a4483bda07606f9642ef">3: Unsupervised Hierarchical Grouping of Knowledge Graph Entities</a></td>
</tr>
<tr>
<td>0</td>
<td>0.704896</td>
<td>0.561746</td>
<td><a href="https://www.semanticscholar.org/paper/8f64fce03a19fc23a999c3d72c6a5bf1da3aa284">3: Pinterest Analysis and Recommendations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701611</td>
<td>0.903199</td>
<td><a href="https://www.semanticscholar.org/paper/4077c1986f32817801b3082ce8dde514424f71a1">3: Add-Remove-Confirm: Crowdsourcing synset cleansing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.700160</td>
<td>0.766562</td>
<td><a href="https://www.semanticscholar.org/paper/897b5277262aa078d2e1b3aba3c7f1533fb7168e">13: Worker ranking determination in crowdsourcing platforms using aggregation functions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.696882</td>
<td>0.579230</td>
<td><a href="https://www.semanticscholar.org/paper/2d97bf8330b055d9f5c1352036fbb82d026710bf">5: From social tagging to polyrepresentation: a study of expert annotating behavior of moving images</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742683</td>
<td>0.971673</td>
<td><a href="https://www.semanticscholar.org/paper/302bfb5c5063195e5691b16d37a2c3ffece9e532">26: Context Trees: Crowdsourcing Global Understanding from Local Views</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.971403</td>
<td><a href="https://www.semanticscholar.org/paper/f3c042f14e80f562d70322a5e2e03e6aa85f8a60">10: Revolt</a></td>
</tr>
<tr>
<td>0</td>
<td>0.667001</td>
<td>0.970119</td>
<td><a href="https://www.semanticscholar.org/paper/88ebed7e5eac6f5d14f0100007a8cf23148e8617">46: Frenzy: collaborative data organization for creating conference sessions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.642821</td>
<td>0.964399</td>
<td><a href="https://www.semanticscholar.org/paper/77e22cdf12715ff3ea7d9ffe316d90c83556f551">0: In Search of Ambiguity: A Three-Stage Workflow Design to Clarify Annotation Guidelines for Crowd Workers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.724670</td>
<td>0.962216</td>
<td><a href="https://www.semanticscholar.org/paper/c3204eddc108434bf7b2a36992207571f1e837aa">26: Crowdlines: Supporting Synthesis of Diverse Information Sources through Crowdsourced Outlines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.667660</td>
<td>0.962104</td>
<td><a href="https://www.semanticscholar.org/paper/2cb123d50cf1bc3f6e4ce88aeb868390f76b4e74">817: Soylent: a word processor with a crowd inside</a></td>
</tr>
<tr>
<td>0</td>
<td>0.775455</td>
<td>0.956188</td>
<td><a href="https://www.semanticscholar.org/paper/47e3f3e976797d54951d21e7ccc185f46f82f10b">44: Alloy: Clustering with Crowds and Computation</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.954030</td>
<td><a href="https://www.semanticscholar.org/paper/9b2fde05ec38fda30904663436e224b708df09da">3: Organic Crowdsourcing Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.666002</td>
<td>0.953224</td>
<td><a href="https://www.semanticscholar.org/paper/350f92b121d0086682e6ffc6d0742d6f88038ea3">229: Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution</a></td>
</tr>
</table></html>
