<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/7fead81d3655f52a221ef8738216ab8826019897">102: A Simple Word Embedding Model for Lexical Substitution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.870499</td>
<td>0.984465</td>
<td><a href="https://www.semanticscholar.org/paper/7649e81c4e9a32644a3c02f256cc012ea3de21fc">0: Contextualized context2vec</a></td>
</tr>
<tr>
<td>0</td>
<td>0.837201</td>
<td>0.892381</td>
<td><a href="https://www.semanticscholar.org/paper/4f12ae30f56fca636966065d2497c6c6deefbf27">53: Latent Vector Weighting for Word Meaning in Context</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834959</td>
<td>0.918866</td>
<td><a href="https://www.semanticscholar.org/paper/993a2a567fa14039f930295dad8e2779ef7dd2c0">3: A Comparative Study of Lexical Substitution Approaches based on Neural Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820312</td>
<td>0.952090</td>
<td><a href="https://www.semanticscholar.org/paper/e9e7473b0e8914433640eef98e34fdf6c2364699">2: Contextually Propagated Term Weights for Document Representation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818716</td>
<td>0.902298</td>
<td><a href="https://www.semanticscholar.org/paper/7fd9f1294703e6f73806ffde71545a5dc88b6df3">3: Exploration of register-dependent lexical semantics using word embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818406</td>
<td>0.917552</td>
<td><a href="https://www.semanticscholar.org/paper/04b1e6e0e38e2f707ad73b736e94b1d1b25186a1">26: FASTSUBS: An Efficient and Exact Procedure for Finding the Most Likely Lexical Substitutes Based on an N-Gram Language Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818137</td>
<td>0.976048</td>
<td><a href="https://www.semanticscholar.org/paper/559b53c05745c5317046bb170f632f872e1e679a">9: Word Embeddings vs Word Types for Sequence Labeling: the Curious Case of CV Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807222</td>
<td>0.863555</td>
<td><a href="https://www.semanticscholar.org/paper/8f76e2431ea5a5b4fd2370409ba5e8ee866dca0a">2: A Matrix-Vector Recurrent Unit Model for Capturing Compositional Semantics in Phrase Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807054</td>
<td>0.977700</td>
<td><a href="https://www.semanticscholar.org/paper/d70df38462a8effa02fd8c8cfb94da8f82fcbcad">41: A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723474</td>
<td>0.994676</td>
<td><a href="https://www.semanticscholar.org/paper/14de10f81a45185f2c1391c416c553fb144b38db">139: Evaluation of Word Vector Representations by Subspace Alignment</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834611</td>
<td>0.994261</td>
<td><a href="https://www.semanticscholar.org/paper/f1f2b416bfe7d30f76ec55d75088835f62ebf980">18: PIC a Different Word: A Simple Model for Lexical Substitution in Context</a></td>
</tr>
<tr>
<td>0</td>
<td>0.754880</td>
<td>0.993880</td>
<td><a href="https://www.semanticscholar.org/paper/bf9db8ca2dce7386cbed1ae0fd6465148cdb2b98">224: From Word to Sense Embeddings: A Survey on Vector Representations of Meaning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788573</td>
<td>0.993784</td>
<td><a href="https://www.semanticscholar.org/paper/47291646a01c8786abd1b168cb78e6af575f9318">278: AutoExtend: Extending Word Embeddings to Embeddings for Synsets and Lexemes</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799535</td>
<td>0.993295</td>
<td><a href="https://www.semanticscholar.org/paper/00cc08c90bc4ae7d3523e4dad2ca3a8fafc8501a">238: Embeddings for Word Sense Disambiguation: An Evaluation Study</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762791</td>
<td>0.993289</td>
<td><a href="https://www.semanticscholar.org/paper/0cdca7c4d5e46ccb0495c142d80afc0fa55d6a0f">19: Inducing Embeddings for Rare and Unseen Words by Leveraging Lexical Resources</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740576</td>
<td>0.992979</td>
<td><a href="https://www.semanticscholar.org/paper/f7e04fa7413d4ede7186fd0a40310a24a3ba27fb">233: Problems With Evaluation of Word Embeddings Using Word Similarity Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.777833</td>
<td>0.992094</td>
<td><a href="https://www.semanticscholar.org/paper/9fd010312235c28ff208b8caa441faacb2283f1f">26: MUSE: Modularizing Unsupervised Sense Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.683948</td>
<td>0.991959</td>
<td><a href="https://www.semanticscholar.org/paper/a1d1e3f7ee6767712fe14ee1bde11a341775daa3">209: SimVerb-3500: A Large-Scale Evaluation Set of Verb Similarity</a></td>
</tr>
</table></html>
