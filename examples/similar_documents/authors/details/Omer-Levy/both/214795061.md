<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/3f11a2124af139af7c6f17eccab5149d759d7f52">51: Aligned Cross Entropy for Non-Autoregressive Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.832630</td>
<td>0.990946</td>
<td><a href="https://www.semanticscholar.org/paper/1a98ce71556e4602b313d424b3d689e026ca4706">32: Constant-Time Machine Translation with Conditional Masked Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831121</td>
<td>0.926744</td>
<td><a href="https://www.semanticscholar.org/paper/6c742836b51ec69d27ccfc0a568f1cc7931abc71">4: Improving Fluency of Non-Autoregressive Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.828268</td>
<td>0.987162</td>
<td><a href="https://www.semanticscholar.org/paper/5efadc9019ce3378a0eb6c8f939cdde6c8918b1e">244: Mask-Predict: Parallel Decoding of Conditional Masked Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785977</td>
<td>0.943239</td>
<td><a href="https://www.semanticscholar.org/paper/c258173312e0dbb750e8c16c2a01294c0ff6a6a8">0: A Self-Paced Mixed Distillation Method for Non-Autoregressive Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760693</td>
<td>0.459650</td>
<td><a href="https://www.semanticscholar.org/paper/415b6b6b7dba904384df1996d9948744f86f0405">0: 9-2011 Multi-Strategy Approaches to Active Learning for Statistical Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759231</td>
<td>0.889821</td>
<td><a href="https://www.semanticscholar.org/paper/5f0c801a72675327c80a9c2beaa971564f578818">23: Exploring Recombination for Efficient Decoding of Neural Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.754787</td>
<td>0.544524</td>
<td><a href="https://www.semanticscholar.org/paper/3043321d60d8840c392dfd902ae23e6021f090cb">12: Segment Choice Models: Feature-Rich Models for Global Distortion in Statistical Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751017</td>
<td>0.581493</td>
<td><a href="https://www.semanticscholar.org/paper/5e8224c272d09ab74dbb523a6ca3ab6ac9e76a93">12: Deep State Space Models for Unconditional Word Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.750619</td>
<td>0.799815</td>
<td><a href="https://www.semanticscholar.org/paper/59a6a924bea66e596b91dc26b3c7a6a906a6ef93">47: Neural Network Translation Models for Grammatical Error Correction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809696</td>
<td>0.998201</td>
<td><a href="https://www.semanticscholar.org/paper/1784fa1b5ac0b9f9fefe5e0508f91033f5952177">32: Fully Non-autoregressive Neural Machine Translation: Tricks of the Trade</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802975</td>
<td>0.997635</td>
<td><a href="https://www.semanticscholar.org/paper/30c1a88ba3573957e4c5ca04132390c71f66d4b0">59: Non-Autoregressive Machine Translation with Latent Alignments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.835123</td>
<td>0.997595</td>
<td><a href="https://www.semanticscholar.org/paper/e2f679183c504d06767223955a578480ecfe808d">21: Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772886</td>
<td>0.997463</td>
<td><a href="https://www.semanticscholar.org/paper/3db8de1e088e1837146c4f2f3c9d13a6c40434da">10: Non-Autoregressive Translation with Layer-Wise Prediction and Deep Supervision</a></td>
</tr>
<tr>
<td>0</td>
<td>0.681112</td>
<td>0.997285</td>
<td><a href="https://www.semanticscholar.org/paper/1967b9127084aa696f32e20f42f0f8d7be583be5">0: I MPROVING N ON -A UTOREGRESSIVE T RANSLATION M ODELS W ITHOUT D ISTILLATION</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823514</td>
<td>0.997228</td>
<td><a href="https://www.semanticscholar.org/paper/33d05a1ff5f15bdc60fc43fa8523a4888af5f116">28: Glancing Transformer for Non-Autoregressive Neural Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.997180</td>
<td><a href="https://www.semanticscholar.org/paper/d5def8e0d66873630e78cfc65cff4051183c639e">19: Hint-based Training for Non-Autoregressive Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816266</td>
<td>0.996987</td>
<td><a href="https://www.semanticscholar.org/paper/94c30d3c03beace3ba0d7014e0b1852bb892133c">42: Non-autoregressive Machine Translation with Disentangled Context Transformer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.771757</td>
<td>0.996859</td>
<td><a href="https://www.semanticscholar.org/paper/7b28577ed96bd1b76bbe79859b3222604b2dc369">40: Semi-Autoregressive Training Improves Mask-Predict Decoding</a></td>
</tr>
</table></html>
