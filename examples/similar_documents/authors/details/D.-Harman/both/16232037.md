<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/91fa6f6dfb09d3a38e500c2eafa3606b87924aa4">58: The Effects of Human Variation in DUC Summarization Evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.871892</td>
<td>0.860737</td>
<td><a href="https://www.semanticscholar.org/paper/e31450fa202b877cd16e3063ddd579518583ed41">17: The DUC summarization evaluations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.848930</td>
<td>0.976502</td>
<td><a href="https://www.semanticscholar.org/paper/6ca755a0e87da3c25ac27e92b73701fe435a12d9">219: Manual and automatic evaluation of summaries</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823077</td>
<td>0.870956</td>
<td><a href="https://www.semanticscholar.org/paper/9a296c206ef66031684152cbd3764a0f642cb688">505: A Survey on Automatic Text Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813201</td>
<td>0.911007</td>
<td><a href="https://www.semanticscholar.org/paper/e9829cd4db2791837f4796aa1c566c442df6de99">7: JRC's Participation in the Guided Summarization Task at TAC 2010</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811662</td>
<td>0.517342</td>
<td><a href="https://www.semanticscholar.org/paper/12d7fc35c772fa69f4b3bd5d61db52e7b2394f9a">60: Evaluating Natural Language Processing Techniques in Information Retrieval</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807059</td>
<td>0.794487</td>
<td><a href="https://www.semanticscholar.org/paper/5a4ec35ccc0ee062af80154cd5ea8d5965181b0e">177: Evaluation Challenges in Large-Scale Document Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802752</td>
<td>0.941068</td>
<td><a href="https://www.semanticscholar.org/paper/351738628be135c360c703d6b5cca6c6d65c07ef">20: Text Specificity and Impact on Quality of News Summaries</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795840</td>
<td>0.956144</td>
<td><a href="https://www.semanticscholar.org/paper/cca42b7e53a2d5e5c0f995735043e84a3b1cc89c">30: Studying Summarization Evaluation Metrics in the Appropriate Scoring Range</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794706</td>
<td>0.649300</td>
<td><a href="https://www.semanticscholar.org/paper/3f959a0bb99bce28dfb287cd8563e4d6421fdd5c">10: The effect of expanding relevance judgements with duplicates</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734656</td>
<td>0.992591</td>
<td><a href="https://www.semanticscholar.org/paper/87be63226941ea6d32b38debbab6da06aea49503">3: A Crowdsourcing Approach to Evaluate the Quality of Query-based Extractive Text Summaries</a></td>
</tr>
<tr>
<td>0</td>
<td>0.653744</td>
<td>0.989961</td>
<td><a href="https://www.semanticscholar.org/paper/d232f71b7da757a91ac9d53d91d295eb4d76cfea">1: Approximate unsupervised summary optimisation for selections of ROUGE</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765304</td>
<td>0.989754</td>
<td><a href="https://www.semanticscholar.org/paper/b7eeacd13a1083565183d2330c6d12f70cbc6975">15: Estimating Summary Quality with Pairwise Preferences</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737721</td>
<td>0.988900</td>
<td><a href="https://www.semanticscholar.org/paper/cfad182f567b6a6d54a4dd517e0122692afca9fb">87: Looking for a Few Good Metrics: ROUGE and its Evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800326</td>
<td>0.988685</td>
<td><a href="https://www.semanticscholar.org/paper/eec3debe5d352f6e83731388b94319c4aa23cd0d">40: A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796172</td>
<td>0.988395</td>
<td><a href="https://www.semanticscholar.org/paper/fa58bb21161873f42b279c8808aa5ea9ead76859">81: Correlation between ROUGE and Human Evaluation of Extractive Meeting Summaries</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816922</td>
<td>0.987888</td>
<td><a href="https://www.semanticscholar.org/paper/81cee0ddf91776053db3f838d1009606aacca7ec">53: DUC 2005: Evaluation of Question-Focused Summarization Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.757210</td>
<td>0.987779</td>
<td><a href="https://www.semanticscholar.org/paper/24cb6122acd983ccf5b175a401c300add943ca38">3: Development of a Konkani Language Dataset for Automatic Text Summarization and its Challenges</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793051</td>
<td>0.987040</td>
<td><a href="https://www.semanticscholar.org/paper/f96c013c014a78905baea21922c9c4a8060e537d">39: Revisiting Summarization Evaluation for Scientific Articles</a></td>
</tr>
</table></html>
