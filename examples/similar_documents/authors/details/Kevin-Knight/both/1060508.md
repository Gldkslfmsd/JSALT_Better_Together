<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/925b40ae3aa7ed1bf642d78dc80fce1f573293e2">146: Two-Level, Many-Paths Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786838</td>
<td>0.988392</td>
<td><a href="https://www.semanticscholar.org/paper/0886bd3d1b4fd46928a295a36b5230c4352f699b">423: Generation that Exploits Corpus-Based Statistical Knowledge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742069</td>
<td>0.957851</td>
<td><a href="https://www.semanticscholar.org/paper/4fa20996d39d03d2ecccddc51084ee079e569ee6">25: Instance-based natural language generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.729051</td>
<td>0.936502</td>
<td><a href="https://www.semanticscholar.org/paper/66a3159c08f335c6ed1d5757c6416e8b7e79880d">0: Grammar-Based Concept Alignment for Domain-Specific Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.715822</td>
<td>0.851751</td>
<td><a href="https://www.semanticscholar.org/paper/e4aade5d2ac7d2bb569aacf5ce88b349476f2c6e">0: Measuring Implemented Grammar Evolution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.709338</td>
<td>0.052783</td>
<td><a href="https://www.semanticscholar.org/paper/d52b969d0702f15fd26cfaaf7d0b3be73cf67ea0">5: Exposing a Bias Toward Short-Length Numbers in Grammatical Evolution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705844</td>
<td>0.783147</td>
<td><a href="https://www.semanticscholar.org/paper/5e0aa4a649269eccc2b995a838dea952888873a1">0: Automated abstracting: A re-evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.704628</td>
<td>0.796927</td>
<td><a href="https://www.semanticscholar.org/paper/295439a6b75615537830c2c1106be91a42da22f5">32: Language-model optimization by mapping of corpora</a></td>
</tr>
<tr>
<td>0</td>
<td>0.702217</td>
<td>0.837339</td>
<td><a href="https://www.semanticscholar.org/paper/fee3e606324b8ece0fe906367c3d3a439ab3b142">1: Deepening wisdom or compromised principles?-the hybridization of statistical and symbolic MT systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701103</td>
<td>0.899333</td>
<td><a href="https://www.semanticscholar.org/paper/12d5edf3ab174a18cc20c13e25d38cffb026fac1">1: Closing the gap between stochastic and rule-based LFG grammars</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759069</td>
<td>0.995171</td>
<td><a href="https://www.semanticscholar.org/paper/093b25b0ce5aaa65c9b7a5ddd1b2fcb8788ffc36">117: The Practical Value of N-Grams Is in Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.676175</td>
<td>0.993198</td>
<td><a href="https://www.semanticscholar.org/paper/df7eb9f3099747579b609a0072d390aa33c3f17f">86: Forest-Based Statistical Sentence Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.726043</td>
<td>0.991184</td>
<td><a href="https://www.semanticscholar.org/paper/c09dd97983f63bda9bafedbffebe87cfc6e18814">19: The Importance of Lexicalized Syntax Models for Natural Language Generation Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.741647</td>
<td>0.990943</td>
<td><a href="https://www.semanticscholar.org/paper/e733d1c229cb010d6630bae29fb86cfbe09a2d0f">182: Exploiting a Probabilistic Hierarchical Model for Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.627521</td>
<td>0.990914</td>
<td><a href="https://www.semanticscholar.org/paper/4754c9e32331fcc531730e9ecb8776d05662260a">15: Building Surface Realizers Automatically from Corpora âˆ— Huayan Zhong and</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701841</td>
<td>0.989879</td>
<td><a href="https://www.semanticscholar.org/paper/322a66f2baa894d6e85f08d772a54660f967f964">61: Corpus-Based Lexical Choice in Natural Language Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.739431</td>
<td>0.989447</td>
<td><a href="https://www.semanticscholar.org/paper/042bae678affac60689cef9030560d8bfc12d3fe">9: Natural language generation using an information-slim representation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.660079</td>
<td>0.988702</td>
<td><a href="https://www.semanticscholar.org/paper/bc688cfcd07a8e4f289c18ed2dd2cf6ba9131f5e">57: An Overview of Amalgam: A Machine-learned Generation Module</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751516</td>
<td>0.988463</td>
<td><a href="https://www.semanticscholar.org/paper/eeef2b1b411c4893aa339788bc23c8f4e447b472">26: Practical Grammar-Based NLG from Examples</a></td>
</tr>
</table></html>
