<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/d821ce08da6c0084d5eacbdf65e25556bc1b9bc3">267: Does String-Based Neural MT Learn Source Syntax?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756443</td>
<td>0.963204</td>
<td><a href="https://www.semanticscholar.org/paper/d2ad6ae5f57844c4474cd3f318c3cdc469994fae">45: Structural Embedding of Syntactic Trees for Machine Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752676</td>
<td>0.943371</td>
<td><a href="https://www.semanticscholar.org/paper/3e969414c426563c64544edbb6fe98b17df76021">13: Linguistic Information in Neural Semantic Parsing with Multiple Encoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748003</td>
<td>0.816951</td>
<td><a href="https://www.semanticscholar.org/paper/71480da09af638260801af1db8eff6acb4e1122f">263: Decoding with Large-Scale Neural Language Models Improves Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.745678</td>
<td>0.985272</td>
<td><a href="https://www.semanticscholar.org/paper/fd04e31c25451f9103a0ac2220ac8d7e7884c343">283: Coarse-to-Fine Decoding for Neural Semantic Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.721781</td>
<td>-0.035215</td>
<td><a href="https://www.semanticscholar.org/paper/97da57dc64d99d337f294bdce92b209fbed20c61">0: SyntaxFest 2019 Invited talk - Transferring NLP models across languages and domains</a></td>
</tr>
<tr>
<td>0</td>
<td>0.718005</td>
<td>0.831086</td>
<td><a href="https://www.semanticscholar.org/paper/eda636e3abae829cf7ad8e0519fbaec3f29d1e82">17: Cross-Lingual Dependency Parsing with Late Decoding for Truly Low-Resource Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717957</td>
<td>0.450683</td>
<td><a href="https://www.semanticscholar.org/paper/64c0efc26a43b1d95064714b51fad5ca602f470e">2: Encoder-decoder models for latent phonological representations of words</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717086</td>
<td>0.096035</td>
<td><a href="https://www.semanticscholar.org/paper/6ac70f0d78c838c73b16abafacae81c3f7632efd">4: Construction of Natural Language Sentence Acceptors by a Supervised-Learning Technique</a></td>
</tr>
<tr>
<td>0</td>
<td>0.712870</td>
<td>0.870863</td>
<td><a href="https://www.semanticscholar.org/paper/9cdd6ecaf25535ebde784cda3447939b6d8a6314">0: Learning to Refine Source Representations for Neural Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.680954</td>
<td>0.997807</td>
<td><a href="https://www.semanticscholar.org/paper/dcb028149bb3cf934fbd2e4cbb773ffbb9b0e49d">118: Evaluating Layers of Representation in Neural Machine Translation on Part-of-Speech and Semantic Tagging Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.753116</td>
<td>0.996800</td>
<td><a href="https://www.semanticscholar.org/paper/82364428995c29b3dcb60c1835548eeff4adcd20">278: What do Neural Machine Translation Models Learn about Morphology?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691592</td>
<td>0.992966</td>
<td><a href="https://www.semanticscholar.org/paper/d1505c6123c102e53eb19dff312cb25cea840b72">2389: Teaching Machines to Read and Comprehend</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759041</td>
<td>0.991919</td>
<td><a href="https://www.semanticscholar.org/paper/af96e98684c278b66769b4656af069585ac6df85">18: The Lazy Encoder: A Fine-Grained Analysis of the Role of Morphology in Neural Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.607705</td>
<td>0.990317</td>
<td><a href="https://www.semanticscholar.org/paper/eac21b22b2bba3a2311820c3f98702fa1d380ad5">166: Question Generation for Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.664889</td>
<td>0.989437</td>
<td><a href="https://www.semanticscholar.org/paper/0c7e41c308d05d6a7d5589e49ea85f4c2c2e0953">41: Deep Attentive Sentence Ordering Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691886</td>
<td>0.989241</td>
<td><a href="https://www.semanticscholar.org/paper/7b29f45df975ed1e4c3864b6ab4483f11086aa76">226: When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.608527</td>
<td>0.989188</td>
<td><a href="https://www.semanticscholar.org/paper/0d1775622abf795c9a6c8f55040fc134a9bb3c92">7: Joint Prediction of Punctuation and Disfluency in Speech Transcripts</a></td>
</tr>
<tr>
<td>0</td>
<td>0.487876</td>
<td>0.989050</td>
<td><a href="https://www.semanticscholar.org/paper/51ba63377280ca2c5d84738257a8fa65effeefe4">22: Semi-Supervised Disfluency Detection</a></td>
</tr>
</table></html>
