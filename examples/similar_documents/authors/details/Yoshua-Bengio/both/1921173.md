<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/b624504240fa52ab76167acfe3156150ca01cf3b">1848: Attention-Based Models for Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.868887</td>
<td>0.972240</td>
<td><a href="https://www.semanticscholar.org/paper/2c0a634a71ade1bb8458db124dc1cc9f7e452627">37: Local Monotonic Attention Mechanism for End-to-End Speech And Language Processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845585</td>
<td>0.977096</td>
<td><a href="https://www.semanticscholar.org/paper/42b5438a084c69065acc436a4237f6c6369abb72">12: An Analysis of Local Monotonic Attention Variants</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845023</td>
<td>0.874728</td>
<td><a href="https://www.semanticscholar.org/paper/b9d9ba48652e09b7cdc8054e082cce1ae9319953">0: Neural Incremental Speech Recognition Through Attention Transfer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.837757</td>
<td>0.975312</td>
<td><a href="https://www.semanticscholar.org/paper/181df5bfdfe36c341cf15b1e29aa1519e19a425f">9: Audio-Attention Discriminative Language Model for ASR Rescoring</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829045</td>
<td>0.937721</td>
<td><a href="https://www.semanticscholar.org/paper/ed62ba897b7aca6f0a54ed398fe0ac76c525b1b9">47: Self-Attention Transducers for End-to-End Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820924</td>
<td>0.954567</td>
<td><a href="https://www.semanticscholar.org/paper/b2f4624e57ad4e6a162dc0755228dddcc2f63d6a">10: Integrating Source-Channel and Attention-Based Sequence-to-Sequence Models for Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.814515</td>
<td>0.839806</td>
<td><a href="https://www.semanticscholar.org/paper/d8ef8e52a04132d2cbb789fa793c628fac22935b">5: End-to-End Architectures for Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811114</td>
<td>0.857073</td>
<td><a href="https://www.semanticscholar.org/paper/4d962c2fd47266fa25801cd47b12fd62656aa473">4: A model with length-variable attention for spoken language understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803105</td>
<td>0.679532</td>
<td><a href="https://www.semanticscholar.org/paper/a99fe72951c4451ca2069b3aa0bc273794d73c67">0: Effective Spoken Language Labeling with Deep Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806607</td>
<td>0.992764</td>
<td><a href="https://www.semanticscholar.org/paper/dc555e8156c956f823587ebbff018863e6d2a95e">358: Listen, Attend and Spell</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804641</td>
<td>0.988042</td>
<td><a href="https://www.semanticscholar.org/paper/3056add22b20e3361c38c0472d294a79d4031cb4">1492: Listen, attend and spell: A neural network for large vocabulary conversational speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.849523</td>
<td>0.986780</td>
<td><a href="https://www.semanticscholar.org/paper/878ba5458e9e51f0b341fd9117fa0b43ef4096d3">890: End-to-end attention-based large vocabulary speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806629</td>
<td>0.985590</td>
<td><a href="https://www.semanticscholar.org/paper/6cc68e8adf34b580f3f37d1bd267ee701974edde">206: A Comparison of Sequence-to-Sequence Models for Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812592</td>
<td>0.984932</td>
<td><a href="https://www.semanticscholar.org/paper/6e8b1bd63e0e33fe633d00742560de1a4ea8e30f">26: Gaussian Prediction Based Attention for Online End-to-End Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772330</td>
<td>0.984322</td>
<td><a href="https://www.semanticscholar.org/paper/47d2dc34e1d02a8109f5c04bb6939725de23716d">370: End-to-end Continuous Speech Recognition using Attention-based Recurrent NN: First Results</a></td>
</tr>
<tr>
<td>0</td>
<td>0.757021</td>
<td>0.984296</td>
<td><a href="https://www.semanticscholar.org/paper/7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f">953: Sequence Transduction with Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831033</td>
<td>0.984128</td>
<td><a href="https://www.semanticscholar.org/paper/9af2264799bdc3490e4650e2f5d126762caf420f">533: Joint CTC-attention based end-to-end speech recognition using multi-task learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.850187</td>
<td>0.983798</td>
<td><a href="https://www.semanticscholar.org/paper/c6b61535f1544835cca3851ceb34222ebc5b4377">816: State-of-the-Art Speech Recognition with Sequence-to-Sequence Models</a></td>
</tr>
</table></html>
