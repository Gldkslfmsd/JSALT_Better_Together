<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/4ea80c206b8ad73a6d320c9d8ed0321d84fe6d85">32: Recursive Neural Networks for Learning Logical Semantics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.824620</td>
<td>0.413116</td>
<td><a href="https://www.semanticscholar.org/paper/01e4d4f96f57ca3f109d618343f546ac80d94e86">1: Learning context-free grammars with recurrent neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813396</td>
<td>0.926889</td>
<td><a href="https://www.semanticscholar.org/paper/f3d04bd02df3be26365ebe3005bcd45db3736058">0: Extensions to Tree-Recursive Neural Networks for Natural Language Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810202</td>
<td>0.894744</td>
<td><a href="https://www.semanticscholar.org/paper/36c097a225a95735271960e2b63a2cb9e98bff83">281: A Fast Unified Model for Parsing and Sentence Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806088</td>
<td>0.387098</td>
<td><a href="https://www.semanticscholar.org/paper/2a39dce757cada1be68bc4fa55e638f290b2bd8c">1: Recurrent Neural Network for Syntax Learning with Flexible Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799638</td>
<td>0.511719</td>
<td><a href="https://www.semanticscholar.org/paper/aa14d921c3efb1e2b73aa8c44f801dc92c6b6e7a">52: Inductive Learning in Symbolic Domains Using Structure-Driven Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799592</td>
<td>0.760481</td>
<td><a href="https://www.semanticscholar.org/paper/f04df4e20a18358ea2f689b4c129781628ef7fc1">2477: A large annotated corpus for learning natural language inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798628</td>
<td>0.720005</td>
<td><a href="https://www.semanticscholar.org/paper/2db6c10f135d5701ae7aec45986124ce264c1344">1: Learning Symbolic Rules for Reasoning in Quasi-Natural Language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793121</td>
<td>0.674509</td>
<td><a href="https://www.semanticscholar.org/paper/f2a9ef36b79c1b25d15bf10ff061db5eaad06798">24: Do Neural Language Models Show Preferences for Syntactic Formalisms?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786627</td>
<td>0.403012</td>
<td><a href="https://www.semanticscholar.org/paper/12ab76d49838d64a31bf09d1e0ec01d4f6917ad2">14: A corpus-based connectionist architecture for large-scale natural language parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.646342</td>
<td>0.990303</td>
<td><a href="https://www.semanticscholar.org/paper/a640fb4a11fc767f4bf801f7a7320b92efc807d3">4: LIPN-IIMAS at SemEval-2017 Task 1: Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737369</td>
<td>0.988719</td>
<td><a href="https://www.semanticscholar.org/paper/4d010154aba7df973037faf18d210c234163b4cf">3: Mapping distributional to model-theoretic semantic spaces: a baseline</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719385</td>
<td>0.988067</td>
<td><a href="https://www.semanticscholar.org/paper/e1448fc3e396ebb56b2e53d06402a70446a172d6">8: Learning Phrase Embeddings from Paraphrases with GRUs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.777166</td>
<td>0.986947</td>
<td><a href="https://www.semanticscholar.org/paper/ff3a766c9f1137df8b6792e0a00d4f952ba8d457">8: Neural Network Models for Implicit Discourse Relation Classification in English and Chinese without Surface Features</a></td>
</tr>
<tr>
<td>0</td>
<td>0.687417</td>
<td>0.986911</td>
<td><a href="https://www.semanticscholar.org/paper/59f456d31d6e90d1c07d31e438e5be652d0529a2">53: Convolutional Neural Networks vs. Convolution Kernels: Feature Engineering for Answer Sentence Reranking</a></td>
</tr>
<tr>
<td>0</td>
<td>0.728522</td>
<td>0.986869</td>
<td><a href="https://www.semanticscholar.org/paper/2ac83dba0647faf9ac7c0c6b5ea8bbb6a356eaca">1: Context-Aware Tree-Based Convolutional Neural Networks for Natural Language Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.708299</td>
<td>0.986715</td>
<td><a href="https://www.semanticscholar.org/paper/88ea460ce2c68db9a1cdf43e613d168c02635c36">4: Predicting answer types for question-answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.576972</td>
<td>0.986712</td>
<td><a href="https://www.semanticscholar.org/paper/9dcc2f7f48b1335d53743be315e6e4919452c80b">3: On the Vector Representation of Utterances in Dialogue Context</a></td>
</tr>
<tr>
<td>0</td>
<td>0.642965</td>
<td>0.986552</td>
<td><a href="https://www.semanticscholar.org/paper/f41ce01de856192e7652b6cd18477d90e8008a97">9: A Chinese Question Answering Approach Integrating Count-Based and Embedding-Based Features</a></td>
</tr>
</table></html>
