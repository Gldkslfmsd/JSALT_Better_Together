<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/1321419b4e093ebd5064cd9c44b61c0d8b6c361d">62: Probing What Different NLP Tasks Teach Machines about Function Word Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834633</td>
<td>0.816897</td>
<td><a href="https://www.semanticscholar.org/paper/f26e088bc4659a9b7fce28b6604d26de779bcf93">56: Learning Answer-Entailing Structures for Machine Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834536</td>
<td>0.976149</td>
<td><a href="https://www.semanticscholar.org/paper/5d85221fed153c6b4bb0deaf7ec2c95e6ea4a7d8">0: Can Edge Probing Tasks Reveal Linguistic Knowledge in QA Models?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.815333</td>
<td>0.982031</td>
<td><a href="https://www.semanticscholar.org/paper/07930920abf70d54d1b0e39853b956aded1fb59a">7: How to Probe Sentence Embeddings in Low-Resource Languages: On Structural Design Choices for Probing Task Evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.808199</td>
<td>0.747486</td>
<td><a href="https://www.semanticscholar.org/paper/aa5b35dcf8b024f5352db73cc3944e8fad4f3793">443: Pointing the Unknown Words</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807588</td>
<td>0.992042</td>
<td><a href="https://www.semanticscholar.org/paper/81d89880586ff87b3ac8a14588b4e3f55c110ff8">16: Several Experiments on Investigating Pretraining and Knowledge-Enhanced Models for Natural Language Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801222</td>
<td>0.930435</td>
<td><a href="https://www.semanticscholar.org/paper/6dfb1fd361f85c3470defebdbaf42ce8344a0f13">0: Exploring Input Representation Granularity for Generating Questions Satisfying Question-Answer Congruence</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793549</td>
<td>-0.018409</td>
<td>NA:215551492</td>
</tr>
<tr>
<td>0</td>
<td>0.789762</td>
<td>0.989574</td>
<td><a href="https://www.semanticscholar.org/paper/5aab0e57b4a7d6d47dfbb34cafce8e728ff47102">0: BiQuAD: Towards QA based on deeper text understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788968</td>
<td>0.864778</td>
<td><a href="https://www.semanticscholar.org/paper/5127dd9446a61e08aa1d68420ac8e4bc3f243b83">6: An Evaluation of Language-Agnostic Inner-Attention-Based Representations in Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732753</td>
<td>0.995862</td>
<td><a href="https://www.semanticscholar.org/paper/27faa3ad168a64ad46a2aecfdb8b302d8217d811">3: SQuAD2-CR: Semi-supervised Annotation for Cause and Rationales for Unanswerability in SQuAD 2.0</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731423</td>
<td>0.995706</td>
<td><a href="https://www.semanticscholar.org/paper/547334370d2b03d51a39a1509fe7e164cd30e550">29: Quick and (not so) Dirty: Unsupervised Selection of Justification Sentences for Multi-hop Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802271</td>
<td>0.995480</td>
<td><a href="https://www.semanticscholar.org/paper/06a1bf4a7333bbc78dbd7470666b33bd9e26882b">70: Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining Beyond Language Modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736093</td>
<td>0.995258</td>
<td><a href="https://www.semanticscholar.org/paper/cf8c493079702ec420ab4fc9c0fabb56b2a16c84">271: SciTaiL: A Textual Entailment Dataset from Science Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701810</td>
<td>0.995093</td>
<td><a href="https://www.semanticscholar.org/paper/aa7b074f9e6043f95fb28c32cc37313ddb597156">104: Performance Impact Caused by Hidden Bias of Training Data for Recognizing Textual Entailment</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752033</td>
<td>0.994900</td>
<td><a href="https://www.semanticscholar.org/paper/a2cb49324b0fb5065b5854a493123237847dbf00">0: THE UNIVERSITY OF CHICAGO ASSESSING REPRESENTATION AND COMPOSITION IN DEEP LANGUAGE MODELS A PROPOSAL SUBMITTED TO THE FACULTY OF THE DIVISION OF THE PHYSICAL SCIENCE IN CANDIDACY FOR THE DEGREE OF DOCTOR OF PHILOSOPHY</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796706</td>
<td>0.994770</td>
<td><a href="https://www.semanticscholar.org/paper/3aaa8aaad5ef36550a6b47d6ee000f0b346a5a1f">61: Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT</a></td>
</tr>
<tr>
<td>0</td>
<td>0.695521</td>
<td>0.994213</td>
<td><a href="https://www.semanticscholar.org/paper/ff070fc5eff18a737545a0f96a068e9ab5a0f234">6: An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.730057</td>
<td>0.994173</td>
<td><a href="https://www.semanticscholar.org/paper/a49577c85544ec3fe0db7198a95ad397949a37dd">0: Catch the "Tails" of BERT</a></td>
</tr>
</table></html>
