<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/c50cd7df4271ef94a0a60894f0e2cf4ef89fb912">47: Ruminating Reader: Reasoning with Gated Multi-hop Attention</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799281</td>
<td>0.983148</td>
<td><a href="https://www.semanticscholar.org/paper/70e21e3234cb7e24b185396ac7b2b3df57848762">2: Read and Comprehend by Gated-Attention Reader with More Belief</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785196</td>
<td>0.942694</td>
<td><a href="https://www.semanticscholar.org/paper/39512024c0eb2ebc5c8f6e228023306c9ba790b7">0: Question Answering with Gated Attention and Multitask Learning-Option 3 (Graded)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.783032</td>
<td>-0.046433</td>
<td><a href="https://www.semanticscholar.org/paper/3abf3597c77c5812ec69ace8c89984bc9a4f38b2">0: CS 224 n Final Project : Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.769700</td>
<td>-0.046433</td>
<td>NA:248022242</td>
</tr>
<tr>
<td>0</td>
<td>0.765008</td>
<td>0.873348</td>
<td><a href="https://www.semanticscholar.org/paper/eaafa87e4c1a2ba43a0a6684046d8f237f684937">0: Multi-hop Question Answering on HotpotQA</a></td>
</tr>
<tr>
<td>0</td>
<td>0.757928</td>
<td>0.931876</td>
<td><a href="https://www.semanticscholar.org/paper/57c9b2be8b134d4c6ffce084ed83c3938a37c897">0: Understanding Dataset Design Choices for Multi-hop Reasoning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.754307</td>
<td>-0.046433</td>
<td><a href="https://www.semanticscholar.org/paper/34a9424c40fc99d9949caaaa05d5fa40a11a42ae">0: Utilizing External Knowledge with Multi-granularity Attention for Review Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.750640</td>
<td>0.803902</td>
<td><a href="https://www.semanticscholar.org/paper/368ffb89988eef9898440569e5378d2cb18cddd2">2: Exploiting Reasoning Chains for Multi-hop Science Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737163</td>
<td>0.916426</td>
<td><a href="https://www.semanticscholar.org/paper/c35f53f7e4a2b219cf7fce7b16fa2704d86ff1db">0: Sequential multi‐headed attention for entity‐based relational neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727329</td>
<td>0.996090</td>
<td><a href="https://www.semanticscholar.org/paper/0680f04750b1e257ffdd161e85382031dc73ea7f">68: End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752735</td>
<td>0.996015</td>
<td><a href="https://www.semanticscholar.org/paper/f2e50e2ee4021f199877c8920f1f984481c723aa">286: Text Understanding with the Attention Sum Reader Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727655</td>
<td>0.995792</td>
<td><a href="https://www.semanticscholar.org/paper/2676dbacd94257c344d8888e9c1147064b4d96c5">1: A Fully Attention-Based Information Retriever</a></td>
</tr>
<tr>
<td>0</td>
<td>0.797486</td>
<td>0.995767</td>
<td><a href="https://www.semanticscholar.org/paper/525f65936c331b0b766c7aea0eae64c595704c50">40: Mnemonic Reader for Machine Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.725115</td>
<td>0.995496</td>
<td><a href="https://www.semanticscholar.org/paper/12e20e4ea572dbe476fd894c5c9a9930cf250dd2">77: MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.753623</td>
<td>0.995403</td>
<td><a href="https://www.semanticscholar.org/paper/e148b1bff6a6959fa15f8bc5c5582d8a04d220f9">72: Reinforced Mnemonic Reader for Machine Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.724514</td>
<td>0.994789</td>
<td><a href="https://www.semanticscholar.org/paper/62f88e8fc3b44c5627f2b4721b08498d78103893">51: Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.606406</td>
<td>0.994353</td>
<td><a href="https://www.semanticscholar.org/paper/3d6fca4617916c2507b4db008b09b3f9d5b14d6d">24: Accurate Supervised and Semi-Supervised Machine Reading for Long Documents</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732824</td>
<td>0.993898</td>
<td><a href="https://www.semanticscholar.org/paper/c6e5df6322659276da6133f9b734a389d7a255e8">361: Attention-over-Attention Neural Networks for Reading Comprehension</a></td>
</tr>
</table></html>
