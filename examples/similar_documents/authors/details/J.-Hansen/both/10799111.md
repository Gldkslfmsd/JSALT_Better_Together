<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/00a241f87bbc0f34d412c2cd76e1556634229136">39: Speaker identification with whispered speech based on modified LFCC parameters and feature mapping</a></td>
</tr>
<tr>
<td>0</td>
<td>0.951604</td>
<td>0.977175</td>
<td>NA:212617764</td>
</tr>
<tr>
<td>1</td>
<td>0.945610</td>
<td>0.984821</td>
<td><a href="https://www.semanticscholar.org/paper/9d5279c8c6d7e26366071b0ea52aba7a4ff75795">7: Speaker Identification for Whispered Speech Using a Training Feature Transformation from Neutral to Whisper</a></td>
</tr>
<tr>
<td>0</td>
<td>0.926378</td>
<td>0.973772</td>
<td><a href="https://www.semanticscholar.org/paper/4ee24d54f358bd3cb9515c3ddbad14bba73861e6">72: Speaker Identification Within Whispered Speech Audio Streams</a></td>
</tr>
<tr>
<td>0</td>
<td>0.892042</td>
<td>0.898057</td>
<td><a href="https://www.semanticscholar.org/paper/dc1710fd54e39c03657f79c47d8e9e75a629cdfa">3: Speaker identification with whispered speech mode using MFCC: Challenges to whispered speech identification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.879594</td>
<td>0.923869</td>
<td><a href="https://www.semanticscholar.org/paper/70dd6d70b982c1a18764e1ae1906c6545911e754">1: Speech Processing for Robust Speaker Recognition: Analysis and Advancements for Whispered Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.875305</td>
<td>0.953268</td>
<td><a href="https://www.semanticscholar.org/paper/0fecb7f39e82f6fe65829fccb5c645ec5e19f31d">0: Combining Evidences from Mel Cepstral and Cochlear Cepstral Features for Speaker Recognition Using Whispered Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.872396</td>
<td>0.830612</td>
<td><a href="https://www.semanticscholar.org/paper/c9b6d70ca8c6b5dd687eb380f1fc8aac1a93276e">2: Speaker Identification Through Natural and Whisper Speech Signal</a></td>
</tr>
<tr>
<td>0</td>
<td>0.870344</td>
<td>0.960132</td>
<td><a href="https://www.semanticscholar.org/paper/f8a911f81d3e0d98f315422f7a267788b8494a91">1: Text-independent Speaker Identification in Emotional and Whispered Speech Environments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.869323</td>
<td>0.958596</td>
<td><a href="https://www.semanticscholar.org/paper/449cd366a891f1d7cc9661b55da6a429cbf5ce04">0: SPEAKER IDENTIFICATION WITH WHISPERED SPEECH : DIFFERENT METHODS AND USE OF TIMBRAL AUDIO DESCRIPTORS</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800879</td>
<td>0.990964</td>
<td><a href="https://www.semanticscholar.org/paper/682e0e8df32c121888e0f09082e1d88a554f67cc">37: Whispering Speaker Identification</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.988598</td>
<td><a href="https://www.semanticscholar.org/paper/9b17432e27a06c6a77926b642d8d082b65e612e0">0: Open-set Speaker Identification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807418</td>
<td>0.985563</td>
<td><a href="https://www.semanticscholar.org/paper/eccf0878ba5b6cc6969ed68aaa31d17c79748f82">2: Joint Factor Analysis of Channel Mismatch in Whispering Speaker Verification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.889451</td>
<td>0.983471</td>
<td><a href="https://www.semanticscholar.org/paper/6b47fa0e10403d2da0abd7bb37eb4062cee34dbd">7: Speaker Identification Using Whispered Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.686647</td>
<td>0.982697</td>
<td><a href="https://www.semanticscholar.org/paper/eb2cead11d5d50115d936e80ad919e643bb8b019">2: Speaker Verification Systems: A Comprehensive Review</a></td>
</tr>
<tr>
<td>0</td>
<td>0.688298</td>
<td>0.982153</td>
<td><a href="https://www.semanticscholar.org/paper/eb08000eae2ce49225d1c6b7e7535a62b3a79466">13: A new speaker identification algorithm for gaming scenarios</a></td>
</tr>
<tr>
<td>0</td>
<td>0.897939</td>
<td>0.981603</td>
<td><a href="https://www.semanticscholar.org/paper/bfeba001f737d060dc86274ca8b9351b2468013a">22: Speaker identification for whispered speech based on frequency warping and score competition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.770808</td>
<td>0.981573</td>
<td><a href="https://www.semanticscholar.org/paper/526ec7641df5a08d66c985b9485ad792f82f7e14">1: Combining the glottal mixture model (GLOMM) with UBM for speaker recognition</a></td>
</tr>
</table></html>
