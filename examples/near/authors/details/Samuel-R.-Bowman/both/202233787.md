<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/3cd331c997e90f737810aad6fcce4d993315189f">67: Investigating BERT’s Knowledge of Language: Five Analysis Methods with NPIs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812563</td>
<td>0.625707</td>
<td><a href="https://www.semanticscholar.org/paper/47eaee2118831c958ce696f91139710bbecde229">2: An Error Analysis Framework for Shallow Surface Realization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810983</td>
<td>0.927274</td>
<td><a href="https://www.semanticscholar.org/paper/cc8a93f934b39ffb437ab6a72ddc2549cf6c1360">18: How well do NLI models capture verb veridicality?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807516</td>
<td>0.955392</td>
<td><a href="https://www.semanticscholar.org/paper/0e6165ec3151e7e758d4ac90e0e009a4e3bbbebd">9: Attention Can Reflect Syntactic Structure (If You Let It)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807408</td>
<td>0.954053</td>
<td><a href="https://www.semanticscholar.org/paper/9a5938af01b4d83793b6743c3f7560b36c6a212f">9: On Losses for Modern Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801223</td>
<td>0.001801</td>
<td>NA:215879497</td>
</tr>
<tr>
<td>0</td>
<td>0.800401</td>
<td>0.974385</td>
<td><a href="https://www.semanticscholar.org/paper/b68b2e81ae2de647394ec05ee62ecf108bf2b50a">77: Eliciting Knowledge from Language Models Using Automatically Generated Prompts</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794786</td>
<td>0.975757</td>
<td><a href="https://www.semanticscholar.org/paper/5a9001cdccdb8b1de227a45eccc503d32d1a2464">30: What Does My QA Model Know? Devising Controlled Probes Using Expert Knowledge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794478</td>
<td>0.603720</td>
<td><a href="https://www.semanticscholar.org/paper/cead64ab532cae2792a9cc0eb60fb161c5a1db36">0: Integrating and Evaluating Extra-linguistic Context in Neural Machine Translation First</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793483</td>
<td>0.797425</td>
<td><a href="https://www.semanticscholar.org/paper/ea77b71385648f5c6ea533a0e3685f0e76302eba">14: A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785661</td>
<td>0.992834</td>
<td><a href="https://www.semanticscholar.org/paper/7ddb18fc67f13ff8ea5467bc04eb41666f8e7cb8">4: AND does not mean OR: Using Formal Languages to Study Language Models’ Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.833962</td>
<td>0.991588</td>
<td><a href="https://www.semanticscholar.org/paper/4bda9767c11a97a3d1a83577cb8ec94f16ceccb5">0: A Closer Look at Linguistic Knowledge in Masked Language Models: The Case of Relative Clauses in American English</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804977</td>
<td>0.991481</td>
<td><a href="https://www.semanticscholar.org/paper/b56e2e7b93be127c953b6ad18230d5905051d23b">118: BLiMP: A Benchmark of Linguistic Minimal Pairs for English</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786575</td>
<td>0.991468</td>
<td><a href="https://www.semanticscholar.org/paper/a0e49f65b6847437f262c59d0d399255101d0b75">256: What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.690980</td>
<td>0.991393</td>
<td><a href="https://www.semanticscholar.org/paper/53396f5401e1b0bd3ba2f2ba69bc09ce1034fc09">0: Vyākarana: A Colorless Green Benchmark for Syntactic Evaluation in Indic Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.780313</td>
<td>0.991254</td>
<td><a href="https://www.semanticscholar.org/paper/055fac05cd424e7b1bdcd359ff7980ca8d938ef3">34: Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.776464</td>
<td>0.991167</td>
<td><a href="https://www.semanticscholar.org/paper/165d51a547cd920e6ac55660ad5c404dcb9562ed">157: Open Sesame: Getting inside BERT’s Linguistic Knowledge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691718</td>
<td>0.991030</td>
<td><a href="https://www.semanticscholar.org/paper/efeab0dcdb4c1cce5e537e57745d84774be99b9a">311: Assessing BERT's Syntactic Abilities</a></td>
</tr>
<tr>
<td>0</td>
<td>0.747503</td>
<td>0.990448</td>
<td><a href="https://www.semanticscholar.org/paper/455a8838cde44f288d456d01c76ede95b56dc675">581: A Structural Probe for Finding Syntax in Word Representations</a></td>
</tr>
</table></html>
