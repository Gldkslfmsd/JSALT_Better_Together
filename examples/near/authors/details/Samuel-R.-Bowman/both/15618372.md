<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/7c05a4ffee7e159e34b2efea7e44d994333ec628">123: Recursive Neural Networks Can Learn Logical Semantics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.930254</td>
<td>0.975503</td>
<td><a href="https://www.semanticscholar.org/paper/4ea80c206b8ad73a6d320c9d8ed0321d84fe6d85">32: Recursive Neural Networks for Learning Logical Semantics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825670</td>
<td>0.917304</td>
<td><a href="https://www.semanticscholar.org/paper/04d1a26c2516dc14a765112a63ec60dc3cb3de72">56: Tree-Structured Composition in Neural Networks without Tree-Structured Architectures</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823592</td>
<td>0.920170</td>
<td><a href="https://www.semanticscholar.org/paper/3ecd3e00bbbfd94446c3adc9c6878de27e250f7c">568: Learning Dependency-Based Compositional Semantics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821471</td>
<td>0.920049</td>
<td><a href="https://www.semanticscholar.org/paper/d3b95595c81d8f8f67e579827f35ac40452a5908">0: Attentive Tree-structured Network for Monotonicity Reasoning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813748</td>
<td>0.939536</td>
<td><a href="https://www.semanticscholar.org/paper/027f9695189355d18ec6be8e48f3d23ea25db35d">150: Learning to Compose Task-Specific Tree Structures</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800180</td>
<td>0.836678</td>
<td><a href="https://www.semanticscholar.org/paper/577d44a10b424a55165a6bf4839bafce2c695302">3: SyGNS: A Systematic Generalization Testbed Based on Natural Language Semantics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795317</td>
<td>0.894712</td>
<td><a href="https://www.semanticscholar.org/paper/d7dc79050f17154e7cf57501cf6cab1b9c18f232">86: Unsupervised Recurrent Neural Network Grammars</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794985</td>
<td>0.608115</td>
<td><a href="https://www.semanticscholar.org/paper/007112213ece771be72cbecfd59f048209facabd">1174: A simple neural network module for relational reasoning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793380</td>
<td>0.803457</td>
<td><a href="https://www.semanticscholar.org/paper/be9136ac2ab5796f0685ebb483718522f301952c">1: A Machine Learning Benchmark with Meaning: Learnability and Verb Semantics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731865</td>
<td>0.989692</td>
<td><a href="https://www.semanticscholar.org/paper/81bd1081df12c554f5b577677eb1a3975f728476">29: Recognizing Entailment and Contradiction by Tree-based Convolution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.655568</td>
<td>0.988866</td>
<td><a href="https://www.semanticscholar.org/paper/f33e86970c11f9bb6d0abb60acdc9274d5c3f342">325: Applying deep learning to answer selection: A study and an open task</a></td>
</tr>
<tr>
<td>0</td>
<td>0.769282</td>
<td>0.985689</td>
<td><a href="https://www.semanticscholar.org/paper/c3efd9334114f82644ed14c4b6083defc6209d85">38: No Need to Pay Attention: Simple Recurrent Neural Networks Work!</a></td>
</tr>
<tr>
<td>0</td>
<td>0.675149</td>
<td>0.984825</td>
<td><a href="https://www.semanticscholar.org/paper/698d675ba7134ac701de810c9ca4a6de72cb414b">159: Character-Level Question Answering with Attention</a></td>
</tr>
<tr>
<td>0</td>
<td>0.646860</td>
<td>0.984267</td>
<td><a href="https://www.semanticscholar.org/paper/fd26f8069cfa528463fdf8a90864587e997ee86d">24: A Multi-View Fusion Neural Network for Answer Selection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.685366</td>
<td>0.983863</td>
<td><a href="https://www.semanticscholar.org/paper/2719eb601b94dbc670a6246d11abaa72540c24c0">12: Neural Networks Models for Entity Discovery and Linking</a></td>
</tr>
<tr>
<td>0</td>
<td>0.655173</td>
<td>0.983452</td>
<td><a href="https://www.semanticscholar.org/paper/f3399e9a516983e5f4c5a27abb8663aa1f745d74">77: Semi-supervised Question Retrieval with Gated Convolutions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.722844</td>
<td>0.983192</td>
<td><a href="https://www.semanticscholar.org/paper/1261fe9bfde319abcc5d011bc70f7e7547b5258f">212: Improved Representation Learning for Question Answer Matching</a></td>
</tr>
<tr>
<td>0</td>
<td>0.672944</td>
<td>0.983145</td>
<td><a href="https://www.semanticscholar.org/paper/812034099dd66df95a9f4ff741e17df62916ef4c">133: Simple Question Answering by Attentive Convolutional Neural Network</a></td>
</tr>
</table></html>
