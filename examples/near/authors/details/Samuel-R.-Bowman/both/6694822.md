<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/a97dc52807d80454e78d255f9fbd7b0fab56bd03">91: Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.770437</td>
<td>-0.019471</td>
<td>NA:198973259</td>
</tr>
<tr>
<td>0</td>
<td>0.767375</td>
<td>0.461964</td>
<td><a href="https://www.semanticscholar.org/paper/d13d3796879335c53ced2daaec7113eccc95b1bf">11: Feature Weight Optimization for Discourse-Level SMT</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765898</td>
<td>0.877807</td>
<td><a href="https://www.semanticscholar.org/paper/db53e9926d7092d7c839c38123be85e84840192a">15: Discourse Representation Parsing for Sentences and Documents</a></td>
</tr>
<tr>
<td>0</td>
<td>0.743733</td>
<td>0.848153</td>
<td><a href="https://www.semanticscholar.org/paper/558fac117b828ab9a31357bc998a5ba04737ca9e">82: Learning Bilingual Word Representations by Marginalizing Alignments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.741127</td>
<td>0.919112</td>
<td><a href="https://www.semanticscholar.org/paper/cfd468bf8b138b1eed6b32ad262a1a794f9440b4">51: A Stacking Gated Neural Architecture for Implicit Discourse Relation Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738034</td>
<td>0.809891</td>
<td><a href="https://www.semanticscholar.org/paper/d912c1aee982d1fc507826158a8f7d2fbb8ec5ff">38: Supervised Sentence Fusion with Single-Stage Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737015</td>
<td>0.085981</td>
<td><a href="https://www.semanticscholar.org/paper/2c48131c4a58a2b78a4989f882887871d3249b1e">1: Modeling (in)variability of human judgments for text summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734704</td>
<td>-0.019471</td>
<td>NA:217246077</td>
</tr>
<tr>
<td>0</td>
<td>0.733703</td>
<td>0.907004</td>
<td><a href="https://www.semanticscholar.org/paper/3abbd6d6978d1af278a73de7e4c2b06f962a548d">31: Unsupervised Query-Focused Multi-Document Summarization using the Cross Entropy Method</a></td>
</tr>
<tr>
<td>0</td>
<td>0.644420</td>
<td>0.995023</td>
<td><a href="https://www.semanticscholar.org/paper/bb1087e8dee2039f773c381a3449a1c382482da6">105: Question Answering through Transfer Learning from Large Fine-grained Supervision Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.720780</td>
<td>0.991014</td>
<td><a href="https://www.semanticscholar.org/paper/afc2850945a871e72c245818f9bc141bd659b453">273: Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.604998</td>
<td>0.988764</td>
<td><a href="https://www.semanticscholar.org/paper/060a8d5a3c1e654e76e773129ce755bb1fe863fc">26: Sequence Tagging with Contextual and Non-Contextual Subword Representations: A Multilingual Evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.553790</td>
<td>0.987313</td>
<td><a href="https://www.semanticscholar.org/paper/f53e2ae46470b89cd1ce6e3bf1d60d9c59722ce1">617: WikiQA: A Challenge Dataset for Open-Domain Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.603903</td>
<td>0.985972</td>
<td><a href="https://www.semanticscholar.org/paper/3fa6ccf2e0cf89fe758b9d634030102f9c3f928a">70: Modelling Domain Relationships for Transfer Learning on Retrieval-based Question Answering Systems in E-commerce</a></td>
</tr>
<tr>
<td>0</td>
<td>0.597852</td>
<td>0.985835</td>
<td><a href="https://www.semanticscholar.org/paper/3238fd7f679d0d0d99c3c7feab767fbfe40ae363">1: Keyword-Attentive Deep Semantic Matching</a></td>
</tr>
<tr>
<td>0</td>
<td>0.606389</td>
<td>0.985769</td>
<td><a href="https://www.semanticscholar.org/paper/641601007c5eb3596b4335a79551f2f7eb3ba399">18: A Multi-Attention based Neural Network with External Knowledge for Story Ending Predicting Task</a></td>
</tr>
<tr>
<td>0</td>
<td>0.657869</td>
<td>0.985361</td>
<td><a href="https://www.semanticscholar.org/paper/5fb5a45f69b2b68b5da3579f776613f931c7aa2c">17: InferLite: Simple Universal Sentence Representations from Natural Language Inference Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.710680</td>
<td>0.984336</td>
<td><a href="https://www.semanticscholar.org/paper/de94bdb155a2a57b50dbd46c616b18b213228089">10: TRANSFER LEARNING IN NATURAL LANGUAGE PRO-</a></td>
</tr>
</table></html>
