<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/d82b55c35c8673774a708353838918346f6c006f">1721: Generating Sentences from a Continuous Space</a></td>
</tr>
<tr>
<td>0</td>
<td>0.952965</td>
<td>0.836237</td>
<td><a href="https://www.semanticscholar.org/paper/f2b8480690f563bc9132ad7bad6df47e8ec88af2">0: Workshop Track -iclr 2016 Generating Sentences from a Continuous Space</a></td>
</tr>
<tr>
<td>0</td>
<td>0.874194</td>
<td>0.731474</td>
<td><a href="https://www.semanticscholar.org/paper/4bf05799ca158e5f6b1644fea066c51dafe05bc6">6: A topic-driven language model for learning to generate diverse sentences</a></td>
</tr>
<tr>
<td>0</td>
<td>0.853221</td>
<td>0.505461</td>
<td><a href="https://www.semanticscholar.org/paper/eea0299ed6b3ee2caaffa1c4fa216309dd07014e">0: Learning Meaningful Sentence Embedding Based on Recursive Auto-encoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.847122</td>
<td>0.736993</td>
<td><a href="https://www.semanticscholar.org/paper/d1810d382f5ea60ee70fd4460ad8311a4b3c58d1">1: An RNN Model for Generating Sentences with a Desired Word at a Desired Position</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825135</td>
<td>0.958704</td>
<td><a href="https://www.semanticscholar.org/paper/af6b3893655e4641daad096a6b29d8728db1f08e">20: A Transformer-Based Variational Autoencoder for Sentence Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823550</td>
<td>0.569334</td>
<td><a href="https://www.semanticscholar.org/paper/e44da7d8c71edcc6e575fa7faadd5e75785a7901">372: Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820287</td>
<td>0.665931</td>
<td><a href="https://www.semanticscholar.org/paper/ecf1ce2e3d792a698dfef17c6518506be961a157">8: Natural Language Multitasking: Analyzing and Improving Syntactic Saliency of Hidden Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.815234</td>
<td>0.725462</td>
<td><a href="https://www.semanticscholar.org/paper/d7dc79050f17154e7cf57501cf6cab1b9c18f232">86: Unsupervised Recurrent Neural Network Grammars</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809429</td>
<td>0.959983</td>
<td><a href="https://www.semanticscholar.org/paper/1743756a62312ca571d0feae53507b22dde810e2">0: Are Latent Sentence Vectors Cross-Linguistically Invariant ?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756285</td>
<td>0.994312</td>
<td><a href="https://www.semanticscholar.org/paper/7d77a29f2e1dc796d202d6cf01f299da7c197c22">297: Improved Variational Autoencoders for Text Modeling using Dilated Convolutions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.754742</td>
<td>0.986400</td>
<td><a href="https://www.semanticscholar.org/paper/24182dd104351de9c66848b68b3f6336256f3f89">5: Preventing Posterior Collapse in Sequence VAEs with Pooling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.696509</td>
<td>0.985863</td>
<td><a href="https://www.semanticscholar.org/paper/bde93bfbe651a294398979c48e753c0258c38292">11: Polarized-VAE: Proximity Based Disentangled Representation Learning for Text Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748057</td>
<td>0.984297</td>
<td><a href="https://www.semanticscholar.org/paper/2bc58fc27652e3935a7358bc356f6953b1658e53">16: A Stable Variational Autoencoder for Text Modelling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.755427</td>
<td>0.983027</td>
<td><a href="https://www.semanticscholar.org/paper/c0429b83e4b7dda7b3dc640c48f4b8167bf8147d">6: Improving Variational Autoencoder for Text Modelling with Timestep-Wise Regularisation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.743077</td>
<td>0.982830</td>
<td><a href="https://www.semanticscholar.org/paper/4f7b108830de2e7964b6e1a89bf1c2da60140a34">45: A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text</a></td>
</tr>
<tr>
<td>0</td>
<td>0.763203</td>
<td>0.982417</td>
<td><a href="https://www.semanticscholar.org/paper/7269d4721ca2b6b555bee86aad97f562fa5cd9ac">1: On Posterior Collapse and Encoder Feature Dispersion in Sequence VAEs.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.741864</td>
<td>0.982298</td>
<td><a href="https://www.semanticscholar.org/paper/81aee1c76e6bd4b915b016f7a8b70abe42841dd8">194: A Hybrid Convolutional Variational Autoencoder for Text Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705404</td>
<td>0.980030</td>
<td><a href="https://www.semanticscholar.org/paper/9d6dad50a831112ae328c1b626e77e5207c5ea68">14: On the Importance of the Kullback-Leibler Divergence Term in Variational Autoencoders for Text Generation</a></td>
</tr>
</table></html>
