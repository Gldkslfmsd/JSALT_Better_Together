<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/ba8215e77f35b0d947c7cec39c45df4516e93421">70: Do Attention Heads in BERT Track Syntactic Dependencies?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.840951</td>
<td>0.755127</td>
<td><a href="https://www.semanticscholar.org/paper/113b01fc9bd46ba89f78fb43cb1eec61310fe401">0: Combining Improvements for Exploiting Dependency Trees in Neural Semantic Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810179</td>
<td>0.807601</td>
<td><a href="https://www.semanticscholar.org/paper/ccd55ab7bd17645fcc7022e0a7aa2febd1375380">0: A New Fine-Tuning Architecture Based on Bert for Word Relation Extraction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809192</td>
<td>0.334228</td>
<td><a href="https://www.semanticscholar.org/paper/42c9f88423e6b0cf38a8dc03a5b3f961efb5d8d8">12: Data-driven Dependency Parsing With Empty Heads</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805013</td>
<td>0.754900</td>
<td><a href="https://www.semanticscholar.org/paper/8595c3cf02e8530be0ad2537f55210518676dd64">3: Source Dependency-Aware Transformer with Supervised Self-Attention</a></td>
</tr>
<tr>
<td>1</td>
<td>0.801411</td>
<td>0.997651</td>
<td><a href="https://www.semanticscholar.org/paper/dd24067c396f4b5a6500a71101ff1dc8ccb8811f">5: The heads hypothesis: A unifying statistical approach towards understanding multi-headed attention in BERT</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800540</td>
<td>0.649293</td>
<td><a href="https://www.semanticscholar.org/paper/9feb366b4cebb93b3a87622b889c61d484526bd0">9: Please Mind the Root: Decoding Arborescences for Dependency Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.797776</td>
<td>0.972411</td>
<td><a href="https://www.semanticscholar.org/paper/494c1f745dbb7625e86e9a222c480e40949b8dad">0: Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-Sentence Dependency Graph</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794410</td>
<td>0.945401</td>
<td><a href="https://www.semanticscholar.org/paper/645a96e5c474d919415850892880005e4ad3fb43">13: Does BERT agree? Evaluating knowledge of structure dependence through agreement relations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790144</td>
<td>0.930732</td>
<td><a href="https://www.semanticscholar.org/paper/ada3753829d04e341807d79539b836518e6198b7">6: Assessing BERTâ€™s ability to learn Italian syntax: a study on null-subject and agreement phenomena</a></td>
</tr>
<tr>
<td>0</td>
<td>0.570545</td>
<td>0.997082</td>
<td><a href="https://www.semanticscholar.org/paper/b496b11fb2091678cc2d299cc778046d9a64b0a4">95: A BERT Baseline for the Natural Questions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.622511</td>
<td>0.997055</td>
<td><a href="https://www.semanticscholar.org/paper/f332a615c33c69f54dfcb9a8b14f96e8b5725def">0: Sub-Character Tokenization for Chinese Pretrained Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.675141</td>
<td>0.997036</td>
<td><a href="https://www.semanticscholar.org/paper/52fa450740913a6cdcb4d9395b45e203f46cab79">52: Giving BERT a Calculator: Finding Operations and Arguments with Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691287</td>
<td>0.996852</td>
<td><a href="https://www.semanticscholar.org/paper/330729fc50df37fb4a1ec560edd3008b4738a6b1">44: MMM: Multi-stage Multi-task Learning for Multi-choice Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.668373</td>
<td>0.996692</td>
<td><a href="https://www.semanticscholar.org/paper/06396c7cd5d223a1776abf8811359ec7bc05d420">0: Knowledge-Augmented Methods for Natural Language Processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.675938</td>
<td>0.996520</td>
<td><a href="https://www.semanticscholar.org/paper/395aae6e7a79e5760457ca38e868acc970016230">8: MATE: Multi-view Attention for Table Transformer Efficiency</a></td>
</tr>
<tr>
<td>0</td>
<td>0.642525</td>
<td>0.996172</td>
<td><a href="https://www.semanticscholar.org/paper/0a955d2ddf8ced245061a86d31033634233de98c">3: Analysing the Effect of Masking Length Distribution of MLM: An Evaluation Framework and Case Study on Chinese MRC Datasets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.704797</td>
<td>0.996102</td>
<td><a href="https://www.semanticscholar.org/paper/9e9d919c1de684ca42c8b581ec62c7aa685f431e">315: On the Cross-lingual Transferability of Monolingual Representations</a></td>
</tr>
</table></html>
