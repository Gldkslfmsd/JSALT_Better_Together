<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/2de8019fd7d04e3d1305d5efaeeb591f0d966550">36: Listen and Fill in the Missing Letters: Non-Autoregressive Transformer for Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.817678</td>
<td>0.842635</td>
<td><a href="https://www.semanticscholar.org/paper/da84e75f9707a1f5465369830c6704d83fccf998">7: TalkNet: Fully-Convolutional Non-Autoregressive Speech Synthesis Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810041</td>
<td>0.902762</td>
<td><a href="https://www.semanticscholar.org/paper/ee15b0d8b7de63bdfc31532e866dfeb675442964">1: s-Transformer: Segment-Transformer for Robust Neural Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805339</td>
<td>0.092493</td>
<td><a href="https://www.semanticscholar.org/paper/6fc40b1e0cf400cc5d957359bcbf51d013aeaf3b">1: Split Acoustic Modeling in Decoder for Phoneme Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795896</td>
<td>0.978373</td>
<td><a href="https://www.semanticscholar.org/paper/f2bb7e2f5a1afad5370159c15760c44df93c0438">109: Very Deep Self-Attention Networks for End-to-End Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.787664</td>
<td>0.644423</td>
<td><a href="https://www.semanticscholar.org/paper/63880b57b95de8afd73036e55b9c4bccb7a528b9">420: Deep Voice: Real-time Neural Text-to-Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784381</td>
<td>0.318915</td>
<td><a href="https://www.semanticscholar.org/paper/6662ac196439ff4efaf4caf9bef721de249e5fef">0: DEEPA: A Deep Neural Analyzer for Speech and Singing Vocoding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781767</td>
<td>0.344853</td>
<td><a href="https://www.semanticscholar.org/paper/d7d93f217ed1a92ad26a9489689d308270639717">5: Synthetic speech detection through short-term and long-term prediction traces</a></td>
</tr>
<tr>
<td>0</td>
<td>0.780920</td>
<td>0.366377</td>
<td><a href="https://www.semanticscholar.org/paper/284de726e700a6c52f9f8fb9f3de4d4b0ff778bb">28: A prioritized grid long short-term memory RNN for speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.777403</td>
<td>0.565214</td>
<td><a href="https://www.semanticscholar.org/paper/e5dd20eb15f0e4811156cce8b4cf930bd002d43e">184: Speaker diarization using deep neural network embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.829970</td>
<td>0.997869</td>
<td><a href="https://www.semanticscholar.org/paper/24986724855f6274456bc7018d937ce9a96dbbea">3: An Improved Single Step Non-autoregressive Transformer for Automatic Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767934</td>
<td>0.995443</td>
<td><a href="https://www.semanticscholar.org/paper/1a671afdac8e7b759cf3b5ec7d03d485c76a989c">54: Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict</a></td>
</tr>
<tr>
<td>0</td>
<td>0.754979</td>
<td>0.995105</td>
<td><a href="https://www.semanticscholar.org/paper/644e0ed2009d1890821b477568b3a4b4717935f8">16: Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810069</td>
<td>0.993665</td>
<td><a href="https://www.semanticscholar.org/paper/4c2c354de20cc812c053c1e80811f1b4917ce281">18: Spike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.776203</td>
<td>0.993627</td>
<td><a href="https://www.semanticscholar.org/paper/533a8eaa4a224d0392011575c47f0e8ba68e3fed">22: Align-Refine: Non-Autoregressive Speech Recognition via Iterative Realignment</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742733</td>
<td>0.993337</td>
<td><a href="https://www.semanticscholar.org/paper/92255f5be9f254057f809943398c156808ef47eb">2: Transformer-based end-to-end speech recognition with residual Gaussian-based self-attention</a></td>
</tr>
<tr>
<td>0</td>
<td>0.771250</td>
<td>0.992957</td>
<td><a href="https://www.semanticscholar.org/paper/05082bbec600b65e85b04f9fbf7081f4a734d488">10: Transformer-Based End-to-End Speech Recognition with Local Dense Synthesizer Attention</a></td>
</tr>
<tr>
<td>0</td>
<td>0.721771</td>
<td>0.991931</td>
<td><a href="https://www.semanticscholar.org/paper/6ba48aa768374a34d426aa7fd5b6c2f062749c8e">0: Conversational Speech Recognition By Learning Conversation-level Characteristics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.710989</td>
<td>0.991766</td>
<td><a href="https://www.semanticscholar.org/paper/07a9f47885cae97efb7b4aa109392128532433da">28: Hard-Coded Gaussian Attention for Neural Machine Translation</a></td>
</tr>
</table></html>
