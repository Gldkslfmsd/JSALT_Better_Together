<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/053912e76e50c9f923a1fc1c173f1365776060cc">875: On optimization methods for deep learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834639</td>
<td>0.615751</td>
<td><a href="https://www.semanticscholar.org/paper/3f7f6c2b7f2264b316d767623834379878212fc8">12: Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.822795</td>
<td>0.792185</td>
<td><a href="https://www.semanticscholar.org/paper/38e1048975e87ac15079eeb398d4faededff9293">2: Analyzing the Effect of Optimization Strategies in Deep Convolutional Neural Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.822475</td>
<td>0.636662</td>
<td><a href="https://www.semanticscholar.org/paper/e699ce7b164ea0dd46e8991d1ec4921624e8b8f9">0: Deep Gradient Boosting</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812117</td>
<td>0.760855</td>
<td><a href="https://www.semanticscholar.org/paper/266ac19137a3e801a6e06e506265ff34eb1cbd11">39: Deep Neural Network Hyperparameter Optimization with Orthogonal Array Tuning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809333</td>
<td>0.810473</td>
<td><a href="https://www.semanticscholar.org/paper/e6806bbd884a80ea75eb24b9b1e80fd4a5fc437b">3: Performance Evaluation of Deep Learning frameworks on Computer Vision problems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804465</td>
<td>0.579859</td>
<td><a href="https://www.semanticscholar.org/paper/a68eb478401d9d5d95fb5f92f838eb1a914170dc">54: Evolutionary neural AutoML for deep learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804067</td>
<td>0.258983</td>
<td><a href="https://www.semanticscholar.org/paper/97af2083449b8ae1a4453bc59ab790ad6b1c93d9">0: Evolving neural selection with adaptive regularization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800760</td>
<td>0.225168</td>
<td><a href="https://www.semanticscholar.org/paper/208cd4b25768f0096fb2e80e7690473da0e2a563">422: Meta-learning with differentiable closed-form solvers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800227</td>
<td>0.486805</td>
<td><a href="https://www.semanticscholar.org/paper/6666d9e27ad3949433e292099daa31aff33ff317">0: Deep curriculum learning optimization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.689251</td>
<td>0.975834</td>
<td><a href="https://www.semanticscholar.org/paper/b8012351bc5ebce4a4b3039bbbba3ce393bc3315">966: An empirical evaluation of deep architectures on problems with many factors of variation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.746490</td>
<td>0.975506</td>
<td><a href="https://www.semanticscholar.org/paper/e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1">638: Large-scale deep unsupervised learning using graphics processors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.746584</td>
<td>0.970800</td>
<td><a href="https://www.semanticscholar.org/paper/83911fe24c47ba4495a201c9f9caf35d14448a56">36: Stacked denoising autoencoder and dropout together to prevent overfitting in deep neural network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.526803</td>
<td>0.969206</td>
<td><a href="https://www.semanticscholar.org/paper/836acf6fc99ebf81d219e2b67f7ab25efc29a6a4">299: Pylearn2: a machine learning research library</a></td>
</tr>
<tr>
<td>0</td>
<td>0.721058</td>
<td>0.968278</td>
<td><a href="https://www.semanticscholar.org/paper/5d5d4f49d6443c8529a6f5ebef5c499d47a869da">232: Improving Neural Networks with Dropout</a></td>
</tr>
<tr>
<td>0</td>
<td>0.644069</td>
<td>0.967791</td>
<td><a href="https://www.semanticscholar.org/paper/327d3df8ea2020882827d6bace1e26c9d24309c2">238: The dropout learning algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758240</td>
<td>0.967305</td>
<td><a href="https://www.semanticscholar.org/paper/ccf415df5a83b343dae261286d29a40e8b80e6c6">394: The Difficulty of Training Deep Architectures and the Effect of Unsupervised Pre-Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.633762</td>
<td>0.967061</td>
<td><a href="https://www.semanticscholar.org/paper/bd19dd1ccd9412171c6932d1556eeb47131b30ce">76: Zero-bias autoencoders and the benefits of co-adapting features</a></td>
</tr>
<tr>
<td>0</td>
<td>0.690412</td>
<td>0.965708</td>
<td><a href="https://www.semanticscholar.org/paper/72d32c986b47d6b880dad0c3f155fe23d2939038">532: Deep Learning of Representations: Looking Forward</a></td>
</tr>
</table></html>
