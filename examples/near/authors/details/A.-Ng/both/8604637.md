<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/d1208ac421cf8ff67b27d93cd19ae42b8d596f95">682: Deep learning with COTS HPC systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.876512</td>
<td>0.798861</td>
<td><a href="https://www.semanticscholar.org/paper/f6173885cf30570e64f175e5130ab983e765d6ac">28: On Scale-out Deep Learning Training for Cloud and HPC</a></td>
</tr>
<tr>
<td>0</td>
<td>0.850669</td>
<td>0.651951</td>
<td><a href="https://www.semanticscholar.org/paper/c26ddc4be489c265961f6418dff385fc5ba16489">0: Challenges for Machine Learning on Distributed Platforms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820133</td>
<td>0.883156</td>
<td><a href="https://www.semanticscholar.org/paper/83735f0590cf1c7dd9f83dbab8f82a1d66f6892a">1: Distributed training of deep neural networks with spark: The MareNostrum experience</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818581</td>
<td>0.908450</td>
<td><a href="https://www.semanticscholar.org/paper/b6b9059c9d034d5032dd0725b81f1976f701f7be">2: Deep Learning on Large-Scale Muticore Clusters</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807082</td>
<td>0.515941</td>
<td><a href="https://www.semanticscholar.org/paper/615843b8cd63a98688dcf9c3746717ddcace8f59">0: Architectural Requirements for Deep Learning Workloads in HPC Environments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804742</td>
<td>0.724278</td>
<td><a href="https://www.semanticscholar.org/paper/1089a3db4aa185eea2eec1211323772bcdb9d6c9">30: Accelerating Deep Learning Workloads Through Efficient Multi-Model Execution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804384</td>
<td>0.651205</td>
<td><a href="https://www.semanticscholar.org/paper/35538d57064a367a0274ec03b285544d2fa4e8a4">0: Benchmarking Neural Networks on Heterogeneous Hardware Resources</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803842</td>
<td>0.412650</td>
<td><a href="https://www.semanticscholar.org/paper/52dcb3739b29f51931f442dee46cad776996ee39">4: Deploying Scientific Al Networks at Petaflop Scale on Secure Large Scale HPC Production Systems with Containers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793972</td>
<td>0.672167</td>
<td><a href="https://www.semanticscholar.org/paper/1de09e181d8dab3291ac52ab8c74e6fd7511a5ad">15: Design Space Exploration for Hardware Acceleration of Machine Learning Applications in MapReduce</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701141</td>
<td>0.987419</td>
<td><a href="https://www.semanticscholar.org/paper/5f6904f96c018a10434a7ecd45777aa2eae9a868">53: Mariana: Tencent Deep Learning Platform and its Applications</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705466</td>
<td>0.983598</td>
<td><a href="https://www.semanticscholar.org/paper/4ce50b6d21e299d60e3ae2f46408ef2b6f29cdd4">85: Multi-GPU Training of ConvNets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.716294</td>
<td>0.981044</td>
<td><a href="https://www.semanticscholar.org/paper/e684e4fcb1754f1b2e0f048af10822de957186f1">15: Parallel Deep Convolutional Neural Network Training by Exploiting the Overlapping of Computation and Communication</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759968</td>
<td>0.979633</td>
<td><a href="https://www.semanticscholar.org/paper/ee8c33a09b94377741c8c4e12cfc9174b9bcc7a1">144: Deep Learning on FPGAs: Past, Present, and Future</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772649</td>
<td>0.979097</td>
<td><a href="https://www.semanticscholar.org/paper/d40b2e84b2ff2b181bcefa9c6926ae46c50d1c83">4: High performance training of deep neural networks using pipelined hardware acceleration and distributed memory</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674651</td>
<td>0.977003</td>
<td><a href="https://www.semanticscholar.org/paper/851c27d7cdb74b0b21bd84a9333bca106f486713">47: Low precision storage for deep learning</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.976404</td>
<td><a href="https://www.semanticscholar.org/paper/d8ed9d625bcb1d2b093e2312b084647dae17e7e0">0: An efficient stochastic computing based deep neural network accelerator with optimized activation functions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.618079</td>
<td>0.975813</td>
<td><a href="https://www.semanticscholar.org/paper/2cc157afda51873c30b195fff56e917b9c06b853">413: High Performance Convolutional Neural Networks for Document Processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736499</td>
<td>0.972019</td>
<td><a href="https://www.semanticscholar.org/paper/f6ec27f0ac6616e61434ba635e1a320e61b5f245">47: Poseidon: A System Architecture for Efficient GPU-based Deep Learning on Multiple Machines</a></td>
</tr>
</table></html>
<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/d1208ac421cf8ff67b27d93cd19ae42b8d596f95">682: Deep learning with COTS HPC systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.876512</td>
<td>0.798861</td>
<td><a href="https://www.semanticscholar.org/paper/f6173885cf30570e64f175e5130ab983e765d6ac">28: On Scale-out Deep Learning Training for Cloud and HPC</a></td>
</tr>
<tr>
<td>0</td>
<td>0.850669</td>
<td>0.651951</td>
<td><a href="https://www.semanticscholar.org/paper/c26ddc4be489c265961f6418dff385fc5ba16489">0: Challenges for Machine Learning on Distributed Platforms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820133</td>
<td>0.883156</td>
<td><a href="https://www.semanticscholar.org/paper/83735f0590cf1c7dd9f83dbab8f82a1d66f6892a">1: Distributed training of deep neural networks with spark: The MareNostrum experience</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818581</td>
<td>0.908450</td>
<td><a href="https://www.semanticscholar.org/paper/b6b9059c9d034d5032dd0725b81f1976f701f7be">2: Deep Learning on Large-Scale Muticore Clusters</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807082</td>
<td>0.515941</td>
<td><a href="https://www.semanticscholar.org/paper/615843b8cd63a98688dcf9c3746717ddcace8f59">0: Architectural Requirements for Deep Learning Workloads in HPC Environments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804742</td>
<td>0.724278</td>
<td><a href="https://www.semanticscholar.org/paper/1089a3db4aa185eea2eec1211323772bcdb9d6c9">30: Accelerating Deep Learning Workloads Through Efficient Multi-Model Execution</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804384</td>
<td>0.651205</td>
<td><a href="https://www.semanticscholar.org/paper/35538d57064a367a0274ec03b285544d2fa4e8a4">0: Benchmarking Neural Networks on Heterogeneous Hardware Resources</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803842</td>
<td>0.412650</td>
<td><a href="https://www.semanticscholar.org/paper/52dcb3739b29f51931f442dee46cad776996ee39">4: Deploying Scientific Al Networks at Petaflop Scale on Secure Large Scale HPC Production Systems with Containers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793972</td>
<td>0.672167</td>
<td><a href="https://www.semanticscholar.org/paper/1de09e181d8dab3291ac52ab8c74e6fd7511a5ad">15: Design Space Exploration for Hardware Acceleration of Machine Learning Applications in MapReduce</a></td>
</tr>
<tr>
<td>0</td>
<td>0.701141</td>
<td>0.987419</td>
<td><a href="https://www.semanticscholar.org/paper/5f6904f96c018a10434a7ecd45777aa2eae9a868">53: Mariana: Tencent Deep Learning Platform and its Applications</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705466</td>
<td>0.983598</td>
<td><a href="https://www.semanticscholar.org/paper/4ce50b6d21e299d60e3ae2f46408ef2b6f29cdd4">85: Multi-GPU Training of ConvNets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.716294</td>
<td>0.981044</td>
<td><a href="https://www.semanticscholar.org/paper/e684e4fcb1754f1b2e0f048af10822de957186f1">15: Parallel Deep Convolutional Neural Network Training by Exploiting the Overlapping of Computation and Communication</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759968</td>
<td>0.979633</td>
<td><a href="https://www.semanticscholar.org/paper/ee8c33a09b94377741c8c4e12cfc9174b9bcc7a1">144: Deep Learning on FPGAs: Past, Present, and Future</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772649</td>
<td>0.979097</td>
<td><a href="https://www.semanticscholar.org/paper/d40b2e84b2ff2b181bcefa9c6926ae46c50d1c83">4: High performance training of deep neural networks using pipelined hardware acceleration and distributed memory</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674651</td>
<td>0.977003</td>
<td><a href="https://www.semanticscholar.org/paper/851c27d7cdb74b0b21bd84a9333bca106f486713">47: Low precision storage for deep learning</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.976404</td>
<td><a href="https://www.semanticscholar.org/paper/d8ed9d625bcb1d2b093e2312b084647dae17e7e0">0: An efficient stochastic computing based deep neural network accelerator with optimized activation functions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.618079</td>
<td>0.975813</td>
<td><a href="https://www.semanticscholar.org/paper/2cc157afda51873c30b195fff56e917b9c06b853">413: High Performance Convolutional Neural Networks for Document Processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736499</td>
<td>0.972019</td>
<td><a href="https://www.semanticscholar.org/paper/f6ec27f0ac6616e61434ba635e1a320e61b5f245">47: Poseidon: A System Architecture for Efficient GPU-based Deep Learning on Multiple Machines</a></td>
</tr>
</table></html>
