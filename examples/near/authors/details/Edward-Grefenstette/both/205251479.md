<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>0</td>
<td>1.000000</td>
<td>0.013758</td>
<td>NA:4463466</td>
</tr>
<tr>
<td>0</td>
<td>0.878602</td>
<td>0.838225</td>
<td><a href="https://www.semanticscholar.org/paper/0298e63bdc97b96bee195187af5f256df460357a">0: Symbolic Reasoning with Differentiable Neural Comput</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812582</td>
<td>0.755885</td>
<td><a href="https://www.semanticscholar.org/paper/3ee01ec27e4e66e089b72a9989724be611c2ad90">188: Neural Map: Structured Memory for Deep Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802223</td>
<td>0.415224</td>
<td><a href="https://www.semanticscholar.org/paper/dcdb9bd64e3d7885c10938291153257b94f3df91">1009: Sparse Distributed Memory</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802178</td>
<td>0.839293</td>
<td><a href="https://www.semanticscholar.org/paper/04cca8e341a5da42b29b0bc831cb25a0f784fa01">324: Adaptive Computation Time for Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799516</td>
<td>0.869111</td>
<td><a href="https://www.semanticscholar.org/paper/fd4ae71916cf400bfd1490f275e91b154eb69160">137: Relational recurrent neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796240</td>
<td>0.466863</td>
<td><a href="https://www.semanticscholar.org/paper/4bca27b823c9724d910b4637fd489343233570f8">24: On the Emergence of Rules in Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.789525</td>
<td>0.513306</td>
<td><a href="https://www.semanticscholar.org/paper/4b0c04fdcab6ee321a80402b45879ddfd3fc43f5">3: DynMat, a network that can learn after learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785778</td>
<td>0.255881</td>
<td><a href="https://www.semanticscholar.org/paper/f96b18f513f6eb1a426bed2b038791d6a3a0c9c8">60: Reducing Communication for Distributed Learning in Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785667</td>
<td>0.362044</td>
<td><a href="https://www.semanticscholar.org/paper/a772ef809888a33dd644921c119f2db5ceef1370">1: Recurrent Neural Network Learning of Performance and Intrinsic Population Dynamics from Sparse Neural Data</a></td>
</tr>
<tr>
<td>0</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/784ee73d5363c711118f784428d1ab89f019daa5">1206: Hybrid computing using a neural network with dynamic external memory</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748508</td>
<td>0.968126</td>
<td><a href="https://www.semanticscholar.org/paper/b59d91e0699d4e1896a15bae13fd180bdaf77ea5">305: Neural Programmer-Interpreters</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759061</td>
<td>0.956622</td>
<td><a href="https://www.semanticscholar.org/paper/11503f8f1d94607b46f58ad4188facdadf257fe4">21: Gated Fast Weights for On-The-Fly Neural Program Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717728</td>
<td>0.955989</td>
<td><a href="https://www.semanticscholar.org/paper/c3823aacea60bc1f2cabb9283144690a3d015db5">1627: Neural Turing Machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.702289</td>
<td>0.954085</td>
<td><a href="https://www.semanticscholar.org/paper/49e24b1fd415e20839c09b5dd68a01f61d1681d9">93: Learning Simple Algorithms from Examples</a></td>
</tr>
<tr>
<td>0</td>
<td>0.747358</td>
<td>0.952142</td>
<td><a href="https://www.semanticscholar.org/paper/a2499dd426c46c645ee805d7594b6687547c72d4">133: Neural Random Access Machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774612</td>
<td>0.951763</td>
<td><a href="https://www.semanticscholar.org/paper/5e4eb58d5b47ac1c73f4cf189497170e75ae6237">286: Neural GPUs Learn Algorithms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751173</td>
<td>0.951604</td>
<td><a href="https://www.semanticscholar.org/paper/1606575fc6f337bde02291a4bf928eb16f58d0e6">30: Implementing Neural Turing Machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.669054</td>
<td>0.949553</td>
<td><a href="https://www.semanticscholar.org/paper/6f69e19348870552a7ab92d038c8b8d753fe6b60">12: Neural Arithmetic Expression Calculator</a></td>
</tr>
<tr>
<td>0</td>
<td>0.656803</td>
<td>0.949321</td>
<td><a href="https://www.semanticscholar.org/paper/61639af1a89c69094bcc0ed40fad752832b037c3">44: Reducing the Ratio Between Learning Complexity and Number of Time Varying Variables in Fully Recurrent Nets</a></td>
</tr>
</table></html>
