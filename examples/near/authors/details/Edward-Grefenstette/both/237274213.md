<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/43ea4f5d999d35d4fc6c544eedbc100d8c3a5e00">15: MiniHack the Planet: A Sandbox for Open-Ended Reinforcement Learning Research</a></td>
</tr>
<tr>
<td>0</td>
<td>0.841305</td>
<td>-0.013003</td>
<td>NA:231883849</td>
</tr>
<tr>
<td>0</td>
<td>0.832710</td>
<td>0.985065</td>
<td><a href="https://www.semanticscholar.org/paper/6f9a9b68a334a87ce051968efbaf71c658fef614">58: rlpyt: A Research Code Base for Deep Reinforcement Learning in PyTorch</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823080</td>
<td>0.982825</td>
<td><a href="https://www.semanticscholar.org/paper/95523836fea59eeac6f5a09aef4a95dfdb7e880d">2: TeachMyAgent: a Benchmark for Automatic Curriculum Learning in Deep RL</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820581</td>
<td>0.981175</td>
<td><a href="https://www.semanticscholar.org/paper/9cffec4a54f82abd55f1c44c1bff5010b2defb60">0: URNAI: A Multi-Game Toolkit for Experimenting Deep Reinforcement Learning Algorithms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.819731</td>
<td>0.820163</td>
<td><a href="https://www.semanticscholar.org/paper/89c083315b3f7aef0b752ebcebb4d630ea31c0b2">1: Ray RLlib: A Framework for Distributed Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812582</td>
<td>0.852400</td>
<td><a href="https://www.semanticscholar.org/paper/91235fb26b7ebb517e0985227eb26ebd915407e9">0: RAPID-RL: A Reconfigurable Architecture with Preemptive-Exits for Efficient Deep-Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806879</td>
<td>0.989163</td>
<td><a href="https://www.semanticscholar.org/paper/0047f2c7052e1aa02803fe5f9c4fd743f3990567">0: Demonstration-Guided Q-Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799672</td>
<td>0.972035</td>
<td><a href="https://www.semanticscholar.org/paper/5d892ffe2eb583f840c464f3831556f6d072bb5b">0: CURIOSITY-DRIVEN EXPERIENCE PRIORITIZATION</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799048</td>
<td>0.952106</td>
<td><a href="https://www.semanticscholar.org/paper/5d19d52d904160c47cbc4981b140315900c3e3f1">1: Efficient Reinforcement Learning for StarCraft by Abstract Forward Models and Transfer Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.841828</td>
<td>0.997752</td>
<td><a href="https://www.semanticscholar.org/paper/3228f6fc7902b23c26378e59f8c8820412de7f42">40: The NetHack Learning Environment</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740440</td>
<td>0.997383</td>
<td><a href="https://www.semanticscholar.org/paper/eb44e9824a927bad07f48dbd41c516626513156a">9: Griddly: A platform for AI research in games</a></td>
</tr>
<tr>
<td>0</td>
<td>0.625538</td>
<td>0.996379</td>
<td><a href="https://www.semanticscholar.org/paper/474c0bc346a7d13dc513a5038d860f843baf473d">0: S KILL H ACK : A B ENCHMARK FOR S KILL T RANSFER IN O PEN -E NDED R EINFORCEMENT L EARNING</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790327</td>
<td>0.996093</td>
<td><a href="https://www.semanticscholar.org/paper/2523d5ae7d753ea720e2ea19e5995c920e46a404">1: Distilling Reinforcement Learning Tricks for Video Games</a></td>
</tr>
<tr>
<td>0</td>
<td>0.700954</td>
<td>0.995912</td>
<td><a href="https://www.semanticscholar.org/paper/fbe48f4cff41511674e78afb78aa644d51a5094b">4: Credit Assignment with Meta-Policy Gradient for Multi-Agent Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.730438</td>
<td>0.995733</td>
<td><a href="https://www.semanticscholar.org/paper/1e3d94ecbdecb73ac7c9353bcf14adbcf96c5563">4: The Neural MMO Platform for Massively Multiagent Research</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772068</td>
<td>0.995692</td>
<td><a href="https://www.semanticscholar.org/paper/484ee269ce0536ae15754602cb5143191b8e7853">3: Towards robust and domain agnostic reinforcement learning competitions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758258</td>
<td>0.995613</td>
<td><a href="https://www.semanticscholar.org/paper/feb7f993c402e2663d20bbafa83c11e6db3dfe6b">13: Cooperative Exploration for Multi-Agent Deep Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774067</td>
<td>0.995608</td>
<td><a href="https://www.semanticscholar.org/paper/b6fb41647db2806471fcdee07f03621961409437">9: SCC: an efficient deep reinforcement learning agent mastering the game of StarCraft II</a></td>
</tr>
</table></html>
