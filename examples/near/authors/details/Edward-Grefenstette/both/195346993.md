<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/71b152f65fd9967ec39f1e1f359ad0d99be1bab2">29: Learning to Follow Language Instructions with Adversarial Reward Induction</a></td>
</tr>
<tr>
<td>1</td>
<td>0.867991</td>
<td>0.985399</td>
<td><a href="https://www.semanticscholar.org/paper/758311575a6385bb15d4f9af8c0e671cb98184b4">65: From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following</a></td>
</tr>
<tr>
<td>0</td>
<td>0.848469</td>
<td>0.903926</td>
<td>NA:248942155</td>
</tr>
<tr>
<td>0</td>
<td>0.832301</td>
<td>0.938471</td>
<td><a href="https://www.semanticscholar.org/paper/2565ce38975f8494b8949360aaf8138665c20d00">0: Implementation of Language-Action Reward Network in Reinforcement Learning by Using Natural Language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.826839</td>
<td>0.952871</td>
<td><a href="https://www.semanticscholar.org/paper/0b22f92be890b720eaa97fa75a49560f11ff2ab2">18: Grounding Language to Autonomously-Acquired Skills via Goal Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820276</td>
<td>0.935609</td>
<td><a href="https://www.semanticscholar.org/paper/5376c6a141889adc8304350a7673a45ef80a1b97">12: Simultaneously Learning Transferable Symbols and Language Groundings from Perceptual Data for Instruction Following</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816922</td>
<td>0.823088</td>
<td><a href="https://www.semanticscholar.org/paper/0916d3112978bbe5f123553b5460ac1d05c6a8fd">0: Mapping Language to Programs using Multiple Reward Components with Inverse Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816467</td>
<td>0.807732</td>
<td><a href="https://www.semanticscholar.org/paper/cc1648c91ffda21bbe6e5f08f69c683588fc384c">261: Reinforcement Learning for Mapping Instructions to Actions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812852</td>
<td>0.927028</td>
<td><a href="https://www.semanticscholar.org/paper/025d142e712c5ddf97157e62765ff518da6ef9b2">8: Encoding formulas as deep networks: Reinforcement learning for zero-shot execution of LTL formulas</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811371</td>
<td>0.891639</td>
<td><a href="https://www.semanticscholar.org/paper/ebf19e71df8cb33e1cd12ef7ab41a94f4e14415b">24: Forward-Backward Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.898817</td>
<td>0.989857</td>
<td><a href="https://www.semanticscholar.org/paper/4a4b71ff918ca8eeffa5dfe66be2db7fcc1291da">97: Learning to Understand Goal Specifications by Modelling Reward</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834512</td>
<td>0.986909</td>
<td><a href="https://www.semanticscholar.org/paper/5dcad60d3ae2271e209badeb1755b06423415e27">4: Safe Reinforcement Learning with Natural Language Constraints</a></td>
</tr>
<tr>
<td>0</td>
<td>0.864236</td>
<td>0.986577</td>
<td><a href="https://www.semanticscholar.org/paper/e43dbd76c0c7d5c4b8efa3e1fec2ea6dca65f0e3">22: Self-Educated Language Agent with Hindsight Experience Replay for Instruction Following</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834196</td>
<td>0.984697</td>
<td><a href="https://www.semanticscholar.org/paper/1abded7824da0d9a5ccabcd998d5d7d95acb0d54">8: HIGhER: Improving instruction following with Hindsight Generation for Experience Replay</a></td>
</tr>
<tr>
<td>0</td>
<td>0.860004</td>
<td>0.982578</td>
<td><a href="https://www.semanticscholar.org/paper/34f5d2f039558ba0b6a5103553ad68321fa6eabd">33: Guiding Policies with Language via Meta-Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807001</td>
<td>0.982364</td>
<td><a href="https://www.semanticscholar.org/paper/30834ae1497c35d362eea14857d93c28d2d12b57">186: Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.783537</td>
<td>0.981684</td>
<td><a href="https://www.semanticscholar.org/paper/a0a1313540a9900c912c73865087f64e8efe793d">1: Learning to request guidance in emergent language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.824602</td>
<td>0.981520</td>
<td><a href="https://www.semanticscholar.org/paper/9d90fa5b4f3b8a6ec0485417ef54fdf548d21714">16: ACTRCE: Augmenting Experience via Teacher's Advice For Multi-Goal Reinforcement Learning</a></td>
</tr>
</table></html>
