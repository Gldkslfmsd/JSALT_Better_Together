<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/49956bdcfb55d8b42c696a743843f2a1e232d739">17: Strength in Numbers: Trading-off Robustness and Computation via Adversarially-Trained Ensembles</a></td>
</tr>
<tr>
<td>0</td>
<td>0.880668</td>
<td>0.942174</td>
<td><a href="https://www.semanticscholar.org/paper/1eff01027877843f1b492c4abecdbbc112497d29">79: Adversarial Robustness vs. Model Compression, or Both?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.872580</td>
<td>0.986323</td>
<td><a href="https://www.semanticscholar.org/paper/b9fa6a2432be3ad541b28a13ac5c29c9fda9e865">0: ARMOURED: ADVERSARIALLY ROBUST MODELS</a></td>
</tr>
<tr>
<td>0</td>
<td>0.872055</td>
<td>0.945283</td>
<td><a href="https://www.semanticscholar.org/paper/78c68d51039f6806b4959c8df8f4a80029037fbf">0: Jacobian Ensembles Improve Robustness Trade-offs to Adversarial Attacks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.866118</td>
<td>0.990542</td>
<td><a href="https://www.semanticscholar.org/paper/fd8a6a3c847b76d668a4d94eac39e12547b5aa48">0: Adversarial examples and where to find them</a></td>
</tr>
<tr>
<td>0</td>
<td>0.865940</td>
<td>0.986319</td>
<td><a href="https://www.semanticscholar.org/paper/44e4035790d1220c77a59310a8616f94c426cb99">0: Adversarial Fine-tune with Dynamically Regulated Adversary</a></td>
</tr>
<tr>
<td>0</td>
<td>0.865895</td>
<td>0.991494</td>
<td><a href="https://www.semanticscholar.org/paper/6429f207519122ca1ac35c899f51250f928083ef">0: Mutual Adversarial Training: Learning together is better than going alone</a></td>
</tr>
<tr>
<td>0</td>
<td>0.865695</td>
<td>0.986666</td>
<td><a href="https://www.semanticscholar.org/paper/36365883d57a4908d4e8a4b660a691a9f69d69c7">0: ARMOURED: ADVERSARIALLY ROBUST MODELS</a></td>
</tr>
<tr>
<td>0</td>
<td>0.865015</td>
<td>0.994435</td>
<td><a href="https://www.semanticscholar.org/paper/d33deae7f654b07ac8a5c437a4fa018c29e6af17">195: You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle</a></td>
</tr>
<tr>
<td>0</td>
<td>0.864354</td>
<td>0.990251</td>
<td><a href="https://www.semanticscholar.org/paper/f8f82100ae73bcc0433bb724405993cd11da57fc">62: You Only Propagate Once: Painless Adversarial Training Using Maximal Principle</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788617</td>
<td>0.997220</td>
<td><a href="https://www.semanticscholar.org/paper/50fa3702f984828f6a406e505f9c75ba47bc4390">36: THERMOMETER ENCODING: ONE HOT WAY TO RESIST</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845599</td>
<td>0.996567</td>
<td><a href="https://www.semanticscholar.org/paper/e9ee1a3605c5d831287c4aa6574668270dc34409">0: PARL: Enhancing Diversity of Ensemble Networks to Resist Adversarial Attacks via Pairwise Adversarially Robust Loss Function</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760237</td>
<td>0.996557</td>
<td><a href="https://www.semanticscholar.org/paper/08d221305682a590b617a7fe015b30d15db51bc9">0: Robustness Learning via Decision Tree Search Robust Optimisation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.779134</td>
<td>0.996479</td>
<td><a href="https://www.semanticscholar.org/paper/fda5f4facce9d5567c090d7ac733158e0fe93dc7">82: DEEPSEC: A Uniform Platform for Security Analysis of Deep Learning Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.847199</td>
<td>0.996399</td>
<td><a href="https://www.semanticscholar.org/paper/9d2307f931c8540485a20044e4f65dfd3bc686a8">6: Effects of Loss Functions And Target Representations on Adversarial Robustness</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825442</td>
<td>0.996346</td>
<td><a href="https://www.semanticscholar.org/paper/37a9e8ce40c010216bad8a009fca168be2332dde">12: Minimum Uncertainty Based Detection of Adversaries in Deep Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831084</td>
<td>0.995855</td>
<td><a href="https://www.semanticscholar.org/paper/5928fe9b51ca6cfefc2d6cce5fd63ec618bf007a">0: Enhancing the transferability of adversarial black-box attacks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.597494</td>
<td>0.995714</td>
<td><a href="https://www.semanticscholar.org/paper/4bb412cadb903e4e51ea1dcc4211025262a448aa">4: Certification of Semantic Perturbations via Randomized Smoothing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825513</td>
<td>0.995479</td>
<td><a href="https://www.semanticscholar.org/paper/d90038afede2d2ea0c5b3de7a9c96485234bc29e">40: ML-LOO: Detecting Adversarial Examples with Feature Attribution</a></td>
</tr>
</table></html>
