<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/62ac088d966d4a9122959f13301759c6bbda6c36">104: Latent-Variable Modeling of String Transductions with Finite-State Methods</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805387</td>
<td>0.894690</td>
<td><a href="https://www.semanticscholar.org/paper/4e749b2e0728044af44d50a708fc99d49359ea0b">1: Comparative Error Analysis in Neural and Finite-state Models for Unsupervised Character-level Transduction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766524</td>
<td>0.766575</td>
<td><a href="https://www.semanticscholar.org/paper/2984f98a16c28760cdafbfad22bab116bba4b79c">26: Improving Lemmatization of Non-Standard Languages with Joint Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765358</td>
<td>0.700298</td>
<td><a href="https://www.semanticscholar.org/paper/68b626eb3712d5aa0ba3dd1f47d590351ce0009d">15: Improving tree-based neural machine translation with dynamic lexicalized dependency encoding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759137</td>
<td>0.685965</td>
<td><a href="https://www.semanticscholar.org/paper/e889e2dd1647fdfc28edb9abe08a863b704f08be">15: Using Intermediate Representations to Solve Math Word Problems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758635</td>
<td>0.436411</td>
<td><a href="https://www.semanticscholar.org/paper/f950beb2624ef0fd701a8da19a45294ffdddb3a3">2: Enhancing Generalization in Natural Language Inference by Syntax</a></td>
</tr>
<tr>
<td>0</td>
<td>0.757134</td>
<td>0.666324</td>
<td><a href="https://www.semanticscholar.org/paper/033b0e39338a89b12e9a4d62dc73aa07b597308e">0: Regressing Word and Sentence Embeddings for Regularization of Neural Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.753540</td>
<td>0.435758</td>
<td>NA:248425888</td>
</tr>
<tr>
<td>0</td>
<td>0.753093</td>
<td>0.815171</td>
<td><a href="https://www.semanticscholar.org/paper/1d8bb078a86b1999805605b71a8ffe410bda4714">20: A Simple Joint Model for Improved Contextual Neural Lemmatization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752719</td>
<td>0.807388</td>
<td><a href="https://www.semanticscholar.org/paper/a5577fdb293d58e3050355080df74d1bc9ce063d">1: Data Generation Using Sequence-to-Sequence</a></td>
</tr>
<tr>
<td>0</td>
<td>0.635667</td>
<td>0.991409</td>
<td><a href="https://www.semanticscholar.org/paper/2864be1d9897ac29fc3c65aa823cea3e6f777c4e">29: Stochastic Contextual Edit Distance and Probabilistic FSTs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717285</td>
<td>0.981035</td>
<td><a href="https://www.semanticscholar.org/paper/592f0d4f2520525476c979ec53c9b44badfcb37b">220: Applying Many-to-Many Alignments and Hidden Markov Models to Letter-to-Phoneme Conversion</a></td>
</tr>
<tr>
<td>0</td>
<td>0.693218</td>
<td>0.979833</td>
<td><a href="https://www.semanticscholar.org/paper/31015d4d212ba436ab7f83bbb178fccd48cda185">71: Semi-Supervised Learning of Concatenative Morphology</a></td>
</tr>
<tr>
<td>0</td>
<td>0.684537</td>
<td>0.979805</td>
<td><a href="https://www.semanticscholar.org/paper/c1bb98738417bc300e83402721fe70be619dc48d">8: Tracing a Loose Wordhood for Chinese Input Method Engine</a></td>
</tr>
<tr>
<td>0</td>
<td>0.571732</td>
<td>0.978639</td>
<td><a href="https://www.semanticscholar.org/paper/0c5043108eda7d2fa467fe91e3c47d4ba08e0b48">385: Unsupervised Discovery of Morphemes</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756507</td>
<td>0.978511</td>
<td><a href="https://www.semanticscholar.org/paper/c56d66a152f025305a6d1033ad797fa87cad18fd">44: Graphical Models over Multiple Strings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717643</td>
<td>0.978387</td>
<td><a href="https://www.semanticscholar.org/paper/e93e60ce34fd91883f0e9a5c44e98ba871df7019">20: A Comparison of Four Character-Level String-to-String Translation Models for (OCR) Spelling Error Correction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785889</td>
<td>0.978209</td>
<td><a href="https://www.semanticscholar.org/paper/620662b32482f84479454055d800f1e75d1aed67">13: Structure learning in hidden conditional random fields for grapheme-to-phoneme conversion</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738495</td>
<td>0.977813</td>
<td><a href="https://www.semanticscholar.org/paper/65162439e07d9fde14aa5e3b1942034a2bc564c1">0: Survey Paper : Improving Neural Language Modeling with Linguistic Annotation</a></td>
</tr>
</table></html>
