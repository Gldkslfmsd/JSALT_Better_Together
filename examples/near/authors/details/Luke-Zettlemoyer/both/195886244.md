<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/1b9ce27801c077433245ad0f9e43e3c38441cecd">109: Vision-and-Dialog Navigation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.881756</td>
<td>0.964824</td>
<td><a href="https://www.semanticscholar.org/paper/cbbdcebe8ece11e883b55bcecc2f962670033263">4: Self-Motivated Communication Agent for Real-World Vision-Dialog Navigation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.851735</td>
<td>0.974501</td>
<td><a href="https://www.semanticscholar.org/paper/645bc7a5347a299a1e8aa965867bd097f6f4bddd">21: RMM: A Recursive Mental Model for Dialog Navigation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810865</td>
<td>0.105883</td>
<td><a href="https://www.semanticscholar.org/paper/d1df64e6c534a6e96940cc8fd65c5563d3936602">0: Assigning perspective in humanâ€“computer route dialogues: a contextual factors model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.797544</td>
<td>0.967272</td>
<td><a href="https://www.semanticscholar.org/paper/b2ffe83f7d03fdd114a2d1449a7abf20f621418f">8: Multimodal attention networks for low-level vision-and-language navigation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794233</td>
<td>0.501834</td>
<td><a href="https://www.semanticscholar.org/paper/99da80d9e9c0aaa2e924fbc27a91dbec9fbaed1f">0: Symbol Grounding for Robot Dialog Research Proposal</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791358</td>
<td>0.171883</td>
<td><a href="https://www.semanticscholar.org/paper/fe3467cc5a17013a097787e5cd5bb30b8230cafe">20: Building an adaptive spoken language interface for perceptually grounded human-robot interaction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786389</td>
<td>-0.027164</td>
<td><a href="https://www.semanticscholar.org/paper/f1fe82c27664afbe53c84a177795f3057de00a20">0: Human Cues for Robot Navigation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785846</td>
<td>0.270067</td>
<td><a href="https://www.semanticscholar.org/paper/4fabe48760bf4e7ca1e6d6c114057fbd8c20271e">0: The Impact of Route Descriptions on Human Expectations for Robot Navigation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781047</td>
<td>0.400450</td>
<td><a href="https://www.semanticscholar.org/paper/afcf6e66fabf3114ad69293ac9d5da766ac24197">5: Deep-Reinforcement-Learning-Based Semantic Navigation of Mobile Robots in Dynamic Environments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792219</td>
<td>0.993393</td>
<td><a href="https://www.semanticscholar.org/paper/29e13746fa5aed13e51558a521a39aaeaa99c1b1">142: Self-Monitoring Navigation Agent via Auxiliary Progress Estimation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.554838</td>
<td>0.993108</td>
<td><a href="https://www.semanticscholar.org/paper/b033400e9a80915a928f4603582e5e8bf7656a85">50: Shifting the Baseline: Single Modality Performance on Visual Navigation & QA</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816424</td>
<td>0.992020</td>
<td><a href="https://www.semanticscholar.org/paper/a00369391b59b4edfc19dd02bc2f81a93f9cb9da">3: NDH-Full: Learning and Evaluating Navigational Agents on Full-Length Dialogue</a></td>
</tr>
<tr>
<td>0</td>
<td>0.747263</td>
<td>0.991814</td>
<td><a href="https://www.semanticscholar.org/paper/b5cc6634724b2238c88bcc324ec01a2c91c1b909">190: TOUCHDOWN: Natural Language Navigation and Spatial Reasoning in Visual Street Environments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785235</td>
<td>0.990963</td>
<td><a href="https://www.semanticscholar.org/paper/ede8ba65c4db10d357d9c3bf8e75b092f536fc84">237: Speaker-Follower Models for Vision-and-Language Navigation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793004</td>
<td>0.990457</td>
<td><a href="https://www.semanticscholar.org/paper/6ec6fa4e34200e13d80ee79b95d1cc6ec0f6b424">7: TEACh: Task-driven Embodied Agents that Chat</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796887</td>
<td>0.988641</td>
<td><a href="https://www.semanticscholar.org/paper/c8c76626db4246c944642e86d19665025fa7deb4">131: Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout</a></td>
</tr>
<tr>
<td>0</td>
<td>0.833855</td>
<td>0.988405</td>
<td><a href="https://www.semanticscholar.org/paper/ac41d132999661f6b59db46a28086d4b6707654a">7: Diagnosing Vision-and-Language Navigation: What Really Matters</a></td>
</tr>
<tr>
<td>0</td>
<td>0.771747</td>
<td>0.987858</td>
<td><a href="https://www.semanticscholar.org/paper/3435e193998ec4118f51bbb608a843b0e123661b">9: Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes' Rule</a></td>
</tr>
</table></html>
