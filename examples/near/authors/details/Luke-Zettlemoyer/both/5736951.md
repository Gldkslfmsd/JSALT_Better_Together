<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/e88ee4fada3147f925a8c1cbfa8b335b3db4f8e7">210: Learning Symbolic Models of Stochastic Domains</a></td>
</tr>
<tr>
<td>1</td>
<td>0.883990</td>
<td>0.991986</td>
<td><a href="https://www.semanticscholar.org/paper/76093fa7a0125fa313347ae0e212c8b5ded9e0d1">80: Learning Planning Rules in Noisy Stochastic Worlds</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793105</td>
<td>0.833428</td>
<td><a href="https://www.semanticscholar.org/paper/1c29adee14deb74552df5d5d1058bce51b08e5ac">3: Autonomous Representation Learning in a Developing Agent</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782009</td>
<td>0.981236</td>
<td><a href="https://www.semanticscholar.org/paper/cf466f444452fcee103c81fce0d754cb75c0af31">42: Symbol Acquisition for Probabilistic High-Level Planning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765626</td>
<td>0.126915</td>
<td><a href="https://www.semanticscholar.org/paper/166c8802ba114456b79229c213faf23aa278f982">0: 작업 예들로부터 관계적 행동 모델의 학습</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760942</td>
<td>0.864465</td>
<td><a href="https://www.semanticscholar.org/paper/cd876934e98b7e9d6a954d5652356d15cb75420b">1: Learning Probabilistic Models via Bayesian Inverse Planning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756791</td>
<td>0.700615</td>
<td><a href="https://www.semanticscholar.org/paper/fd8f49d5909a7333aa08e923af996a05592f3afb">2: Probabilistic Perception Revision in AgentSpeak(L)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751694</td>
<td>0.798171</td>
<td><a href="https://www.semanticscholar.org/paper/a01570c3ba7abafe23022daa8c13ba2afd21f9d7">2: Learning Integrated Symbolic and Continuous Action Models for Continuous Domains</a></td>
</tr>
<tr>
<td>0</td>
<td>0.747557</td>
<td>0.752855</td>
<td><a href="https://www.semanticscholar.org/paper/fb231a294008b1c0caba9f92979f8519370e9951">17: On Planning while Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.744383</td>
<td>0.975231</td>
<td><a href="https://www.semanticscholar.org/paper/d4cb0450d9324e396d0ea21b981a1e6d4957856b">29: Learning Unknown Event Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768982</td>
<td>0.994635</td>
<td><a href="https://www.semanticscholar.org/paper/c7f7274715956691d1b3f908002198236f726440">85: Planning with Noisy Probabilistic Relational Rules</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717204</td>
<td>0.989629</td>
<td><a href="https://www.semanticscholar.org/paper/927f5fd03530c8170f3b91666d6fcaca5fdd4da8">12: Incremental Learning of Planning Operators in Stochastic Domains</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734769</td>
<td>0.988528</td>
<td><a href="https://www.semanticscholar.org/paper/abdf51fa58fbd0aaa1e71b295b4cd0bf9915ffd0">7: Symbol Acquisition for Task-Level Planning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.697190</td>
<td>0.987689</td>
<td><a href="https://www.semanticscholar.org/paper/86eb9a2038ed7226ab6b7671bc14a6fb9fb11560">0: Learning relational models with human interaction for planning in robotics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723391</td>
<td>0.987497</td>
<td><a href="https://www.semanticscholar.org/paper/9e06ab9603512ff0abdc1920b81bbafc8be8d703">23: Incremental Learning of Relational Action Models in Noisy Environments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.613219</td>
<td>0.986780</td>
<td><a href="https://www.semanticscholar.org/paper/dde3c2431abc4d1153e4867d001b9439488a3ffb">3: Statistical Relational Artificial Intelligence: From Distributions through Actions to Optimization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.690362</td>
<td>0.986310</td>
<td><a href="https://www.semanticscholar.org/paper/a0c5d8025a9dc5621ce4d2ebe21ccdd0745760a8">51: Exploration in relational domains for model-based reinforcement learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.671682</td>
<td>0.986229</td>
<td><a href="https://www.semanticscholar.org/paper/ea44e3078876d7ba8e37316b5fe9e12af7450a3c">4: Online Learning of Action Models for PDDL Planning</a></td>
</tr>
</table></html>
