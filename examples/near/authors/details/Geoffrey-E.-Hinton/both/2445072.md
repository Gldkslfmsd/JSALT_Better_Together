<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/3dc3a0efe58eaf8564ca1965c0ffd23ec495b83f">959: Autoencoders, Minimum Description Length and Helmholtz Free Energy</a></td>
</tr>
<tr>
<td>0</td>
<td>0.933891</td>
<td>0.875581</td>
<td><a href="https://www.semanticscholar.org/paper/fc48accc709c7aa22a9e0b66bf4966f5ea162999">10: Minimizing Description Length in an Unsupervised Neural Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731144</td>
<td>0.131097</td>
<td><a href="https://www.semanticscholar.org/paper/92f0677d6a98221e967799d38ceb85b0e252282a">29: Rate-distortion via Markov chain Monte Carlo</a></td>
</tr>
<tr>
<td>0</td>
<td>0.713446</td>
<td>0.856178</td>
<td><a href="https://www.semanticscholar.org/paper/0bb754879154b0a10ee9966636348d831081e151">13: Learning invariant features through local space contraction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.705578</td>
<td>0.620474</td>
<td><a href="https://www.semanticscholar.org/paper/108c1d7c504587952e0e8c9f6cf2f38656b67992">1: Efficient Riemannian training of recurrent neural networks for learning symbolic data sequences</a></td>
</tr>
<tr>
<td>0</td>
<td>0.693816</td>
<td>0.494109</td>
<td><a href="https://www.semanticscholar.org/paper/3d9a1f2bda166bf3793ed69529030f16d36d0de9">1: Node estimate for sparse random vector functional-link networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.693600</td>
<td>0.558287</td>
<td><a href="https://www.semanticscholar.org/paper/2e2f71b454ac3290dd1d29130f743e79bedd4c32">2: Exact gradient updates in time independent of output size for the spherical loss family</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691192</td>
<td>0.352033</td>
<td><a href="https://www.semanticscholar.org/paper/8fbc2d349d3d0945efa5e92fd3713734ce63d19e">0: Autoregressive Image Generation using Residual Quantization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.687894</td>
<td>0.605981</td>
<td><a href="https://www.semanticscholar.org/paper/6dca99dbb7a4656e708b94a25ecc1fb825debe7d">3: Using Swarm Optimization To Enhance Autoencoders Images</a></td>
</tr>
<tr>
<td>0</td>
<td>0.682174</td>
<td>0.469831</td>
<td><a href="https://www.semanticscholar.org/paper/49d4a9e019b19b7a294d5590fcf43154663f2524">18: Vector-output ReLU Neural Network Problems are Copositive Programs: Convex Analysis of Two Layer Networks and Polynomial-time Algorithms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.582952</td>
<td>0.955382</td>
<td><a href="https://www.semanticscholar.org/paper/f5821548720901c89b3b7481f7500d7cd64e99bd">964: Auto-association by multilayer perceptrons and singular value decomposition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.612508</td>
<td>0.953433</td>
<td><a href="https://www.semanticscholar.org/paper/f50dfcc143bc1cc8ded1d88d31a59140b0a0ebd8">63: Deep Mixtures of Factor Analysers</a></td>
</tr>
<tr>
<td>0</td>
<td>0.640217</td>
<td>0.951413</td>
<td><a href="https://www.semanticscholar.org/paper/843959ffdccf31c6694d135fad07425924f785b1">5401: Extracting and composing robust features with denoising autoencoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.625203</td>
<td>0.950419</td>
<td><a href="https://www.semanticscholar.org/paper/247c55d43e1208c6109027f871adbdccecaf6337">156: From neural PCA to deep unsupervised learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.506821</td>
<td>0.950162</td>
<td><a href="https://www.semanticscholar.org/paper/c50dca78e97e335d362d6b991ae0e1448914e9a3">285: Reducing the Dimensionality of Data with Neural</a></td>
</tr>
<tr>
<td>0</td>
<td>0.678822</td>
<td>0.948267</td>
<td><a href="https://www.semanticscholar.org/paper/df8294254b229e1751de70db5988273f97e218a0">975: Autoencoders, Unsupervised Learning, and Deep Architectures</a></td>
</tr>
<tr>
<td>0</td>
<td>0.637729</td>
<td>0.947456</td>
<td><a href="https://www.semanticscholar.org/paper/923d8dd5d36dd5ab68aadbe2e3eecb57de88d859">324: Learning deep generative models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737569</td>
<td>0.942565</td>
<td><a href="https://www.semanticscholar.org/paper/aaaea06da21f22221d5fbfd61bb3a02439f0fe02">74: A Generative Process for sampling Contractive Auto-Encoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.562160</td>
<td>0.941517</td>
<td><a href="https://www.semanticscholar.org/paper/104a50406127fdb05ebdeb267fdc6c898104bd80">5: Novel deep generative simultaneous recurrent model for efficient representation learning</a></td>
</tr>
</table></html>
