<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/3e7f5f4382ac6f9c4fef6197dd21abf74456acd1">715: Big Self-Supervised Models are Strong Semi-Supervised Learners</a></td>
</tr>
<tr>
<td>0</td>
<td>0.881893</td>
<td>0.563480</td>
<td><a href="https://www.semanticscholar.org/paper/450149acf23636e5b006caec9e6a3cdb0facf802">13: Semi-Supervised Learning for Fine-Grained Classification With Self-Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.862330</td>
<td>0.539511</td>
<td><a href="https://www.semanticscholar.org/paper/c33f90022b9318206264870967a4419d414e00a3">18: Naive semi-supervised deep learning using pseudo-label</a></td>
</tr>
<tr>
<td>0</td>
<td>0.857054</td>
<td>0.538614</td>
<td><a href="https://www.semanticscholar.org/paper/a594fcad159544b4096f6b960d0ba92d5e4399c8">1: Guided Learning for the combination of weakly-supervised and semi-supervised learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.855742</td>
<td>0.317012</td>
<td><a href="https://www.semanticscholar.org/paper/521aa8dcd66428b07728b91722cc8f2b5a73944b">5: Pseudo-Labeling Using Gaussian Process for Semi-Supervised Deep Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.853359</td>
<td>0.013083</td>
<td>NA:237950760</td>
</tr>
<tr>
<td>0</td>
<td>0.851107</td>
<td>0.961887</td>
<td><a href="https://www.semanticscholar.org/paper/0adfcedb76db0f30208fac406c1000c79f3dd06c">0: Research on Self-Supervised Comparative Learning for Computer Vision</a></td>
</tr>
<tr>
<td>0</td>
<td>0.847902</td>
<td>0.970818</td>
<td><a href="https://www.semanticscholar.org/paper/2bd5c2840ee9d499137895197b93cef129c22b60">1: Barely-Supervised Learning: Semi-Supervised Learning with very few labeled images</a></td>
</tr>
<tr>
<td>0</td>
<td>0.846859</td>
<td>0.855636</td>
<td><a href="https://www.semanticscholar.org/paper/ffa89c1bc4c853f87f84ceb6c354c64ead20b688">3: Task Cooperation for Semi-Supervised Few-Shot Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.843750</td>
<td>0.910076</td>
<td><a href="https://www.semanticscholar.org/paper/ee307fd6f74e47935af224af61a76903f9a0c887">42: TransMatch: A Transfer-Learning Scheme for Semi-Supervised Few-Shot Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782308</td>
<td>0.996555</td>
<td><a href="https://www.semanticscholar.org/paper/38f93092ece8eee9771e61c1edaf11b1293cae1b">1379: Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736996</td>
<td>0.994963</td>
<td><a href="https://www.semanticscholar.org/paper/0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d">687: Exploring Simple Siamese Representation Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.787727</td>
<td>0.992411</td>
<td><a href="https://www.semanticscholar.org/paper/38643c2926b10f6f74f122a7037e2cd20d77c0f1">755: Supervised Contrastive Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.772892</td>
<td>0.992248</td>
<td><a href="https://www.semanticscholar.org/paper/10161d83d29fc968c4612c9e9e2b61a2fc25842e">916: Unsupervised Learning of Visual Features by Contrasting Cluster Assignments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740972</td>
<td>0.992075</td>
<td><a href="https://www.semanticscholar.org/paper/add2f205338d70e10ce5e686df4a690e2851bdfc">3096: Momentum Contrast for Unsupervised Visual Representation Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691126</td>
<td>0.991514</td>
<td><a href="https://www.semanticscholar.org/paper/8a9d84d86ac0d76e63914802f9738325c3bece9c">345: Barlow Twins: Self-Supervised Learning via Redundancy Reduction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719795</td>
<td>0.990981</td>
<td><a href="https://www.semanticscholar.org/paper/8653cbe908c64c0e4a3591fe652d239ab7cf98c1">18: On Feature Decorrelation in Self-Supervised Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.678966</td>
<td>0.990372</td>
<td><a href="https://www.semanticscholar.org/paper/a1b8a8df281bbaec148a897927a49ea47ea31515">1004: Improved Baselines with Momentum Contrastive Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.711513</td>
<td>0.989702</td>
<td><a href="https://www.semanticscholar.org/paper/3021152ab7540da7fd85baf2560568d8ef4a9b23">19: MixCo: Mix-up Contrastive Learning for Visual Representation</a></td>
</tr>
</table></html>
