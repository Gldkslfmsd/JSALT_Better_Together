<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/25c9f33aceac6dcff357727cbe2faf145b01d13c">930: Keeping the neural networks simple by minimizing the description length of the weights</a></td>
</tr>
<tr>
<td>0</td>
<td>0.934925</td>
<td>0.857745</td>
<td><a href="https://www.semanticscholar.org/paper/24049fe69136657a5e9dfa05bb079b8e29df8582">55: Keeping Neural Networks Simple</a></td>
</tr>
<tr>
<td>0</td>
<td>0.903680</td>
<td>0.122877</td>
<td><a href="https://www.semanticscholar.org/paper/d74e8b9603c4e5e85d20260b7d7a00a866cbe9fb">0: ICANN ’93</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809888</td>
<td>0.469434</td>
<td><a href="https://www.semanticscholar.org/paper/6a4e262e4b2b875de83682bb1c26f9ba40c635f7">7: Estimation of size of hidden layer on basis of bound of generalization error</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786988</td>
<td>0.277176</td>
<td><a href="https://www.semanticscholar.org/paper/fb9d1d1d2c3c898823cb0b38e999799c0c7ba6c1">3: Minimizing the Quadratic Training Error of a Sigmoid Neuron Is Hard</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784655</td>
<td>0.297225</td>
<td><a href="https://www.semanticscholar.org/paper/d28bc1368e8ad222174461939e73bf3f69a9b8f1">10: Complexity issues in learning by neural nets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768267</td>
<td>0.545316</td>
<td><a href="https://www.semanticscholar.org/paper/76623c3a14a67dd454a55e4790f60bd670ec2f0c">40: ON THE ALGEBRAIC STRUCTURE OF FEEDFORWARD NETWORK WEIGHT SPACES</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766625</td>
<td>0.455083</td>
<td><a href="https://www.semanticscholar.org/paper/b3bc84ce7da357b150e3a85961828ce49dec2f21">1: Strong data processing inequality in neural networks with noisy neurons and its implications</a></td>
</tr>
<tr>
<td>0</td>
<td>0.764701</td>
<td>0.612641</td>
<td><a href="https://www.semanticscholar.org/paper/01a824dbd00c86493be17dbbc399e24f1da11e91">9: Training Discrete-Valued Neural Networks with Sign Activations Using Weight Distributions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758404</td>
<td>0.122877</td>
<td>NA:42107767</td>
</tr>
<tr>
<td>0</td>
<td>0.701139</td>
<td>0.975880</td>
<td><a href="https://www.semanticscholar.org/paper/78d19e190dc5ece1e4e42a76662c5e98c2bb0842">167: Ensemble learning in Bayesian neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.564387</td>
<td>0.948154</td>
<td><a href="https://www.semanticscholar.org/paper/efecb6b217b770a0f56e8d3506d90f2c07aa41f5">10: Output-Constrained Bayesian Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.664451</td>
<td>0.945986</td>
<td><a href="https://www.semanticscholar.org/paper/ab1e853bc28ee5ef623bef7d609178de8636c999">1: Collapsed Variational Bounds for Bayesian Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.588641</td>
<td>0.945538</td>
<td><a href="https://www.semanticscholar.org/paper/be6e55c5300036f8fe79061035f7543bdb561ff5">72: Early Stopping as Nonparametric Variational Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.615823</td>
<td>0.945508</td>
<td><a href="https://www.semanticscholar.org/paper/92ea0e1f85397cb85668e20ff86c11a0cb97fa73">11: Fixing Variational Bayes: Deterministic Variational Inference for Bayesian Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.565483</td>
<td>0.945140</td>
<td><a href="https://www.semanticscholar.org/paper/9eebd3c7971a239cf69a0358563f397bd8a8f99c">75: Hands-On Bayesian Neural Networks—A Tutorial for Deep Learning Users</a></td>
</tr>
<tr>
<td>0</td>
<td>0.724692</td>
<td>0.943515</td>
<td><a href="https://www.semanticscholar.org/paper/7e17a3c231dc37d162b9ad74043afc1cee4ee2dd">651: Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.657633</td>
<td>0.942745</td>
<td><a href="https://www.semanticscholar.org/paper/91441bb1237b290a5d207881b3667d28dc807c03">0: Investigating Inference in Bayesian Neural Networks via Active Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.685768</td>
<td>0.940021</td>
<td><a href="https://www.semanticscholar.org/paper/50f63fdea55375036a196664f125f24f4b1a9793">2: Latent Derivative Bayesian Last Layer Networks</a></td>
</tr>
</table></html>
