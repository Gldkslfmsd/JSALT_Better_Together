<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f">12594: Rectified Linear Units Improve Restricted Boltzmann Machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.763371</td>
<td>0.520799</td>
<td><a href="https://www.semanticscholar.org/paper/99fef41cb04c7141df447768fff7df50898680f1">2: Restricted Boltzmann Machine with Adaptive Local Hidden Units</a></td>
</tr>
<tr>
<td>0</td>
<td>0.685543</td>
<td>0.138408</td>
<td><a href="https://www.semanticscholar.org/paper/5317298635a0ed2d22e1060c4390a15e6c34c0d1">7: Learning Binary Perceptrons Perfectly Efficiently</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674947</td>
<td>0.491496</td>
<td><a href="https://www.semanticscholar.org/paper/d3a851c929b6cc0517acdc5cd3e909518c708351">2: Kullback-Leibler Importance Estimation Procedureを用いた Restricted Boltzmann Machineの学習アルゴリズム Learning Algorithm in Restricted Boltzmann Machines using Kullback-Leibler Importance Estimation Procedure</a></td>
</tr>
<tr>
<td>0</td>
<td>0.671025</td>
<td>0.074965</td>
<td>NA:206457126</td>
</tr>
<tr>
<td>0</td>
<td>0.669106</td>
<td>0.642004</td>
<td><a href="https://www.semanticscholar.org/paper/5b7547aa20140b29cd6d8426e4110d4ef97717ed">0: ReLEx: Regularisation for Linear Extrapolation in Neural Networks with Rectified Linear Units</a></td>
</tr>
<tr>
<td>0</td>
<td>0.666688</td>
<td>0.235287</td>
<td><a href="https://www.semanticscholar.org/paper/9d6d1d1a623b0c59614f4100e89219dbb3ea3904">9: Sequence recognition with radial basis function networks: experiments with spoken digits</a></td>
</tr>
<tr>
<td>0</td>
<td>0.655861</td>
<td>0.352713</td>
<td><a href="https://www.semanticscholar.org/paper/58a76705d3f7a1ee2d89e3ee01495ae65fcfd177">4: Improving Generalization Performance of Neural Networks by Constructing Orthonormal Weight Vectors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.654000</td>
<td>0.611619</td>
<td><a href="https://www.semanticscholar.org/paper/3214cde25ab64fba27346f2f47ed7abeaf01352a">17: Kolmogorov width decay and poor approximators in machine learning: shallow neural networks, random feature models and neural tangent kernels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.641760</td>
<td>0.659975</td>
<td><a href="https://www.semanticscholar.org/paper/2443b743669f87f9f7a9c8e25018b05205d4eebc">16: Training Binary Neural Networks using the Bayesian Learning Rule</a></td>
</tr>
<tr>
<td>0</td>
<td>0.582100</td>
<td>0.979474</td>
<td><a href="https://www.semanticscholar.org/paper/67107f78a84bdb2411053cb54e94fa226eea6d8e">5804: Deep Sparse Rectifier Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.599559</td>
<td>0.979288</td>
<td><a href="https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f">12258: Understanding the difficulty of training deep feedforward neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.972977</td>
<td><a href="https://www.semanticscholar.org/paper/5ef5e2fa01f1b3b512786bf9f8e2c98f7557f4f9">399: Lasagne: First release.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.544973</td>
<td>0.969547</td>
<td><a href="https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d">9157: TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.603884</td>
<td>0.966133</td>
<td><a href="https://www.semanticscholar.org/paper/d589392ab606a3d2861988ebcba95176517939ec">360: On Loss Functions for Deep Neural Networks in Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.626552</td>
<td>0.949672</td>
<td><a href="https://www.semanticscholar.org/paper/f63e917638553414526a0cc8550de4ad2d83fe7a">3622: Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.619042</td>
<td>0.944657</td>
<td><a href="https://www.semanticscholar.org/paper/1ba3b27cc34bddee92670f9d8dcd3b66dee4838b">40: Comparative Study of Convolution Neural Network’s Relu and Leaky-Relu Activation Functions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.616212</td>
<td>0.943112</td>
<td><a href="https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698">27771: Dropout: a simple way to prevent neural networks from overfitting</a></td>
</tr>
<tr>
<td>0</td>
<td>0.586239</td>
<td>0.936597</td>
<td><a href="https://www.semanticscholar.org/paper/424a6e62084d919bfc2e39a507c263e5991ebdad">1305: Self-Normalizing Neural Networks</a></td>
</tr>
</table></html>
<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f">12594: Rectified Linear Units Improve Restricted Boltzmann Machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.763371</td>
<td>0.520799</td>
<td><a href="https://www.semanticscholar.org/paper/99fef41cb04c7141df447768fff7df50898680f1">2: Restricted Boltzmann Machine with Adaptive Local Hidden Units</a></td>
</tr>
<tr>
<td>0</td>
<td>0.685543</td>
<td>0.138408</td>
<td><a href="https://www.semanticscholar.org/paper/5317298635a0ed2d22e1060c4390a15e6c34c0d1">7: Learning Binary Perceptrons Perfectly Efficiently</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674947</td>
<td>0.491496</td>
<td><a href="https://www.semanticscholar.org/paper/d3a851c929b6cc0517acdc5cd3e909518c708351">2: Kullback-Leibler Importance Estimation Procedureを用いた Restricted Boltzmann Machineの学習アルゴリズム Learning Algorithm in Restricted Boltzmann Machines using Kullback-Leibler Importance Estimation Procedure</a></td>
</tr>
<tr>
<td>0</td>
<td>0.671025</td>
<td>0.074965</td>
<td>NA:206457126</td>
</tr>
<tr>
<td>0</td>
<td>0.669106</td>
<td>0.642004</td>
<td><a href="https://www.semanticscholar.org/paper/5b7547aa20140b29cd6d8426e4110d4ef97717ed">0: ReLEx: Regularisation for Linear Extrapolation in Neural Networks with Rectified Linear Units</a></td>
</tr>
<tr>
<td>0</td>
<td>0.666688</td>
<td>0.235287</td>
<td><a href="https://www.semanticscholar.org/paper/9d6d1d1a623b0c59614f4100e89219dbb3ea3904">9: Sequence recognition with radial basis function networks: experiments with spoken digits</a></td>
</tr>
<tr>
<td>0</td>
<td>0.655861</td>
<td>0.352713</td>
<td><a href="https://www.semanticscholar.org/paper/58a76705d3f7a1ee2d89e3ee01495ae65fcfd177">4: Improving Generalization Performance of Neural Networks by Constructing Orthonormal Weight Vectors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.654000</td>
<td>0.611619</td>
<td><a href="https://www.semanticscholar.org/paper/3214cde25ab64fba27346f2f47ed7abeaf01352a">17: Kolmogorov width decay and poor approximators in machine learning: shallow neural networks, random feature models and neural tangent kernels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.641760</td>
<td>0.659975</td>
<td><a href="https://www.semanticscholar.org/paper/2443b743669f87f9f7a9c8e25018b05205d4eebc">16: Training Binary Neural Networks using the Bayesian Learning Rule</a></td>
</tr>
<tr>
<td>0</td>
<td>0.582100</td>
<td>0.979474</td>
<td><a href="https://www.semanticscholar.org/paper/67107f78a84bdb2411053cb54e94fa226eea6d8e">5804: Deep Sparse Rectifier Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.599559</td>
<td>0.979288</td>
<td><a href="https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f">12258: Understanding the difficulty of training deep feedforward neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.972977</td>
<td><a href="https://www.semanticscholar.org/paper/5ef5e2fa01f1b3b512786bf9f8e2c98f7557f4f9">399: Lasagne: First release.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.544973</td>
<td>0.969547</td>
<td><a href="https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d">9157: TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.603884</td>
<td>0.966133</td>
<td><a href="https://www.semanticscholar.org/paper/d589392ab606a3d2861988ebcba95176517939ec">360: On Loss Functions for Deep Neural Networks in Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.626552</td>
<td>0.949672</td>
<td><a href="https://www.semanticscholar.org/paper/f63e917638553414526a0cc8550de4ad2d83fe7a">3622: Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.619042</td>
<td>0.944657</td>
<td><a href="https://www.semanticscholar.org/paper/1ba3b27cc34bddee92670f9d8dcd3b66dee4838b">40: Comparative Study of Convolution Neural Network’s Relu and Leaky-Relu Activation Functions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.616212</td>
<td>0.943112</td>
<td><a href="https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698">27771: Dropout: a simple way to prevent neural networks from overfitting</a></td>
</tr>
<tr>
<td>0</td>
<td>0.586239</td>
<td>0.936597</td>
<td><a href="https://www.semanticscholar.org/paper/424a6e62084d919bfc2e39a507c263e5991ebdad">1305: Self-Normalizing Neural Networks</a></td>
</tr>
</table></html>
