<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/9f87a11a523e4680e61966e36ea2eac516096f23">2620: A View of the Em Algorithm that Justifies Incremental, Sparse, and other Variants</a></td>
</tr>
<tr>
<td>0</td>
<td>0.898055</td>
<td>0.930551</td>
<td><a href="https://www.semanticscholar.org/paper/7cf1292781c1613927de466f2015225da19e8b19">7: A New View of the EM Algorithm thatJusti es Incremental and Other VariantsRadford</a></td>
</tr>
<tr>
<td>0</td>
<td>0.787237</td>
<td>0.864927</td>
<td><a href="https://www.semanticscholar.org/paper/6c40bc0fd621b1001bb1a1041122995c7f2fe0f1">6: Efficient computation of the Fisher information matrix in the EM algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781726</td>
<td>0.894364</td>
<td><a href="https://www.semanticscholar.org/paper/d1c24faaaa7cbbd8e0219070c3b751d8438263fe">723: Convergence of a stochastic approximation version of the EM algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.778383</td>
<td>0.594843</td>
<td><a href="https://www.semanticscholar.org/paper/b2d313d4c007852d5cc4c327cc4d0010379d1c45">4: A map approach for ℓq-norm regularized sparse parameter estimation using the EM algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.776392</td>
<td>0.908912</td>
<td><a href="https://www.semanticscholar.org/paper/33f54c9f71ebafd70db7cc6b9c4f311ac2ec916a">17: Domains of convergence for the EM algorithm: a cautionary tale in a location estimation problem</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766168</td>
<td>0.914269</td>
<td><a href="https://www.semanticscholar.org/paper/5a53920f77ddbcde3e6651718fb59a66d7ce892e">88: The EM Algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.764269</td>
<td>0.840766</td>
<td><a href="https://www.semanticscholar.org/paper/3d33e78a2eb75b1b224bb9ef62d1be7bd15a22c7">3: The Generalized CEM Algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.749607</td>
<td>0.879339</td>
<td><a href="https://www.semanticscholar.org/paper/266a32615cdc2028eb743dc19d28242c8e67e357">1481: A Monte Carlo Implementation of the EM Algorithm and the Poor Man's Data Augmentation Algorithms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742101</td>
<td>0.826487</td>
<td><a href="https://www.semanticscholar.org/paper/04a855b44477eb5c97bfc218fc86551447049e9b">0: A Robust and Flexible EM Algorithm for Mixtures of Elliptical Distributions with Missing Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737213</td>
<td>0.985127</td>
<td><a href="https://www.semanticscholar.org/paper/a6d815f8b3fd31fbf6db122a0e367d3e2a58ee9b">172: Optimization with EM and Expectation-Conjugate-Gradient</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796833</td>
<td>0.980724</td>
<td><a href="https://www.semanticscholar.org/paper/3d6a4c1e87fce6abb4f3d34f6cf860cc11e47b23">108: Online EM Algorithm for Latent Data Models</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.978529</td>
<td><a href="https://www.semanticscholar.org/paper/418cc44768ff9d0ed8cf4cef79869f90ab672f7b">218: A new view of the EM algorithm that justifies incremental and other variants</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737004</td>
<td>0.974084</td>
<td><a href="https://www.semanticscholar.org/paper/d0f3bbe7b5654427246bee62650f8f89ec3ba26c">516: Deterministic annealing EM algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751826</td>
<td>0.973563</td>
<td><a href="https://www.semanticscholar.org/paper/f1064a66a060294e20c7047c5f0e4af754dac32b">399: On‐line expectation–maximization algorithm for latent data models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.665878</td>
<td>0.966327</td>
<td><a href="https://www.semanticscholar.org/paper/3f5089ec05fcdaeabab202e98330be3ffd3eab3a">26: Using lower bounds to approxi-mate integrals</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766202</td>
<td>0.965297</td>
<td><a href="https://www.semanticscholar.org/paper/fa15611d42ae97d196331b8f41c2d3c37411fc78">307: Theory and Use of the EM Algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.698387</td>
<td>0.965149</td>
<td><a href="https://www.semanticscholar.org/paper/0e24dbbb32cbbaf32f020443c1f50fa7f2e5ef1d">133: Variational learning for Gaussian mixture models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.647670</td>
<td>0.963346</td>
<td><a href="https://www.semanticscholar.org/paper/2300241ec3eee313488de9e0e37f6499c515eefd">12: Relationship between gradient and EM steps in latent variable models</a></td>
</tr>
</table></html>
