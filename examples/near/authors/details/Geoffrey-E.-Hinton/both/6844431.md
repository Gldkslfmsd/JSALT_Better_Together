<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698">27771: Dropout: a simple way to prevent neural networks from overfitting</a></td>
</tr>
<tr>
<td>0</td>
<td>0.945937</td>
<td>0.110857</td>
<td><a href="https://www.semanticscholar.org/paper/2d0decf3151c68f9037aed9bf4a89f3be5beb84c">2: Drop : A Simple Way to Prevent Neural Network by Overfitting</a></td>
</tr>
<tr>
<td>0</td>
<td>0.915352</td>
<td>0.636981</td>
<td><a href="https://www.semanticscholar.org/paper/793e0f5211108c65b23bdd08f8b9cfe4155157a0">12: A Survey on Prevention of Overfitting in Convolution Neural Networks Using Machine Learning Techniques</a></td>
</tr>
<tr>
<td>0</td>
<td>0.907041</td>
<td>0.840457</td>
<td><a href="https://www.semanticscholar.org/paper/5d5d4f49d6443c8529a6f5ebef5c499d47a869da">232: Improving Neural Networks with Dropout</a></td>
</tr>
<tr>
<td>0</td>
<td>0.861841</td>
<td>0.742273</td>
<td><a href="https://www.semanticscholar.org/paper/15f446ad6d335b48060614aa297e57b23b6e9a5c">1: Automatic Dropout for Deep Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.855101</td>
<td>0.099028</td>
<td><a href="https://www.semanticscholar.org/paper/ca019b31bda7e17e5263c700a4091d60e8f82f0f">0: Dropout- A Detailed Survey</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800064</td>
<td>0.642802</td>
<td><a href="https://www.semanticscholar.org/paper/d851038005a3e057ec7839e58a5448c8f895b8e3">0: Regularizing Deep Neural Networks by Ensemble-based Low-Level Sample-Variances Method</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794668</td>
<td>0.412212</td>
<td><a href="https://www.semanticscholar.org/paper/12a630e7e0e1cf44602810a04936e18f988bc167">3: Additive Ensemble Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792346</td>
<td>0.311266</td>
<td><a href="https://www.semanticscholar.org/paper/2efd454b0e8bde68598ede62415d85068e8d4d24">3: Sequential Training of Neural Networks with Gradient Boosting</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790779</td>
<td>0.583834</td>
<td><a href="https://www.semanticscholar.org/paper/83438a7392ff70a80fffa5d04f5937df36abca68">9: SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792864</td>
<td>0.955695</td>
<td><a href="https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f">12258: Understanding the difficulty of training deep feedforward neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.535725</td>
<td>0.947762</td>
<td><a href="https://www.semanticscholar.org/paper/67107f78a84bdb2411053cb54e94fa226eea6d8e">5804: Deep Sparse Rectifier Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.616212</td>
<td>0.943112</td>
<td><a href="https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f">12594: Rectified Linear Units Improve Restricted Boltzmann Machines</a></td>
</tr>
<tr>
<td>0</td>
<td>0.615645</td>
<td>0.943047</td>
<td><a href="https://www.semanticscholar.org/paper/6b570069f14c7588e066f7138e1f21af59d62e61">2083: Theano: A Python framework for fast computation of mathematical expressions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.666544</td>
<td>0.942467</td>
<td><a href="https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d">9157: TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.939144</td>
<td><a href="https://www.semanticscholar.org/paper/96ca450bedf5c0be78c93e14aa92d2da6a223971">2: A Study on Dropout Techniques to Reduce Overfitting in Deep Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.669774</td>
<td>0.929679</td>
<td><a href="https://www.semanticscholar.org/paper/1bdf014c1bd613dbdc656e074379badc4ae492dc">231: RMSProp and equilibrated adaptive learning rates for non-convex optimization.</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.929286</td>
<td><a href="https://www.semanticscholar.org/paper/5ef5e2fa01f1b3b512786bf9f8e2c98f7557f4f9">399: Lasagne: First release.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.572764</td>
<td>0.929194</td>
<td><a href="https://www.semanticscholar.org/paper/14a356b520cb7900e0a799e1c37f500944bf992b">17: AURALISATION OF DEEP CONVOLUTIONAL NEURAL NETWORKS: LISTENING TO LEARNED FEATURES</a></td>
</tr>
</table></html>
