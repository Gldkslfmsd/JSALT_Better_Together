<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/0f6911bc1e6abee8bbf9dd3f8d54d40466429da7">846: Zero-shot Learning with Semantic Output Codes</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793687</td>
<td>0.912652</td>
<td><a href="https://www.semanticscholar.org/paper/0dbde0840fdf887ba08caa9ec24346bf66b91add">0: Learning Semantic Ambiguities for Zero-Shot Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.760704</td>
<td>0.573644</td>
<td><a href="https://www.semanticscholar.org/paper/cf42c89fe45e31cdd83be78c22c28508e335b9aa">437: Low-Shot Learning from Imaginary Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752802</td>
<td>0.884331</td>
<td><a href="https://www.semanticscholar.org/paper/90bda3f5eaca18250477989f7a30e3e60c85b4b8">0: Zero-shot Learning with Class Description Regularization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752509</td>
<td>0.494742</td>
<td><a href="https://www.semanticscholar.org/paper/3ad1caf62e0f4353ac3a7bb563392f7683999d23">2: COMPAS: Representation Learning with Compositional Part Sharing for Few-Shot Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.747133</td>
<td>0.855891</td>
<td><a href="https://www.semanticscholar.org/paper/fd676b0058d5d83e588e0bb1ed5c67a866f4891c">1: Towards Visual Explainable Active Learning for Zero-Shot Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742736</td>
<td>0.527487</td>
<td><a href="https://www.semanticscholar.org/paper/c1f3d3f50d9574f1a4bd34eba0e0d17b5f7382ae">4: A Modular Theory of Feature Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742253</td>
<td>0.828475</td>
<td><a href="https://www.semanticscholar.org/paper/4b23d64e4964367ac9eec982f12035bf8baa85b8">5: Zero-shot classification with unseen prototype learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737810</td>
<td>0.505984</td>
<td><a href="https://www.semanticscholar.org/paper/6b5a4547c479c78b8ee680fcc05045d4e1ce8efa">0: Online Unsupervised Learning of Visual Representations and Categories</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734387</td>
<td>0.715445</td>
<td><a href="https://www.semanticscholar.org/paper/f9b33df6c912d39cc0df10a23f9c2d131ffb06ab">25: What Makes a Good Detector? - Structured Priors for Learning from Few Examples</a></td>
</tr>
<tr>
<td>0</td>
<td>0.743316</td>
<td>0.984703</td>
<td><a href="https://www.semanticscholar.org/paper/fabb43426ead447305c9186f54d5124863730e47">352: Zero-data Learning of New Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752833</td>
<td>0.975340</td>
<td><a href="https://www.semanticscholar.org/paper/755e9f43ce398ae8737366720c5f82685b0c253e">1161: Zero-Shot Learning Through Cross-Modal Transfer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.676608</td>
<td>0.970280</td>
<td><a href="https://www.semanticscholar.org/paper/3a8e1b6f624438c1c35af19a20b9105f293c31fe">2: A novel approach based on fully connected weighted bipartite graph for zero-shot learning problems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.685373</td>
<td>0.969421</td>
<td><a href="https://www.semanticscholar.org/paper/caa632d101a41a7860562e4399a5eaa9a4088b55">516: Label-Embedding for Attribute-Based Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.729472</td>
<td>0.969379</td>
<td><a href="https://www.semanticscholar.org/paper/a6b8cd5f34b438f487679b1166ea03e56eb14c9e">107: Semi-Supervised Zero-Shot Classification with Label Representation Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.720586</td>
<td>0.969290</td>
<td><a href="https://www.semanticscholar.org/paper/ccbc09d498cad330c37f94e15b77bf220b10ccb4">219: Transductive Multi-view Embedding for Zero-Shot Recognition and Annotation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.729408</td>
<td>0.968272</td>
<td><a href="https://www.semanticscholar.org/paper/af3a5c22e447416c5de12627c49ba1e5cfdd5067">11: Vocabulary-Informed Zero-Shot and Open-Set Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752510</td>
<td>0.967367</td>
<td><a href="https://www.semanticscholar.org/paper/f038e8c3656f5c7a4846a7eca731eb567255adcb">263: Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.718501</td>
<td>0.965143</td>
<td><a href="https://www.semanticscholar.org/paper/b29227f8dde62a5cd21678b4bc429206615485a2">38: Max-Margin Zero-Shot Learning for Multi-class Classification</a></td>
</tr>
</table></html>
