<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/1366de5bb112746a555e9c0cd00de3ad8628aea8">6124: Improving neural networks by preventing co-adaptation of feature detectors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766695</td>
<td>0.452199</td>
<td><a href="https://www.semanticscholar.org/paper/f2ca3367419f3689159d2badbbd38c10546bf6e4">3: Correlative training and recurrent network automata for speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766131</td>
<td>0.345764</td>
<td><a href="https://www.semanticscholar.org/paper/7655e707acb4328834de1cf79eaa7be603e6168e">5: Improving speech recognition learning through lazy training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765129</td>
<td>0.530543</td>
<td><a href="https://www.semanticscholar.org/paper/0e9f88e8f47b7a1b73d9090f0da3f0e5c2bec9aa">7: Regularization for Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759467</td>
<td>0.092375</td>
<td><a href="https://www.semanticscholar.org/paper/79c5e3afea1b362d60d0d8da8945cdb052c28174">2: Noise suppression in training data for improving generalization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.739367</td>
<td>0.219201</td>
<td><a href="https://www.semanticscholar.org/paper/b1204e264b912b72e383f828f35ef0d33193a055">1: A self-supervised learning system for category detection by integrating information from several sensors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732866</td>
<td>0.429668</td>
<td><a href="https://www.semanticscholar.org/paper/c3e4a73d397bef2cb8262218d66717d43a68a743">4: Strategic Application of Feedforward Neural Networks to Large-Scale Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727428</td>
<td>0.320963</td>
<td><a href="https://www.semanticscholar.org/paper/cb6ee44fe3af6e5f34356cda8134f8f99299d91b">38: Learn more by training less: systematicity in sentence processing by recurrent networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.720896</td>
<td>0.162971</td>
<td><a href="https://www.semanticscholar.org/paper/75fdbbc99c1478677159da94eb6f46767cc118e6">2: Survey of Neural Net Paradigms for Specification of Discrete Networks.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719933</td>
<td>0.135982</td>
<td><a href="https://www.semanticscholar.org/paper/19fcc0e1149f9e14199a381f7db0193ae7273d82">2: Effective learning in noisy environment using neural network ensemble</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738030</td>
<td>0.981460</td>
<td><a href="https://www.semanticscholar.org/paper/1a3c74c7b11ad5635570932577cdde2a3f7a6a5c">1162: Improving deep neural networks for LVCSR using rectified linear units and dropout</a></td>
</tr>
<tr>
<td>0</td>
<td>0.457147</td>
<td>0.978007</td>
<td><a href="https://www.semanticscholar.org/paper/3ec10bc12d9e40b1a43eaf0f4d7e3320ac5e7dc8">236: Theano: Deep Learning on GPUs with Python</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.976250</td>
<td><a href="https://www.semanticscholar.org/paper/563e821bb5ea825efb56b77484f5287f08cf3753">4034: Convolutional networks for images, speech, and time series</a></td>
</tr>
<tr>
<td>0</td>
<td>0.725859</td>
<td>0.973767</td>
<td><a href="https://www.semanticscholar.org/paper/5d5d4f49d6443c8529a6f5ebef5c499d47a869da">232: Improving Neural Networks with Dropout</a></td>
</tr>
<tr>
<td>0</td>
<td>0.430735</td>
<td>0.973348</td>
<td><a href="https://www.semanticscholar.org/paper/63936fa32f9e75ab2a864daae6791ce02112183d">830: Theano: A CPU and GPU Math Compiler in Python</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691010</td>
<td>0.968553</td>
<td><a href="https://www.semanticscholar.org/paper/1b3aab4ff8f77b81501f271877321609cc1a1a2b">116: Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.692519</td>
<td>0.961277</td>
<td><a href="https://www.semanticscholar.org/paper/86efe7769f2b8a0e15ca213ab09881e6705caeb0">1518: Convolutional Neural Networks for Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.692295</td>
<td>0.959568</td>
<td><a href="https://www.semanticscholar.org/paper/80d2e35888a5f072aae0c6f367c52f33dc874f8d">191: Towards dropout training for convolutional neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.694605</td>
<td>0.957531</td>
<td><a href="https://www.semanticscholar.org/paper/327d3df8ea2020882827d6bace1e26c9d24309c2">238: The dropout learning algorithm</a></td>
</tr>
</table></html>
<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/1366de5bb112746a555e9c0cd00de3ad8628aea8">6124: Improving neural networks by preventing co-adaptation of feature detectors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766695</td>
<td>0.452199</td>
<td><a href="https://www.semanticscholar.org/paper/f2ca3367419f3689159d2badbbd38c10546bf6e4">3: Correlative training and recurrent network automata for speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766131</td>
<td>0.345764</td>
<td><a href="https://www.semanticscholar.org/paper/7655e707acb4328834de1cf79eaa7be603e6168e">5: Improving speech recognition learning through lazy training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765129</td>
<td>0.530543</td>
<td><a href="https://www.semanticscholar.org/paper/0e9f88e8f47b7a1b73d9090f0da3f0e5c2bec9aa">7: Regularization for Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759467</td>
<td>0.092375</td>
<td><a href="https://www.semanticscholar.org/paper/79c5e3afea1b362d60d0d8da8945cdb052c28174">2: Noise suppression in training data for improving generalization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.739367</td>
<td>0.219201</td>
<td><a href="https://www.semanticscholar.org/paper/b1204e264b912b72e383f828f35ef0d33193a055">1: A self-supervised learning system for category detection by integrating information from several sensors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732866</td>
<td>0.429668</td>
<td><a href="https://www.semanticscholar.org/paper/c3e4a73d397bef2cb8262218d66717d43a68a743">4: Strategic Application of Feedforward Neural Networks to Large-Scale Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727428</td>
<td>0.320963</td>
<td><a href="https://www.semanticscholar.org/paper/cb6ee44fe3af6e5f34356cda8134f8f99299d91b">38: Learn more by training less: systematicity in sentence processing by recurrent networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.720896</td>
<td>0.162971</td>
<td><a href="https://www.semanticscholar.org/paper/75fdbbc99c1478677159da94eb6f46767cc118e6">2: Survey of Neural Net Paradigms for Specification of Discrete Networks.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719933</td>
<td>0.135982</td>
<td><a href="https://www.semanticscholar.org/paper/19fcc0e1149f9e14199a381f7db0193ae7273d82">2: Effective learning in noisy environment using neural network ensemble</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738030</td>
<td>0.981460</td>
<td><a href="https://www.semanticscholar.org/paper/1a3c74c7b11ad5635570932577cdde2a3f7a6a5c">1162: Improving deep neural networks for LVCSR using rectified linear units and dropout</a></td>
</tr>
<tr>
<td>0</td>
<td>0.457147</td>
<td>0.978007</td>
<td><a href="https://www.semanticscholar.org/paper/3ec10bc12d9e40b1a43eaf0f4d7e3320ac5e7dc8">236: Theano: Deep Learning on GPUs with Python</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.976250</td>
<td><a href="https://www.semanticscholar.org/paper/563e821bb5ea825efb56b77484f5287f08cf3753">4034: Convolutional networks for images, speech, and time series</a></td>
</tr>
<tr>
<td>0</td>
<td>0.725859</td>
<td>0.973767</td>
<td><a href="https://www.semanticscholar.org/paper/5d5d4f49d6443c8529a6f5ebef5c499d47a869da">232: Improving Neural Networks with Dropout</a></td>
</tr>
<tr>
<td>0</td>
<td>0.430735</td>
<td>0.973348</td>
<td><a href="https://www.semanticscholar.org/paper/63936fa32f9e75ab2a864daae6791ce02112183d">830: Theano: A CPU and GPU Math Compiler in Python</a></td>
</tr>
<tr>
<td>0</td>
<td>0.691010</td>
<td>0.968553</td>
<td><a href="https://www.semanticscholar.org/paper/1b3aab4ff8f77b81501f271877321609cc1a1a2b">116: Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.692519</td>
<td>0.961277</td>
<td><a href="https://www.semanticscholar.org/paper/86efe7769f2b8a0e15ca213ab09881e6705caeb0">1518: Convolutional Neural Networks for Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.692295</td>
<td>0.959568</td>
<td><a href="https://www.semanticscholar.org/paper/80d2e35888a5f072aae0c6f367c52f33dc874f8d">191: Towards dropout training for convolutional neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.694605</td>
<td>0.957531</td>
<td><a href="https://www.semanticscholar.org/paper/327d3df8ea2020882827d6bace1e26c9d24309c2">238: The dropout learning algorithm</a></td>
</tr>
</table></html>
