<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/509a275d2563e08a193d4b032f43dd9eb9e6c575">31: G-DAug: Generative Data Augmentation for Commonsense Reasoning</a></td>
</tr>
<tr>
<td>1</td>
<td>0.970838</td>
<td>0.999158</td>
<td><a href="https://www.semanticscholar.org/paper/1b8a5210f5ec202d3c6b880f389ca9ddc6fbaf9a">33: Generative Data Augmentation for Commonsense Reasoning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.826855</td>
<td>0.886051</td>
<td><a href="https://www.semanticscholar.org/paper/77f08ec1fc1a26d5e2c493be06a305d1480ad1c0">26: CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825940</td>
<td>-0.014261</td>
<td>NA:104292422</td>
</tr>
<tr>
<td>0</td>
<td>0.824662</td>
<td>0.986880</td>
<td><a href="https://www.semanticscholar.org/paper/af5c4b80fbf847f69a202ba5a780a3dd18c1a027">448: SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812976</td>
<td>0.957108</td>
<td><a href="https://www.semanticscholar.org/paper/0119a57cf88ef16e6dc291252fae340bb6b3953c">91: CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806777</td>
<td>0.749206</td>
<td><a href="https://www.semanticscholar.org/paper/4cd2bd79b0e0aa3a104799337d37b13149ffeff9">28: Insufficient Data Can Also Rock! Learning to Converse Using Smaller Data with Augmentation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.806324</td>
<td>-0.014261</td>
<td><a href="https://www.semanticscholar.org/paper/b502b2d5bcd5bb38f5253bfa9e8c9f7ae1756fda">0: Revisiting Generative Commonsense Reasoning: A Pre-Ordering Approach</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801931</td>
<td>0.755124</td>
<td><a href="https://www.semanticscholar.org/paper/023719b69c1722e35ad4d06e2efe130f630334f0">0: Simple Contrastive Representation Adversarial Learning for NLP Tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.799473</td>
<td>0.929702</td>
<td><a href="https://www.semanticscholar.org/paper/15f5d93f6aef086451ad98a73cf3c067c548ecee">1: BLISS: Robust Sequence-to-Sequence Learning via Self-Supervised Input Representation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781365</td>
<td>0.994086</td>
<td><a href="https://www.semanticscholar.org/paper/9fec5868542b4d9070306f1418d1d21666226e90">66: Evaluating NLP Models via Contrast Sets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.629864</td>
<td>0.993407</td>
<td><a href="https://www.semanticscholar.org/paper/d6fa3acbb070132979165671c80344fd4c6f9450">0: LMdiff: A Visual Diff Tool to Compare Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.609929</td>
<td>0.993344</td>
<td><a href="https://www.semanticscholar.org/paper/776a49616c84d52e8fff9911c561e3bac90910eb">42: Out of Order: How important is the sequential order of words in a sentence in Natural Language Understanding tasks?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.677598</td>
<td>0.992663</td>
<td><a href="https://www.semanticscholar.org/paper/77a096d80eb4dd4ccd103d1660c5a5498f7d026b">65: Dynabench: Rethinking Benchmarking in NLP</a></td>
</tr>
<tr>
<td>0</td>
<td>0.668618</td>
<td>0.992655</td>
<td><a href="https://www.semanticscholar.org/paper/5b6c582d51266be9aa7e32bfdc20891e5231eca4">20: When Can Models Learn From Explanations? A Formal Framework for Understanding the Roles of Explanation Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.646114</td>
<td>0.992446</td>
<td><a href="https://www.semanticscholar.org/paper/82a44fbe798d514c81439c90c655975a32c2af10">28: The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.566197</td>
<td>0.992087</td>
<td><a href="https://www.semanticscholar.org/paper/295dbbf20b4c2fa0048813e204dbeb37d3caaeb3">4: A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.687896</td>
<td>0.991878</td>
<td><a href="https://www.semanticscholar.org/paper/4311eefc03a3f391bae39ebf364cbd5f8b90a001">7: Beyond Leaderboards: A survey of methods for revealing weaknesses in Natural Language Inference data and models</a></td>
</tr>
</table></html>
