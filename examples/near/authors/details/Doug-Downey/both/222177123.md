<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/1b8a5210f5ec202d3c6b880f389ca9ddc6fbaf9a">33: Generative Data Augmentation for Commonsense Reasoning</a></td>
</tr>
<tr>
<td>1</td>
<td>0.970838</td>
<td>0.999158</td>
<td><a href="https://www.semanticscholar.org/paper/509a275d2563e08a193d4b032f43dd9eb9e6c575">31: G-DAug: Generative Data Augmentation for Commonsense Reasoning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.838979</td>
<td>0.984514</td>
<td><a href="https://www.semanticscholar.org/paper/6597d61bdb531051678c773526758a6dc113b9ce">6: COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences</a></td>
</tr>
<tr>
<td>0</td>
<td>0.832882</td>
<td>0.954021</td>
<td><a href="https://www.semanticscholar.org/paper/be5c4cbde12db1c7bb89e3775e41e207aa4f9ed3">6: Improving Commonsense Causal Reasoning by Adversarial Training and Data Augmentation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811359</td>
<td>0.858387</td>
<td><a href="https://www.semanticscholar.org/paper/c44ec5fe53b0349b7239ab1c08135f7cb0f1c96d">2: Virtual Data Augmentation: A Robust and General Framework for Fine-tuning Pre-trained Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.808602</td>
<td>0.747684</td>
<td><a href="https://www.semanticscholar.org/paper/4cd2bd79b0e0aa3a104799337d37b13149ffeff9">28: Insufficient Data Can Also Rock! Learning to Converse Using Smaller Data with Augmentation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795103</td>
<td>0.262278</td>
<td><a href="https://www.semanticscholar.org/paper/fec31ef31e4c0ff30618e5caa30ea15e3265e489">2: How Does Contrastive Pre-training Connect Disparate Domains?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788362</td>
<td>0.905375</td>
<td><a href="https://www.semanticscholar.org/paper/8436897e713c2242d6291df9a6a33c1544d4dd39">8: Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785968</td>
<td>0.865078</td>
<td><a href="https://www.semanticscholar.org/paper/e327186b75e8359ea10c7258c2fdcf93c437e2a5">3: Manifold Adversarial Augmentation for Neural Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784485</td>
<td>0.140212</td>
<td><a href="https://www.semanticscholar.org/paper/a9ced877c5ac8563053e246ac1e3cc690f24609d">24: Uncertainty-Aware Deep Classifiers Using Generative Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768021</td>
<td>0.994717</td>
<td><a href="https://www.semanticscholar.org/paper/9fec5868542b4d9070306f1418d1d21666226e90">66: Evaluating NLP Models via Contrast Sets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.585408</td>
<td>0.994444</td>
<td><a href="https://www.semanticscholar.org/paper/776a49616c84d52e8fff9911c561e3bac90910eb">42: Out of Order: How important is the sequential order of words in a sentence in Natural Language Understanding tasks?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.670354</td>
<td>0.993839</td>
<td><a href="https://www.semanticscholar.org/paper/77a096d80eb4dd4ccd103d1660c5a5498f7d026b">65: Dynabench: Rethinking Benchmarking in NLP</a></td>
</tr>
<tr>
<td>0</td>
<td>0.687878</td>
<td>0.993620</td>
<td><a href="https://www.semanticscholar.org/paper/fc09d6486be1c9bbfbef4165ce3c1ab664e5d084">171: PAWS: Paraphrase Adversaries from Word Scrambling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.438955</td>
<td>0.993518</td>
<td><a href="https://www.semanticscholar.org/paper/6260e0e330d4f913d8c4dda7aa42043c05b07a6d">53: Utility is in the Eye of the User: A Critique of NLP Leaderboards</a></td>
</tr>
<tr>
<td>0</td>
<td>0.628572</td>
<td>0.993462</td>
<td><a href="https://www.semanticscholar.org/paper/e0c66240239263f16159eef166a391d3939ae2d5">164: How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.667421</td>
<td>0.993448</td>
<td><a href="https://www.semanticscholar.org/paper/4311eefc03a3f391bae39ebf364cbd5f8b90a001">7: Beyond Leaderboards: A survey of methods for revealing weaknesses in Natural Language Inference data and models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.633272</td>
<td>0.992915</td>
<td><a href="https://www.semanticscholar.org/paper/82a44fbe798d514c81439c90c655975a32c2af10">28: The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions</a></td>
</tr>
</table></html>
