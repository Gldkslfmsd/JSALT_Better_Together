<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/02eaaf87f9cae34cca398fed146079e6eeb1f868">247: Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.802396</td>
<td>0.928177</td>
<td><a href="https://www.semanticscholar.org/paper/401a19f6a5d7dfae9ffdb7760bcc098a965223e3">1: LMMS Reloaded: Transformer-based Sense Embeddings for Disambiguation and Beyond</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801144</td>
<td>0.719909</td>
<td><a href="https://www.semanticscholar.org/paper/6b7bb9f69e2de6156b262082c59677da280ddd24">1: Dual Inference for Improving Language Understanding and Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798557</td>
<td>0.735989</td>
<td><a href="https://www.semanticscholar.org/paper/ff20f3c7a838424b37607c80982d2d617e1f9b91">26: Marrying Up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798139</td>
<td>0.774581</td>
<td><a href="https://www.semanticscholar.org/paper/b91ec4aab099dcbc643cd2a10a3c0681b11add7c">62: High-risk learning: acquiring new word vectors from tiny data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798103</td>
<td>0.957463</td>
<td><a href="https://www.semanticscholar.org/paper/81d89880586ff87b3ac8a14588b4e3f55c110ff8">16: Several Experiments on Investigating Pretraining and Knowledge-Enhanced Models for Natural Language Inference</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785712</td>
<td>0.238972</td>
<td><a href="https://www.semanticscholar.org/paper/19907ff7d53c2b8adfa4d17bf39681ebc38c9501">2: On Deep Computational Formalization of Natural Language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784213</td>
<td>0.962853</td>
<td><a href="https://www.semanticscholar.org/paper/fb51dc284e42927d018858fcc6618d16cbdfc042">3: Embracing Ambiguity: Shifting the Training Target of NLI Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781227</td>
<td>0.453971</td>
<td><a href="https://www.semanticscholar.org/paper/f11ec79b0f34b7bd8e9c6799d2a4525343c4ae2c">2: Keeping Apace with Progress in Natural Language Processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.780223</td>
<td>0.973145</td>
<td><a href="https://www.semanticscholar.org/paper/f9b91c369f4cae2486c23cd052ad7495a5ad2983">16: A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP</a></td>
</tr>
<tr>
<td>0</td>
<td>0.632035</td>
<td>0.990219</td>
<td><a href="https://www.semanticscholar.org/paper/128cb6b891aee1b5df099acb48e2efecfcff689f">683: The Winograd Schema Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737700</td>
<td>0.989162</td>
<td><a href="https://www.semanticscholar.org/paper/cc02386375b1262c3a1d5525154eaea24c761d15">56: Do Neural Language Representations Learn Physical Commonsense?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758727</td>
<td>0.987961</td>
<td><a href="https://www.semanticscholar.org/paper/d0cda85c030711aaa5383c80d5928a4d22f8d3bf">93: How Can We Accelerate Progress Towards Human-like Linguistic Generalization?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.607495</td>
<td>0.987723</td>
<td><a href="https://www.semanticscholar.org/paper/fb0b11046474b8f1c810f947f313c7c7229a988f">273: SemEval-2012 Task 7: Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.686191</td>
<td>0.987167</td>
<td><a href="https://www.semanticscholar.org/paper/a67955df15688a908190e57420df5cea9278cdcb">36: Evaluating BERT for natural language inference: A case study on the CommitmentBank</a></td>
</tr>
<tr>
<td>0</td>
<td>0.725510</td>
<td>0.987029</td>
<td><a href="https://www.semanticscholar.org/paper/7096304d19457833972daec4d3f5107befe30b1c">17: Do Neural Language Models Overcome Reporting Bias?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.680238</td>
<td>0.986943</td>
<td><a href="https://www.semanticscholar.org/paper/45f952c21130d655090058e864c2772358a1de72">33: Commonsense Reasoning for Natural Language Processing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.601480</td>
<td>0.986941</td>
<td><a href="https://www.semanticscholar.org/paper/ba40d5fa06a0b14aa50c681c0a38746e348a4491">8: “I’m Not Mad”: Commonsense Implications of Negation and Contradiction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.675634</td>
<td>0.986619</td>
<td><a href="https://www.semanticscholar.org/paper/774319233a107a29622003a115aa6c79f4a7b37f">21: Probing Neural Language Models for Human Tacit Assumptions</a></td>
</tr>
</table></html>
