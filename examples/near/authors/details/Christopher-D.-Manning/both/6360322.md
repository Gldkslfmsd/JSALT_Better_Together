<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/b1e20420982a4f923c08652941666b189b11b7fe">491: A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807559</td>
<td>0.691542</td>
<td><a href="https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57">13: Visual question answering: a state-of-the-art review</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804894</td>
<td>0.935599</td>
<td><a href="https://www.semanticscholar.org/paper/f010affab57b5fcf1cd6be23df79d8ec98c7289c">867: TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788907</td>
<td>0.930326</td>
<td><a href="https://www.semanticscholar.org/paper/654948d57fe8f257bdb7ab39548f141bae30776a">15: Prerequisite Skills for Reading Comprehension: Multi-Perspective Analysis of MCTest Datasets and Systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788116</td>
<td>0.676529</td>
<td><a href="https://www.semanticscholar.org/paper/3d268a342b23d22fc84a2eeb806b072b6f3d22b5">0: Machine Reading Comprehension (LSTM) Review (State of Art)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786531</td>
<td>0.305909</td>
<td><a href="https://www.semanticscholar.org/paper/17e7ad56c7c73e370365943ffba1abce5832eea0">3: Evaluating Surprise Adequacy for Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785677</td>
<td>0.963780</td>
<td><a href="https://www.semanticscholar.org/paper/6b4610d1ff3a69650b3b8311bfa378396c6725a1">0: Towards Robust Neural Machine Reading Comprehension via Question Paraphrases</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774297</td>
<td>0.927664</td>
<td><a href="https://www.semanticscholar.org/paper/aa420082c996788ca1d36e0b8b47321dc316e19a">0: IID SQuAD track: Comparing QANet with BiDAF</a></td>
</tr>
<tr>
<td>0</td>
<td>0.773535</td>
<td>0.900344</td>
<td><a href="https://www.semanticscholar.org/paper/d0cda85c030711aaa5383c80d5928a4d22f8d3bf">93: How Can We Accelerate Progress Towards Human-like Linguistic Generalization?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.773205</td>
<td>0.593984</td>
<td><a href="https://www.semanticscholar.org/paper/c2777a8ca7447764e51a4b2498a7a6157f76da37">0: Multimodal Attention for Visual Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723392</td>
<td>0.998035</td>
<td><a href="https://www.semanticscholar.org/paper/35b91b365ceb016fb3e022577cec96fb9b445dc5">530: The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.757661</td>
<td>0.997994</td>
<td><a href="https://www.semanticscholar.org/paper/b798cfd967e1a9ca5e7bc995d33a907bf65d1c7f">572: Gated Self-Matching Networks for Reading Comprehension and Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.717384</td>
<td>0.997035</td>
<td><a href="https://www.semanticscholar.org/paper/ecc8aa0e1ac0b3133adfb2aec4945f7f15dd766e">27: Learning to Transform, Combine, and Reason in Open-Domain Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759753</td>
<td>0.996677</td>
<td><a href="https://www.semanticscholar.org/paper/e4600ece1f09236d082eca4537ee9c1efe687f6c">73: FastQA: A Simple and Efficient Neural Architecture for Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784583</td>
<td>0.996151</td>
<td><a href="https://www.semanticscholar.org/paper/256183171d30f86dae9f1ac9eb94e9aa7a6d599a">18: R-Trans: RNN Transformer Network for Chinese Machine Reading Comprehension</a></td>
</tr>
<tr>
<td>0</td>
<td>0.815006</td>
<td>0.995769</td>
<td><a href="https://www.semanticscholar.org/paper/ff1861b71eaedba46cb679bbe2c585dbe18f9b19">538: Machine Comprehension Using Match-LSTM and Answer Pointer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792550</td>
<td>0.995607</td>
<td><a href="https://www.semanticscholar.org/paper/b42e784ee14709828d9f1028f4147fb904d0be7c">9: MemoReader: Large-Scale Reading Comprehension through Neural Memory Controller</a></td>
</tr>
<tr>
<td>0</td>
<td>0.826563</td>
<td>0.995467</td>
<td><a href="https://www.semanticscholar.org/paper/97e6ed1f7e5de0034f71c370c01f59c87aaf9a72">138: Learning Recurrent Span Representations for Extractive Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.733899</td>
<td>0.995420</td>
<td><a href="https://www.semanticscholar.org/paper/6eec608f266de95eb817e9a6086641abc3c91e5f">57: Embracing data abundance: BookTest Dataset for Reading Comprehension</a></td>
</tr>
</table></html>
