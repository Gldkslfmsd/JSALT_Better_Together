<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/2b669398c4cf2ebe04375c8b1beae20f4ac802fa">1180: Improving Word Representations via Global Context and Multiple Word Prototypes</a></td>
</tr>
<tr>
<td>0</td>
<td>0.878749</td>
<td>0.983546</td>
<td><a href="https://www.semanticscholar.org/paper/46ccf2c7583ec0e50b1d8570e7ddd6c779221982">3: Enhanced word embedding with multiple prototypes</a></td>
</tr>
<tr>
<td>0</td>
<td>0.866481</td>
<td>0.990311</td>
<td><a href="https://www.semanticscholar.org/paper/fd08f5dc09cbe4d8e1c05b7afd0053952710d27e">35: Improving Distributed Representation of Word Sense via WordNet Gloss Composition and Context Clustering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.861139</td>
<td>0.954425</td>
<td><a href="https://www.semanticscholar.org/paper/18bba8ef95f1acd36963e325e39f9eb6b4b84729">0: Multi-Context Information for Word Representation Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.860959</td>
<td>0.978931</td>
<td><a href="https://www.semanticscholar.org/paper/4adc77c7a638af30470b096f04b367868ea6caba">13: Improving Word Representations with Document Labels</a></td>
</tr>
<tr>
<td>0</td>
<td>0.859185</td>
<td>0.790760</td>
<td><a href="https://www.semanticscholar.org/paper/50d9abffc1864889eb5d4da0154edf1e20b24b44">7: Refining Word Representations by Manifold Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.857207</td>
<td>0.926986</td>
<td><a href="https://www.semanticscholar.org/paper/f7439f97c6da2800cb75383f783f6744496f7751">0: Combining Local and Global Features in Supervised Word Sense Disambiguation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.853936</td>
<td>0.959576</td>
<td><a href="https://www.semanticscholar.org/paper/43c1cf3048a4334fe925e0b9532880c7a0eed640">0: Embedding for Out of Vocabulary Words Considering Contextual and Morphosyntactic Information</a></td>
</tr>
<tr>
<td>0</td>
<td>0.851424</td>
<td>0.983926</td>
<td><a href="https://www.semanticscholar.org/paper/42cf161894f4b9ebb86a9109dc2af45d9eee8916">115: Integrating and Evaluating Neural Word Embeddings in Information Retrieval</a></td>
</tr>
<tr>
<td>0</td>
<td>0.844832</td>
<td>0.924617</td>
<td><a href="https://www.semanticscholar.org/paper/691309a438474ecc8a6a27bbcb6de767d0b21912">7: Learning Word Sense Embeddings from Word Sense Definitions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.584045</td>
<td>0.997214</td>
<td><a href="https://www.semanticscholar.org/paper/1a99d1e2e92ee1abb810bee2aa72dda9a1b413e4">141: A Probabilistic Model for Learning Multi-Prototype Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.798117</td>
<td>0.996070</td>
<td><a href="https://www.semanticscholar.org/paper/e89f679710507e239775a1e9c81988c3f928cbed">239: Word Embeddings through Hellinger PCA</a></td>
</tr>
<tr>
<td>0</td>
<td>0.800110</td>
<td>0.995459</td>
<td><a href="https://www.semanticscholar.org/paper/75669c9df94f992985ac3318a744c4f3feb132ef">214: Do Multi-Sense Embeddings Improve Natural Language Understanding?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.828831</td>
<td>0.995215</td>
<td><a href="https://www.semanticscholar.org/paper/f9f91e7bac46b13444eddeb2438b01089e73b786">295: Tailoring Continuous Word Representations for Dependency Parsing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793959</td>
<td>0.995193</td>
<td><a href="https://www.semanticscholar.org/paper/d02e7eba6e765f38bc6be1f71e7fe9bbd11ace9d">314: A Unified Model for Word Sense Representation and Disambiguation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.733246</td>
<td>0.995189</td>
<td><a href="https://www.semanticscholar.org/paper/a5991db236c230b6e1dca0ddb8944cd478c20fa5">85: The Expressive Power of Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738017</td>
<td>0.995173</td>
<td><a href="https://www.semanticscholar.org/paper/613b3ca2628e5d9f0cc792789b0109fee107d46a">111: Community Evaluation and Exchange of Word Vectors at wordvectors.org</a></td>
</tr>
<tr>
<td>0</td>
<td>0.860527</td>
<td>0.995158</td>
<td><a href="https://www.semanticscholar.org/paper/d483f9a0e0bc23477311341fb8f72462c0d97c33">50: Rehabilitation of Count-Based Models for Word Vector Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.788512</td>
<td>0.995157</td>
<td><a href="https://www.semanticscholar.org/paper/c8dfdb6bc17094fc1c35757a0020dea8d813b7b6">288: Improving Lexical Embeddings with Semantic Knowledge</a></td>
</tr>
</table></html>
