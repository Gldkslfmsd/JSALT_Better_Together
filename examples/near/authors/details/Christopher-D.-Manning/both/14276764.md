<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/53ab89807caead278d3deb7b6a4180b277d3cb77">792: Better Word Representations with Recursive Neural Networks for Morphology</a></td>
</tr>
<tr>
<td>0</td>
<td>0.832062</td>
<td>0.956577</td>
<td><a href="https://www.semanticscholar.org/paper/95845fa4046f75df4fc83290ea4431d4a5730f28">0: Robust Representation Learning for Low Resource Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.828680</td>
<td>0.990453</td>
<td><a href="https://www.semanticscholar.org/paper/0bb3a0d139e47608ec567fad150029c985c81868">71: Dict2vec : Learning Word Embeddings using Lexical Dictionaries</a></td>
</tr>
<tr>
<td>0</td>
<td>0.824754</td>
<td>0.838185</td>
<td><a href="https://www.semanticscholar.org/paper/50d9abffc1864889eb5d4da0154edf1e20b24b44">7: Refining Word Representations by Manifold Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.817730</td>
<td>0.151870</td>
<td><a href="https://www.semanticscholar.org/paper/82bf75d885105030839ca0d76fe41127d7eeb564">0: Modelling Maltese noun plural classes without morphemes</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816860</td>
<td>0.933186</td>
<td><a href="https://www.semanticscholar.org/paper/5483cf4d1c4ade2b55943a3a22a20cf8c3df6141">2: Word2Vec using Character n-grams</a></td>
</tr>
<tr>
<td>0</td>
<td>0.816049</td>
<td>0.851403</td>
<td><a href="https://www.semanticscholar.org/paper/b38923ae6b9f9ce1e761fba820401788de62c1c8">4: Development and Evaluation of Word Embeddings for Morphologically Rich Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813003</td>
<td>0.362607</td>
<td><a href="https://www.semanticscholar.org/paper/9f7adce3694cc4a0b073ea519f8f96ed31518d49">1: Associative memory neural networks for information retrieval of text word pairs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.811672</td>
<td>0.801217</td>
<td><a href="https://www.semanticscholar.org/paper/1e50e1973b466c0b26d7d8a70b4caefdc5342faa">3: Fast Oov Words Incorporation Using Structured Word Embeddings for Neural Network Language Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810310</td>
<td>0.518251</td>
<td><a href="https://www.semanticscholar.org/paper/55f3c22d2ed195b686495e031f9a9b337785d591">8: Word vectorization using relations among words for neural network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723982</td>
<td>0.996914</td>
<td><a href="https://www.semanticscholar.org/paper/135c89b491f82bd4fd7de175ac778207f598342b">48: Not All Neural Embeddings are Born Equal</a></td>
</tr>
<tr>
<td>0</td>
<td>0.716686</td>
<td>0.996435</td>
<td><a href="https://www.semanticscholar.org/paper/1d1db6344bdd023a7508135476cbddec12071d12">35: Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics</a></td>
</tr>
<tr>
<td>0</td>
<td>0.628352</td>
<td>0.996015</td>
<td><a href="https://www.semanticscholar.org/paper/89f1aaeffca0f3a8b09692e12fa5b58c12d5d41d">20: Efficient, Compositional, Order-sensitive n-gram Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674523</td>
<td>0.995634</td>
<td><a href="https://www.semanticscholar.org/paper/43eaf3250f3506a804a4f6d055ace19effb485fa">12: Analysis of Italian Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.714633</td>
<td>0.994890</td>
<td><a href="https://www.semanticscholar.org/paper/cf9830bf8d2babc3c32d192cdccb27aeaf46a048">106: The Role of Context Types and Dimensionality in Learning Word Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.779012</td>
<td>0.994137</td>
<td><a href="https://www.semanticscholar.org/paper/8e3f0f7a761f18cb91c11764d8d6cb3b1e9c5731">426: Polyglot: Distributed Word Representations for Multilingual NLP</a></td>
</tr>
<tr>
<td>0</td>
<td>0.720865</td>
<td>0.994111</td>
<td><a href="https://www.semanticscholar.org/paper/cabfb5c0503c24d812838fb52c9a7c04b44e04e7">21: Learning Word Meta-Embeddings by Using Ensembles of Embedding Sets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793111</td>
<td>0.994010</td>
<td><a href="https://www.semanticscholar.org/paper/343d39534682bb7b2eec14f573360877eb80cd59">94: Word Embedding Evaluation and Combination</a></td>
</tr>
<tr>
<td>0</td>
<td>0.709768</td>
<td>0.993607</td>
<td><a href="https://www.semanticscholar.org/paper/c7cf38bc337760dee4fc6766060178a5c1904127">26: Learning Meta-Embeddings by Using Ensembles of Embedding Sets</a></td>
</tr>
</table></html>
