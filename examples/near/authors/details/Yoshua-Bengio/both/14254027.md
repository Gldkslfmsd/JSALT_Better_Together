<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/e221e2c2ca8bd74a7b818406c8a2a342760e7d65">426: SampleRNN: An Unconditional End-to-End Neural Audio Generation Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.757591</td>
<td>-0.003106</td>
<td><a href="https://www.semanticscholar.org/paper/6ab77186ea9d13eeae25d76e969a49fa32011908">0: Lecture 20 : Reversible and Autoregressive Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.754375</td>
<td>0.486655</td>
<td><a href="https://www.semanticscholar.org/paper/7e05eb04d83b07014e7b2018666358ff5b9432a7">36: Compression of End-to-End Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.749244</td>
<td>0.453299</td>
<td><a href="https://www.semanticscholar.org/paper/d1275b2a2ab53013310e759e5c6878b96df643d4">547: Context dependent recurrent neural network language model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748756</td>
<td>0.558153</td>
<td><a href="https://www.semanticscholar.org/paper/1cfcdf0cec5636066a4c2aa60b4451462ed49fca">172: Exploring neural transducers for end-to-end speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748268</td>
<td>0.560886</td>
<td><a href="https://www.semanticscholar.org/paper/6aed9eedd5cb712c3d902152cb94f2f18ba4c729">7: Unidirectional Neural Network Architectures for End-to-End Automatic Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.744209</td>
<td>0.482931</td>
<td><a href="https://www.semanticscholar.org/paper/ab1e3e6385dbd316917f70311eb3101cbfe6cb99">23: Listen Attentively, and Spell Once: Whole Sentence Generation via a Non-Autoregressive Architecture for Low-Latency Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738695</td>
<td>0.971539</td>
<td><a href="https://www.semanticscholar.org/paper/fd39d24f06164411c3f010305c3243c12c4a25a2">1: MTCRNN: A multi-scale RNN for directed audio texture synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.730289</td>
<td>0.654242</td>
<td><a href="https://www.semanticscholar.org/paper/0059454469b6a983deb94306ba33ca5ee83f82b7">0: Exploring single-song autoencoding schemes for audio-based music structure analysis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.728508</td>
<td>0.502360</td>
<td><a href="https://www.semanticscholar.org/paper/e7bd0e7a7ee6b0904d5de6e76e095a6a3b88dd12">1: T REE-STRUCTURED DECODING WITH DOUBLY-RECURRENT NEURAL NETWORKS</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767410</td>
<td>0.986963</td>
<td><a href="https://www.semanticscholar.org/paper/889aa0021991008ae01aaadd9d3b51c5a26dd1a2">31: SING: Symbol-to-Instrument Neural Generator</a></td>
</tr>
<tr>
<td>0</td>
<td>0.741345</td>
<td>0.986249</td>
<td><a href="https://www.semanticscholar.org/paper/d198754b61b3d87b015b382d6cc9204a270eb6cb">88: Fftnet: A Real-Time Speaker-Dependent Neural Vocoder</a></td>
</tr>
<tr>
<td>0</td>
<td>0.616018</td>
<td>0.983530</td>
<td><a href="https://www.semanticscholar.org/paper/487aa8076bf3c0edb4134759e1ddf09d64f21476">231: Speaker-Dependent WaveNet Vocoder</a></td>
</tr>
<tr>
<td>0</td>
<td>0.523749</td>
<td>0.983436</td>
<td><a href="https://www.semanticscholar.org/paper/df9aa3438af7a0938cf1829f4c2f20b3f9bd05f5">58: Fast Wavenet Generation Algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.729593</td>
<td>0.982574</td>
<td><a href="https://www.semanticscholar.org/paper/b9357ef8753b07253b144617e0ef798569192bed">31: STCN: Stochastic Temporal Convolutional Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727109</td>
<td>0.982343</td>
<td><a href="https://www.semanticscholar.org/paper/1b6dc40dfd98adaec532a23819594dbded4cb654">61: Neural Source-Filter Waveform Models for Statistical Parametric Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.631358</td>
<td>0.982310</td>
<td><a href="https://www.semanticscholar.org/paper/e1ca65f8b5e6e1b48dfb019682aac91a479411c5">108: WaveNet Vocoder with Limited Training Data for Voice Conversion</a></td>
</tr>
<tr>
<td>0</td>
<td>0.610782</td>
<td>0.981092</td>
<td><a href="https://www.semanticscholar.org/paper/d756007348b6d70f9e0cf45cdbb77a0112e50473">1: CycleDRUMS: Automatic Drum Arrangement For Bass Lines Using CycleGAN</a></td>
</tr>
<tr>
<td>0</td>
<td>0.720281</td>
<td>0.981001</td>
<td><a href="https://www.semanticscholar.org/paper/d9210563b5b6ce3186f05e5f68fe72f87cd8841f">18: Voice Conversion with Cyclic Recurrent Neural Network and Fine-tuned Wavenet Vocoder</a></td>
</tr>
</table></html>
