<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/7b28577ed96bd1b76bbe79859b3222604b2dc369">40: Semi-Autoregressive Training Improves Mask-Predict Decoding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.684588</td>
<td>0.389130</td>
<td><a href="https://www.semanticscholar.org/paper/b4fc91e543ec868658cde6170f1e59c33292e595">146: Recurrent Neural Network Based Language Modeling in Meeting Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.675593</td>
<td>0.540313</td>
<td><a href="https://www.semanticscholar.org/paper/2b346c9c246f8ad8ec9a3133978639682ca59d18">1: Neural network joint modeling via context-dependent projection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.673948</td>
<td>0.105006</td>
<td><a href="https://www.semanticscholar.org/paper/b7dbfbe1c0effb1fa65ee55d20c05e7304aa65d8">0: Non-linear Adaptive Prediction of Speech with a Pipelined Recurrent Neural Network and a Linearised Recursive Least Squares Algorithm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.669069</td>
<td>-0.047519</td>
<td><a href="https://www.semanticscholar.org/paper/5634738155c416bb88e47bc802d606c1f41e945c">2: A neural model of centered tri-gram speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.668261</td>
<td>-0.009571</td>
<td><a href="https://www.semanticscholar.org/paper/c35e66a2d78acd8f9e7126a2081696ac8c63cdbf">10: Kernel density-based acoustic model with cross-lingual bottleneck features for resource limited LVCSR</a></td>
</tr>
<tr>
<td>0</td>
<td>0.664621</td>
<td>-0.220228</td>
<td><a href="https://www.semanticscholar.org/paper/dc73b1c25a0652f9793f6b06bd777a9bb100b24f">1: A Specific and Selective Neural Response Representation With Decorrelating Auto-Encoder</a></td>
</tr>
<tr>
<td>0</td>
<td>0.659545</td>
<td>0.562206</td>
<td><a href="https://www.semanticscholar.org/paper/8cfbaed6f1edecd51226f5a9e3c4645588e24746">5: Exploiting semi-supervised training through a dropout regularization in end-to-end speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.657121</td>
<td>-0.027310</td>
<td><a href="https://www.semanticscholar.org/paper/945d405c5735b3e7b70d4d073626b9dbda431daf">12: Optimizing deep bottleneck feature extraction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.656813</td>
<td>0.257079</td>
<td><a href="https://www.semanticscholar.org/paper/ce72e9e72b8a2bc36cec0bb84424d2e57d5e12cc">81: A Hierarchical Pitman-Yor Process HMM for Unsupervised Part of Speech Induction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.734508</td>
<td>0.998295</td>
<td><a href="https://www.semanticscholar.org/paper/3db8de1e088e1837146c4f2f3c9d13a6c40434da">10: Non-Autoregressive Translation with Layer-Wise Prediction and Deep Supervision</a></td>
</tr>
<tr>
<td>0</td>
<td>0.679952</td>
<td>0.998128</td>
<td><a href="https://www.semanticscholar.org/paper/e2f679183c504d06767223955a578480ecfe808d">21: Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.686907</td>
<td>0.998069</td>
<td><a href="https://www.semanticscholar.org/paper/30c1a88ba3573957e4c5ca04132390c71f66d4b0">59: Non-Autoregressive Machine Translation with Latent Alignments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.727138</td>
<td>0.998033</td>
<td><a href="https://www.semanticscholar.org/paper/94c30d3c03beace3ba0d7014e0b1852bb892133c">42: Non-autoregressive Machine Translation with Disentangled Context Transformer</a></td>
</tr>
<tr>
<td>0</td>
<td>0.733926</td>
<td>0.997874</td>
<td><a href="https://www.semanticscholar.org/paper/1784fa1b5ac0b9f9fefe5e0508f91033f5952177">32: Fully Non-autoregressive Neural Machine Translation: Tricks of the Trade</a></td>
</tr>
<tr>
<td>0</td>
<td>0.627879</td>
<td>0.997164</td>
<td><a href="https://www.semanticscholar.org/paper/1967b9127084aa696f32e20f42f0f8d7be583be5">0: I MPROVING N ON -A UTOREGRESSIVE T RANSLATION M ODELS W ITHOUT D ISTILLATION</a></td>
</tr>
<tr>
<td>0</td>
<td>0.771757</td>
<td>0.996859</td>
<td><a href="https://www.semanticscholar.org/paper/3f11a2124af139af7c6f17eccab5149d759d7f52">51: Aligned Cross Entropy for Non-Autoregressive Machine Translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.618717</td>
<td>0.996684</td>
<td><a href="https://www.semanticscholar.org/paper/34547845de514f43345e809c1b0a329e3fad5a5a">17: Tencent Neural Machine Translation Systems for the WMT20 News Translation Task</a></td>
</tr>
<tr>
<td>0</td>
<td>0.571230</td>
<td>0.996611</td>
<td><a href="https://www.semanticscholar.org/paper/87400e61bb66cadf7e8878ce37df88cfe31c718e">15: WeChat Neural Machine Translation Systems for WMT20</a></td>
</tr>
</table></html>
