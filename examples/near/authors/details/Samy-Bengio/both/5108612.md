<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/ccf415df5a83b343dae261286d29a40e8b80e6c6">394: The Difficulty of Training Deep Architectures and the Effect of Unsupervised Pre-Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809894</td>
<td>0.265446</td>
<td><a href="https://www.semanticscholar.org/paper/489666f4c11787b679b36238dee95b63248ed60a">6: Training Larger Networks for Deep Reinforcement Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.796119</td>
<td>0.913457</td>
<td><a href="https://www.semanticscholar.org/paper/c55421b36494ef514ed3e0a462947d70c633ed20">1: Layer-wise training of deep generative models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795109</td>
<td>0.208193</td>
<td><a href="https://www.semanticscholar.org/paper/da47685ad651f764bf749e4ff38bd88b22b3d1fa">2: Pre-training as Batch Meta Reinforcement Learning with tiMe</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790471</td>
<td>0.671672</td>
<td><a href="https://www.semanticscholar.org/paper/4873c78f0cd5a1fad96300e49e196af75800a24e">115: Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790399</td>
<td>0.571420</td>
<td><a href="https://www.semanticscholar.org/paper/e0a7aa88bae1b6e7d0a149e5dc4e509b9a93c180">1: A Novel Set Of Weight Initialization Techniques For Deep Learning Architectures</a></td>
</tr>
<tr>
<td>0</td>
<td>0.775621</td>
<td>0.935699</td>
<td><a href="https://www.semanticscholar.org/paper/8046dacd9fd80a97607ca91f9a001ea284e86716">4: Learning Deep Autoencoders without Layer-wise Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774653</td>
<td>0.291663</td>
<td><a href="https://www.semanticscholar.org/paper/4c266aa3de043213357944c8b973447abc4cb615">9: Scalable and Practical Natural Gradient for Large-Scale Deep Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774316</td>
<td>0.413101</td>
<td><a href="https://www.semanticscholar.org/paper/c6ae465b5448bd0012462c3c9aeaab8f0a8c5d14">0: Explaining Deep Learning Representations by Tracing the Training Process</a></td>
</tr>
<tr>
<td>0</td>
<td>0.773764</td>
<td>-0.003130</td>
<td><a href="https://www.semanticscholar.org/paper/a60ba96a94ed1a5ff6872f54134b25d36fb924c6">0: Knowledge Distillation as Efficient Pre-training: Faster Convergence, Higher Data-efficiency, and Better Transferability</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.994507</td>
<td><a href="https://www.semanticscholar.org/paper/97474c55c834584b71f006557aed70e09eb6eb47">634: Why Does Unsupervised Pre-training Help Deep Learning?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.739051</td>
<td>0.992980</td>
<td><a href="https://www.semanticscholar.org/paper/90a99fb11720ad5977f9195c8edbb217744b0f67">229: On the Expressive Power of Deep Architectures</a></td>
</tr>
<tr>
<td>0</td>
<td>0.892352</td>
<td>0.989262</td>
<td><a href="https://www.semanticscholar.org/paper/0d2336389dff3031910bd21dd1c44d1b4cd51725">1672: Why Does Unsupervised Pre-training Help Deep Learning?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.750135</td>
<td>0.988919</td>
<td><a href="https://www.semanticscholar.org/paper/72d32c986b47d6b880dad0c3f155fe23d2939038">532: Deep Learning of Representations: Looking Forward</a></td>
</tr>
<tr>
<td>0</td>
<td>0.814968</td>
<td>0.988747</td>
<td><a href="https://www.semanticscholar.org/paper/355d44f53428b1ac4fb2ab468d593c720640e5bd">3375: Greedy Layer-Wise Training of Deep Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809330</td>
<td>0.987726</td>
<td><a href="https://www.semanticscholar.org/paper/43c8a545f7166659e9e21c88fe234e0323855216">1242: Greedy Layer-Wise Training of Deep Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>-1.000000</td>
<td>0.987104</td>
<td><a href="https://www.semanticscholar.org/paper/594ac17a44a9fbd93722bae196e9e1bbabaabe90">3: A new deep auto-encoder using multiscale reconstruction errors and weight update correlation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732103</td>
<td>0.986439</td>
<td><a href="https://www.semanticscholar.org/paper/6fdb77260fc83dff91c44fea0f31a2cb8ed13d04">1107: Scaling learning algorithms towards AI</a></td>
</tr>
<tr>
<td>0</td>
<td>0.782854</td>
<td>0.983756</td>
<td><a href="https://www.semanticscholar.org/paper/e60ff004dde5c13ec53087872cfcdd12e85beb57">7523: Learning Deep Architectures for AI</a></td>
</tr>
</table></html>
