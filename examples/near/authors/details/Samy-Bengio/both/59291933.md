<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/e1715a0f3ba06e34f0745ce114ce0f375648639d">220: Unsupervised Speech Representation Learning Using WaveNet Autoencoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.867857</td>
<td>0.943967</td>
<td><a href="https://www.semanticscholar.org/paper/74fe88e3e48e216da60f77039e0962a9f1a135e9">7: Unsupervised Acoustic Unit Representation Learning for Voice Conversion using WaveNet Auto-encoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831813</td>
<td>0.326087</td>
<td><a href="https://www.semanticscholar.org/paper/af8aa646a1e76f2de5aaaf4c1e9e6add9c492ec5">10: Word-level invariant representations from acoustic waveforms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821653</td>
<td>0.917125</td>
<td><a href="https://www.semanticscholar.org/paper/6b999320967b0be84fbfc5038e7e6b4c4f6932f3">43: Deep Encoder-Decoder Models for Unsupervised Learning of Controllable Speech Synthesis</a></td>
</tr>
<tr>
<td>0</td>
<td>0.818533</td>
<td>0.888729</td>
<td><a href="https://www.semanticscholar.org/paper/e718e557755498f5ae005d89070b6cc484b78a69">0: The Multilayer Perceptron Vector Quantized Variational AutoEncoder for Spectral Envelope Quantization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.812140</td>
<td>0.810461</td>
<td><a href="https://www.semanticscholar.org/paper/f6e43c20b3628a0673477476fc8db391fa189dbf">11: A Deep Generative Model of Speech Complex Spectrograms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.808877</td>
<td>0.403486</td>
<td><a href="https://www.semanticscholar.org/paper/b95799a25def71b100bd12e7ebb32cbcee6590bf">176: Energy-Based Models for Sparse Overcomplete Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.807808</td>
<td>0.871343</td>
<td><a href="https://www.semanticscholar.org/paper/b5f972554ed661c8b73ed140cc68e77bf06dce65">10: Problem-Agnostic Speech Embeddings for Multi-Speaker Text-to-Speech with SampleRNN</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795113</td>
<td>0.594973</td>
<td><a href="https://www.semanticscholar.org/paper/9fafcaea364bf2597b1ab18b86b4b685620642be">0: A joint restricted Boltzmann machine for dictionary learning in sparse-representation-based voice conversion</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793178</td>
<td>0.441025</td>
<td><a href="https://www.semanticscholar.org/paper/b16b2a54ae47e73db70c5dabe4487cafb89d33f1">32: Integrating articulatory data in deep neural network-based acoustic modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.824345</td>
<td>0.973409</td>
<td><a href="https://www.semanticscholar.org/paper/8863b202aaeadd198f8cc014aceb85d1638e9557">61: Vector-quantized neural networks for acoustic unit discovery in the ZeroSpeech 2020 challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768027</td>
<td>0.968602</td>
<td><a href="https://www.semanticscholar.org/paper/50970f392a76ced3054703a21d581377f1cc1086">46: VQVAE Unsupervised Unit Discovery and Multi-scale Code2Spec Inverter for Zerospeech Challenge 2019</a></td>
</tr>
<tr>
<td>0</td>
<td>0.695213</td>
<td>0.965519</td>
<td><a href="https://www.semanticscholar.org/paper/fd80c74299a0ba9ea6b582e1ad8397e5e2db82ed">90: The Zero Resource Speech Challenge 2019: TTS without T</a></td>
</tr>
<tr>
<td>0</td>
<td>0.783863</td>
<td>0.964366</td>
<td><a href="https://www.semanticscholar.org/paper/0b41d8989d6c5b24557dbeec2f00ac44446f9e16">2: Disentangled Speech Representation Learning Based on Factorized Hierarchical Variational Autoencoder with Self-Supervised Objective</a></td>
</tr>
<tr>
<td>0</td>
<td>0.836185</td>
<td>0.963327</td>
<td><a href="https://www.semanticscholar.org/paper/2130cb5ddde3efe79ace0246203c4e81ad495809">48: Unsupervised acoustic unit discovery for speech synthesis using discrete latent-variable neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.850151</td>
<td>0.963249</td>
<td><a href="https://www.semanticscholar.org/paper/23843c8f0064a1bfc3b6cad8046fe1ead8691837">19: A Convolutional Deep Markov Model for Unsupervised Speech Representation Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781926</td>
<td>0.963056</td>
<td><a href="https://www.semanticscholar.org/paper/031c6baabd61f5b654ef4892f8f6ed737ec52511">82: Sample Efficient Adaptive Text-to-Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748212</td>
<td>0.959872</td>
<td><a href="https://www.semanticscholar.org/paper/6f6127faf516fb4dc47a24aaab9d5e96c4fcc751">49: Theory and Experiments on Vector Quantized Autoencoders</a></td>
</tr>
<tr>
<td>0</td>
<td>0.700385</td>
<td>0.959663</td>
<td><a href="https://www.semanticscholar.org/paper/0546e471b793032e8a26e367344571576ee9a43d">0: Distribution augmentation for low-resource expressive text-to-speech</a></td>
</tr>
</table></html>
