<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0">4457: Show and tell: A neural image caption generator</a></td>
</tr>
<tr>
<td>1</td>
<td>0.935127</td>
<td>0.986099</td>
<td><a href="https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e">615: Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.875598</td>
<td>0.974128</td>
<td><a href="https://www.semanticscholar.org/paper/123b9de009865472c660192f8072493a48352dc2">96: Phrase-based Image Captioning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.859692</td>
<td>0.917518</td>
<td><a href="https://www.semanticscholar.org/paper/074eb7a6940d8629c6f26594a1f485d42aba8821">8: Simple Image Description Generator via a Linear Phrase-based Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.859287</td>
<td>-0.039993</td>
<td><a href="https://www.semanticscholar.org/paper/98d8a913a0c129f1a32d92d25e458738b51dcffd">0: Automatic Image Captioning Methods</a></td>
</tr>
<tr>
<td>0</td>
<td>0.856724</td>
<td>0.947025</td>
<td><a href="https://www.semanticscholar.org/paper/5c0c24a4b19e97ea92b716b28efd31de4cc38c4e">3: Ensemble Learning on Deep Neural Networks for Image Caption Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.855915</td>
<td>0.913463</td>
<td><a href="https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0">0: Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents</a></td>
</tr>
<tr>
<td>0</td>
<td>0.842469</td>
<td>0.930908</td>
<td><a href="https://www.semanticscholar.org/paper/981075404a933851c3fde8ee0b220e1c6ff2a2f5">0: Review of deep learning approaches for image caption generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.837706</td>
<td>0.704469</td>
<td><a href="https://www.semanticscholar.org/paper/af04aebcc5e935253590537793439487d5510ebc">2: A Picture May Be Worth a Hundred Words for Visual Question Answering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.836351</td>
<td>0.961336</td>
<td><a href="https://www.semanticscholar.org/paper/a55f5de768a455ab01fbe0432962f2f6f1a0a7db">2: On Architectures for Including Visual Information in Neural Language Models for Image Description</a></td>
</tr>
<tr>
<td>0</td>
<td>0.810225</td>
<td>0.993255</td>
<td><a href="https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745">1001: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)</a></td>
</tr>
<tr>
<td>0</td>
<td>0.815022</td>
<td>0.987296</td>
<td><a href="https://www.semanticscholar.org/paper/a5d8c57c53d896275d6fa2d1137cd152a2cd7624">36: Image Captioning at Will: A Versatile Scheme for Effectively Injecting Sentiments into Image Descriptions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.840920</td>
<td>0.985410</td>
<td><a href="https://www.semanticscholar.org/paper/48f17b2b08aebd16e711f5c7ca9e773fe6639dc3">5: Reference-based model using multimodal gated recurrent units for image captioning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.587287</td>
<td>0.985084</td>
<td><a href="https://www.semanticscholar.org/paper/53e9d718ec981850cfc6110385ac42ca2da2f612">21: Learning Cnn Lstm Architectures For Image Caption Generation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845467</td>
<td>0.985046</td>
<td><a href="https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88">2464: Deep Visual-Semantic Alignments for Generating Image Descriptions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.729924</td>
<td>0.983893</td>
<td><a href="https://www.semanticscholar.org/paper/39a20428734b1b38b8e93c1c23283f4c85ff27f4">13: A Hierarchical Multimodal Attention-based Neural Network for Image Captioning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825526</td>
<td>0.983549</td>
<td><a href="https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4">1842: Deep visual-semantic alignments for generating image descriptions</a></td>
</tr>
<tr>
<td>0</td>
<td>0.833037</td>
<td>0.983015</td>
<td><a href="https://www.semanticscholar.org/paper/6cc46899b415ebef4a70068b2cbd8a50e955aeb6">55: Where to put the image in an image caption generator</a></td>
</tr>
</table></html>
