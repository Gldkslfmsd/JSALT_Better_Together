<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/e5a95a679774e069e1e36d96f92bac6b93027118">212: Insights on representational similarity in neural networks with canonical correlation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.843762</td>
<td>-0.064466</td>
<td><a href="https://www.semanticscholar.org/paper/806f47e6e389305a6f8360a1fb294ba30ebe6771">1: Measuring representational similarity across neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.792008</td>
<td>0.922552</td>
<td><a href="https://www.semanticscholar.org/paper/3ac13e3dc212fba60835b8917e02a3179eb3465a">3: Transferred Discrepancy: Quantifying the Difference Between Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791328</td>
<td>0.666084</td>
<td><a href="https://www.semanticscholar.org/paper/140cca7cef243b431563a0b86de8c0286edb142b">9: Emergence of Separable Manifolds in Deep Language Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.773150</td>
<td>0.851941</td>
<td><a href="https://www.semanticscholar.org/paper/2a3bad4004f175519f6973f74eb0aa2c3dd2da87">17: Input Similarity from the Neural Network Perspective</a></td>
</tr>
<tr>
<td>0</td>
<td>0.766328</td>
<td>0.657177</td>
<td><a href="https://www.semanticscholar.org/paper/ad9899e2cfe260d6c12f432c45bbac58b682d10d">5: A Differential Topological View of Challenges in Learning with Feedforward Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758524</td>
<td>0.090764</td>
<td><a href="https://www.semanticscholar.org/paper/9c0328fd386e6994eaf62742e92627d4937b68d1">3: TNE: A Latent Model for Representation Learning on Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748444</td>
<td>0.131814</td>
<td><a href="https://www.semanticscholar.org/paper/f346d07136b3cdeaac85a7258c42e87b4e25651e">1: Deep Hypergraph U-Net for Brain Graph Embedding and Classification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742920</td>
<td>0.355335</td>
<td><a href="https://www.semanticscholar.org/paper/6968eba4e2959ee749f8a8a3577e330ce0fd8b80">0: Variational Beauty of Space: Machine Intuition and Non-Linear Neural Aggregations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740589</td>
<td>0.730093</td>
<td><a href="https://www.semanticscholar.org/paper/38cef3868684ebdcf0d5ecf71ebe4323abe35026">2: When Are Solutions Connected in Deep Networks?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.759232</td>
<td>0.990287</td>
<td><a href="https://www.semanticscholar.org/paper/a3f7a30abe44424e5ef8348a02cc103237ac5210">332: SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834062</td>
<td>0.979693</td>
<td><a href="https://www.semanticscholar.org/paper/726320cdbd04804ffa8f3a78c095bd1b55a2a695">347: Similarity of Neural Network Representations Revisited</a></td>
</tr>
<tr>
<td>0</td>
<td>0.619827</td>
<td>0.964778</td>
<td><a href="https://www.semanticscholar.org/paper/5e23a28063b395bdaf784dc548a046885cb90cf2">367: Understanding intermediate layers using linear classifier probes</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756786</td>
<td>0.960834</td>
<td><a href="https://www.semanticscholar.org/paper/d21806115a79c960298cfca45a49b24682cac71a">52: Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth</a></td>
</tr>
<tr>
<td>0</td>
<td>0.631246</td>
<td>0.958723</td>
<td><a href="https://www.semanticscholar.org/paper/efffb82dd9926874b7b1a93c12f6f9f7a26103a3">1: Interlocking Backpropagation: Improving depthwise model-parallelism</a></td>
</tr>
<tr>
<td>0</td>
<td>0.712062</td>
<td>0.956866</td>
<td><a href="https://www.semanticscholar.org/paper/41fe7f4b3ebf9616419101faa8c5f2ee43a118b4">5: Revisiting Model Stitching to Compare Neural Representations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.696941</td>
<td>0.953487</td>
<td><a href="https://www.semanticscholar.org/paper/a2b5d224895d96bfe2e384e2dcf1ebd136ac3782">174: An Empirical Study of Example Forgetting during Deep Neural Network Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.672814</td>
<td>0.949813</td>
<td><a href="https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19">8429: Distilling the Knowledge in a Neural Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.719375</td>
<td>0.949266</td>
<td><a href="https://www.semanticscholar.org/paper/45a7ce70b9a1c46f76a9eac22bcf7bc08e2befc9">20: Let's Agree to Agree: Neural Networks Share Classification Order on Real Datasets</a></td>
</tr>
</table></html>
