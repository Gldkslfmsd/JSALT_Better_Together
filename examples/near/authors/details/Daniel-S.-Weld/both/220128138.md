<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/1109f787fc8d51feb3bae9bf6e1945dc4a1191e7">99: Does the Whole Exceed its Parts? The Effect of AI Explanations on Complementary Team Performance</a></td>
</tr>
<tr>
<td>0</td>
<td>0.764834</td>
<td>0.949898</td>
<td><a href="https://www.semanticscholar.org/paper/5cc4100a67fd6f2ce3c760655ba7a12f358c7950">155: Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making</a></td>
</tr>
<tr>
<td>0</td>
<td>0.737435</td>
<td>0.201135</td>
<td><a href="https://www.semanticscholar.org/paper/b02a51658eedaf4b0cd26510b78538f6c640c823">0: Measuring an adaptive change in human decision-making from AI: Application to evaluate changes after AlphaGo</a></td>
</tr>
<tr>
<td>0</td>
<td>0.711506</td>
<td>0.163840</td>
<td><a href="https://www.semanticscholar.org/paper/ac8143cde04dc1f14ff8f6b365d0172d0d1f5a17">0: Threatened by AI: Analyzing Users’ Responses to the Introduction of AI in a Crowd-sourcing Platform</a></td>
</tr>
<tr>
<td>0</td>
<td>0.697571</td>
<td>0.791086</td>
<td><a href="https://www.semanticscholar.org/paper/992311aa0763bbe1d669831ab5ea7cabf6d5ef51">2: Are you sure? Prediction revision in automated decision‐making</a></td>
</tr>
<tr>
<td>0</td>
<td>0.683316</td>
<td>0.071925</td>
<td><a href="https://www.semanticscholar.org/paper/0baa0e36bdeaaabc112b247860e668e51067bbcc">0: Can the predictive processing model of the mind ameliorate the value-alignment problem?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.665439</td>
<td>0.320432</td>
<td><a href="https://www.semanticscholar.org/paper/0caced884b8e739f38387e62034a30e3f8d1f4dd">0: Point of View Explainable AI – The Need to Know ‘ Why ’</a></td>
</tr>
<tr>
<td>0</td>
<td>0.659653</td>
<td>0.404670</td>
<td><a href="https://www.semanticscholar.org/paper/64513c79cd9bba8b400d3215204dfa601b6cd861">0: Warmth and competence in human-agent cooperation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.659442</td>
<td>0.141390</td>
<td><a href="https://www.semanticscholar.org/paper/0e634890b1fffe047eef2fa8f8ea83d6d5810e4f">1: INSIGHT: Helping domain experts make their knowledge more consistent</a></td>
</tr>
<tr>
<td>0</td>
<td>0.653497</td>
<td>0.297178</td>
<td><a href="https://www.semanticscholar.org/paper/4dfb1ed11d90075efe349f527d504ed8e4d12051">6: eXtended Artificial Intelligence: New Prospects of Human-AI Interaction Research</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793531</td>
<td>0.977199</td>
<td><a href="https://www.semanticscholar.org/paper/74bcea217e5bd1d04ee0315abaf7e29a25eb418b">13: Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI Decision Making</a></td>
</tr>
<tr>
<td>0</td>
<td>0.657806</td>
<td>0.972941</td>
<td><a href="https://www.semanticscholar.org/paper/127c1cb96b73399f429de553d315561504cc7cd4">130: On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.621947</td>
<td>0.972310</td>
<td><a href="https://www.semanticscholar.org/paper/fce28adcc4458a2c69604cd16fa3bfe98e3f92a9">5: Harnessing Explanations to Bridge AI and Humans</a></td>
</tr>
<tr>
<td>0</td>
<td>0.559963</td>
<td>0.971662</td>
<td><a href="https://www.semanticscholar.org/paper/bc89a6fbf43cf911f71e5428d0b4a70fa5a40be9">34: A Human-Centered Agenda for Intelligible Machine Learning</a></td>
</tr>
<tr>
<td>0</td>
<td>0.731712</td>
<td>0.971608</td>
<td><a href="https://www.semanticscholar.org/paper/449ff2404a7b11fa3c47cd228fa5469b00ffef20">8: Towards a Science of Human-AI Decision Making: A Survey of Empirical Studies</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674599</td>
<td>0.969769</td>
<td><a href="https://www.semanticscholar.org/paper/600cf858bf86cc22e03eeb5c3580b237c8b695ce">61: What can AI do for me?: evaluating machine learning interpretations in cooperative play</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801321</td>
<td>0.967948</td>
<td><a href="https://www.semanticscholar.org/paper/9da6390af0fee98c571f1cb4814cc89d0b6bf9e3">1: On the Effect of Information Asymmetry in Human-AI Teams</a></td>
</tr>
<tr>
<td>0</td>
<td>0.664754</td>
<td>0.966587</td>
<td><a href="https://www.semanticscholar.org/paper/8dd94f8a907493cef47fb7726eff14850c7088b8">38: "Why is 'Chicago' deceptive?" Towards Building Model-Driven Tutorials for Humans</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762449</td>
<td>0.964550</td>
<td><a href="https://www.semanticscholar.org/paper/4244da5fc9b7e57ae7bb0c1b4c08c662af595a23">70: Proxy tasks and subjective measures can be misleading in evaluating explainable AI systems</a></td>
</tr>
</table></html>
