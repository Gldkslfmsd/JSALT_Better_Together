<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/05e6314a3456ba2efae7c9262212eab7be5923e2">174: Automatically generating user interfaces adapted to users' motor and vision capabilities</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825932</td>
<td>0.922399</td>
<td><a href="https://www.semanticscholar.org/paper/821031d4b93c173a8215129a17a31960351dd646">32: Automatically generating custom user interfaces for users with physical disabilities</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784992</td>
<td>0.171987</td>
<td><a href="https://www.semanticscholar.org/paper/d2013c82e565d8b9bda79c22eecfa34e6f684da2">0: EYEHOME 3.0 A Multimodal Input System with Adaptive User Interfaces for the Severely Motor Impaired</a></td>
</tr>
<tr>
<td>0</td>
<td>0.769138</td>
<td>0.171987</td>
<td><a href="https://www.semanticscholar.org/paper/aaf2af33fc865b20f4c8a28a3f181f6a90bb6458">0: Combining vision and cognition for human computer intelligent interfaces</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762472</td>
<td>0.604675</td>
<td><a href="https://www.semanticscholar.org/paper/1f3ceae393979c27343d5a1e0d3efe96b534cc1d">11: Adaptive Mouse-Replacement Interface Control Functions for Users with Disabilities</a></td>
</tr>
<tr>
<td>0</td>
<td>0.755942</td>
<td>0.628709</td>
<td><a href="https://www.semanticscholar.org/paper/623a78e444e17d6e7dca7ee5db996774886b1bcd">9: Can User-Paced, Menu-free Spoken Language Interfaces Improve Dual Task Handling While Driving?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.741789</td>
<td>0.874157</td>
<td><a href="https://www.semanticscholar.org/paper/3194e7d5722ca94fdab002c5033e2da51fc97308">24: User Model to Design Adaptable Interfaces for Motor-Impaired Users</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740211</td>
<td>0.757028</td>
<td><a href="https://www.semanticscholar.org/paper/337e6bb1ed32cd9613318825a24accfcef68586c">0: Towards Adaptive Switches through implementation of visual feedback in assistive devices</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736248</td>
<td>0.789218</td>
<td><a href="https://www.semanticscholar.org/paper/ef4c10c7801bee4e56eb3887c44313302df8c07e">10: Some virtues and limitations of action inferring interfaces</a></td>
</tr>
<tr>
<td>0</td>
<td>0.736130</td>
<td>0.521284</td>
<td><a href="https://www.semanticscholar.org/paper/9abff27b4ff4243a808720fd9e548922c23994c7">6: Goal-recognition-based adaptive brain-computer interface for navigating immersive robotic systems.</a></td>
</tr>
<tr>
<td>0</td>
<td>0.865407</td>
<td>0.967176</td>
<td><a href="https://www.semanticscholar.org/paper/de4b2e736615bf25f37efb5305bf7586aa5cbe0e">199: Improving the performance of motor-impaired users with automatically-generated, ability-based interfaces</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723733</td>
<td>0.953901</td>
<td><a href="https://www.semanticscholar.org/paper/837b45c80881c4f2b745bfd36be9ee1f9b8a8a6e">33: Dynamically adapting GUIs to diverse input devices</a></td>
</tr>
<tr>
<td>0</td>
<td>0.627421</td>
<td>0.953873</td>
<td><a href="https://www.semanticscholar.org/paper/6837db983d2e0d22d0cd7bef75bff304a4d616ab">1: A Personalized Interaction Approach: Motivation and Use Case</a></td>
</tr>
<tr>
<td>0</td>
<td>0.743952</td>
<td>0.947574</td>
<td><a href="https://www.semanticscholar.org/paper/e7dab4e88f5c0e59e67354e059d472d69b74c95f">12: Adaptive click-and-cross: adapting to both abilities and task improves performance of users with impaired dexterity</a></td>
</tr>
<tr>
<td>0</td>
<td>0.654636</td>
<td>0.942701</td>
<td><a href="https://www.semanticscholar.org/paper/192356ca3d869811ada5110ff2045ea97715d1f7">41: Using handhelds to help people with motor impairments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.602993</td>
<td>0.940353</td>
<td><a href="https://www.semanticscholar.org/paper/862fed88fa5c3fe56292781f1ff6a3b02fde0261">1: Dynamic Accessibility: Detecting and Accommodating Differences in Ability and Situation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.600378</td>
<td>0.939781</td>
<td><a href="https://www.semanticscholar.org/paper/5fedbeff15f7f1885082343680f09d54f2190a2e">41: Developing accessible TV applications</a></td>
</tr>
<tr>
<td>0</td>
<td>0.515258</td>
<td>0.935342</td>
<td><a href="https://www.semanticscholar.org/paper/fd1e8945d5a72b8da47eecf2639dadb916468b37">14: Assisted Interaction Data Analysis of Web-Based User Studies</a></td>
</tr>
<tr>
<td>0</td>
<td>0.633534</td>
<td>0.932450</td>
<td><a href="https://www.semanticscholar.org/paper/d6ec3b4e914dc922e55f31c7420b43636e92f92f">133: AppLens and launchTile: two designs for one-handed thumb use on small devices</a></td>
</tr>
</table></html>
