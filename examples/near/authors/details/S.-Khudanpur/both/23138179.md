<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/5005a3295dc2c931526438dd6d3f8fae8e34b641">418: A study on data augmentation of reverberant speech for robust speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.863167</td>
<td>0.600100</td>
<td><a href="https://www.semanticscholar.org/paper/c2293e3bc676274a9b84790a016c4b9ebfb96f69">3: Acoustic modeling based on early-to-late reverberation ratio for robust ASR</a></td>
</tr>
<tr>
<td>0</td>
<td>0.860719</td>
<td>0.846669</td>
<td><a href="https://www.semanticscholar.org/paper/9242cc3228e6d43b5cbe68ada0f05477b3405378">1: Acoustic Model Ensembling Using Effective Data Augmentation for CHiME-5 Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.852821</td>
<td>0.768274</td>
<td><a href="https://www.semanticscholar.org/paper/20c83198bba34c88a31fd6184a405e0ee2f073ae">2: An Adaptation Method in Noise Mismatch Conditions for DNN-based Speech Enhancement</a></td>
</tr>
<tr>
<td>0</td>
<td>0.851797</td>
<td>0.608224</td>
<td><a href="https://www.semanticscholar.org/paper/99216a8689fda351363ef3bdc5f5e53e8a9af89c">22: A corpus-based approach for robust ASR in reverberant environments</a></td>
</tr>
<tr>
<td>0</td>
<td>0.849107</td>
<td>0.712893</td>
<td><a href="https://www.semanticscholar.org/paper/2146614220472ad3d698dff5cc08076b82e27f9e">4: Robust DNN-Based Speech Enhancement with Limited Training Data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.842322</td>
<td>0.813905</td>
<td><a href="https://www.semanticscholar.org/paper/497fd77f9dd4813e5928ded7ed46e9839abababc">1: Investigation of Monaural Front-End Processing for Robust ASR without Retraining or Joint-Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.838807</td>
<td>0.735572</td>
<td><a href="https://www.semanticscholar.org/paper/5e0eb42ee15004e3b3408201b11a1c9fdddb6185">72: The ACE challenge â€” Corpus description and performance evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.833046</td>
<td>0.376871</td>
<td><a href="https://www.semanticscholar.org/paper/8074e8a5d9da7eae3f500a0f76a15a486362f005">2: Lasso-based reverberation suppression in automatic speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.832315</td>
<td>0.813281</td>
<td><a href="https://www.semanticscholar.org/paper/5b46335627e4661712c0f35d03e1289835400b08">53: Two-Stage Deep Learning for Noisy-Reverberant Speech Enhancement</a></td>
</tr>
<tr>
<td>0</td>
<td>0.742144</td>
<td>0.981734</td>
<td><a href="https://www.semanticscholar.org/paper/ad9ae55f07e0311fe7288855e208d9fb2a799b71">14: The VOiCES from a Distance Challenge 2019</a></td>
</tr>
<tr>
<td>0</td>
<td>0.680060</td>
<td>0.977023</td>
<td><a href="https://www.semanticscholar.org/paper/f57951f0dcf93c6011fe8281ed23fe7639f2a081">1: The XMUSPEECH System for the AP19-OLR Challenge</a></td>
</tr>
<tr>
<td>0</td>
<td>0.728377</td>
<td>0.973750</td>
<td><a href="https://www.semanticscholar.org/paper/b3a0d0af025bda1f09ee60b063927989ea88e11d">23: Personal VAD: Speaker-Conditioned Voice Activity Detection</a></td>
</tr>
<tr>
<td>0</td>
<td>0.655442</td>
<td>0.972062</td>
<td><a href="https://www.semanticscholar.org/paper/63fa9d5a24af3a897d5a007a989036ceab73bb3d">130: Spoken Language Recognition using X-vectors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.653136</td>
<td>0.971779</td>
<td><a href="https://www.semanticscholar.org/paper/9f5f12800d0678362d009544b97c7b7c823782f1">14: Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.647383</td>
<td>0.970974</td>
<td><a href="https://www.semanticscholar.org/paper/4243785d952c14b94c4d1966b71f23b381efff9f">21: Attention Mechanism in Speaker Recognition: What Does it Learn in Deep Speaker Embedding?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.678189</td>
<td>0.970822</td>
<td><a href="https://www.semanticscholar.org/paper/728e89e403b2a445a0b7dd9001424772a2a636fc">2: Speaker Verification Employing Combinations of Self-Attention Mechanisms</a></td>
</tr>
<tr>
<td>0</td>
<td>0.644377</td>
<td>0.968886</td>
<td><a href="https://www.semanticscholar.org/paper/638dd69688b38b808b90ab7a3992b90e543c9142">2: SpeakerStew: Scaling to Many Languages with a Triaged Multilingual Text-Dependent and Text-Independent Speaker Verification System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.751267</td>
<td>0.967642</td>
<td><a href="https://www.semanticscholar.org/paper/e5dd20eb15f0e4811156cce8b4cf930bd002d43e">184: Speaker diarization using deep neural network embeddings</a></td>
</tr>
</table></html>
