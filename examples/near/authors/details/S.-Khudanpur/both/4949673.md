<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/78b29eba4d6c836483c0aa67d637205e95223ae4">280: Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.776607</td>
<td>0.463896</td>
<td><a href="https://www.semanticscholar.org/paper/0968d2e4759a202f4c4e8127931dbc0522ff22d8">0: A note on factor normalization for deep neural network models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.774626</td>
<td>0.049051</td>
<td><a href="https://www.semanticscholar.org/paper/219fe829c26e741bca221426b30e753de33321a1">0: Learning Polynomial Neural Networks via Low Rank Tensor Recovery</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762737</td>
<td>0.528719</td>
<td><a href="https://www.semanticscholar.org/paper/8e3282595e7f73cb6478b207c2e510026525bd38">14: Neural network alternatives toconvolutive audio models for source separation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.748202</td>
<td>0.467329</td>
<td><a href="https://www.semanticscholar.org/paper/675ac07ad45971043dd41be4b62b92f4435fbda4">42: A neural network alternative to non-negative audio models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732301</td>
<td>0.685478</td>
<td><a href="https://www.semanticscholar.org/paper/ca6e502623b2ad7f0e67e4e14497c36cfa6912a8">16: Multi-Modal Hybrid Deep Neural Network for Speech Enhancement</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732006</td>
<td>-0.019519</td>
<td><a href="https://www.semanticscholar.org/paper/9873de5a40b615eb7cf279e66f1d4357eb07773e">0: Low-rank passthrough neural networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.730042</td>
<td>0.255846</td>
<td><a href="https://www.semanticscholar.org/paper/fe335326841381bf3274747ea1e5d0b387a63b38">46: Same, Same But Different - Recovering Neural Network Quantization Error Through Weight Factorization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.724143</td>
<td>0.457082</td>
<td><a href="https://www.semanticscholar.org/paper/d4b86f40bd1b4baf99e76d95ee5912c13d4c52fc">26: Learning Compressed Transforms with Low Displacement Rank</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723968</td>
<td>-0.019519</td>
<td><a href="https://www.semanticscholar.org/paper/95c0b00d7339b4eabdb6a2b476de670bab694367">0: Tensor Convolutional Dictionary Learning With CP Low-Rank Activations</a></td>
</tr>
<tr>
<td>0</td>
<td>0.557438</td>
<td>0.976294</td>
<td><a href="https://www.semanticscholar.org/paper/896663e03eef1b46deac6123450dfcc538b7b30f">0: Multilingual Approach to Joint Speech and Accent Recognition with DNN-HMM Framework</a></td>
</tr>
<tr>
<td>0</td>
<td>0.619448</td>
<td>0.974881</td>
<td><a href="https://www.semanticscholar.org/paper/0a085d9e37796ade9b9d00b2b2787376e09122cd">12: Cross-Language Transfer Learning, Continuous Learning, and Domain Adaptation for End-to-End Automatic Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.566387</td>
<td>0.969228</td>
<td><a href="https://www.semanticscholar.org/paper/0971ad49ed7f063375d7a21bdfc2fab347d68ba8">1: Transformer-based Arabic Dialect Identification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.573650</td>
<td>0.967291</td>
<td><a href="https://www.semanticscholar.org/paper/0736a106ae67aa190032f2c244aba505cdf434df">0: Contextual Phonetic Pre-training for End-to-end Utterance-level Language and Speaker Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.578954</td>
<td>0.967264</td>
<td><a href="https://www.semanticscholar.org/paper/65eacd3003fa076f8b969895d41b7f6ed95efdb2">0: Pretraining for End-to-end Utterance-level Language and Speaker Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.579283</td>
<td>0.967227</td>
<td><a href="https://www.semanticscholar.org/paper/9ade0dc842687cf4bd5b050c3ceace21a0e7dea8">0: Contextual Phonetic Pretraining for End-to-end Utterance-level Language and Speaker Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.625721</td>
<td>0.967095</td>
<td><a href="https://www.semanticscholar.org/paper/187be9194de4974e428409a8693d1bdba7dd6e7d">7: MixSpeech: Data Augmentation for Low-Resource Automatic Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.553263</td>
<td>0.966693</td>
<td><a href="https://www.semanticscholar.org/paper/c9369029144e1815276c4a08751d4f87806b394a">7: Minimum Bayes Risk Training for End-to-End Speaker-Attributed ASR</a></td>
</tr>
<tr>
<td>0</td>
<td>0.596772</td>
<td>0.966128</td>
<td><a href="https://www.semanticscholar.org/paper/6632853535bd7f7f9c438d19467341f6e46a63e5">51: Joint Speech Recognition and Speaker Diarization via Sequence Transduction</a></td>
</tr>
</table></html>
