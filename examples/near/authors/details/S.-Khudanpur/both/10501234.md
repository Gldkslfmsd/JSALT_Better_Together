<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/6ce6a9a30cd69bd2842a4b581cf48c6815bdfdd8">702: Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI</a></td>
</tr>
<tr>
<td>0</td>
<td>0.843048</td>
<td>0.850232</td>
<td><a href="https://www.semanticscholar.org/paper/17142d06d5cd934ebd6cc22202e0b585c06a9f8f">121: Semi-supervised training of Deep Neural Networks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830487</td>
<td>0.828166</td>
<td><a href="https://www.semanticscholar.org/paper/571c9435108129ac02ddcec6b75f49a1bb77fdce">0: Multilingual Deep Neural Network Training Using Cyclical Learning Rate</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820308</td>
<td>0.931880</td>
<td><a href="https://www.semanticscholar.org/paper/66da8cf0069519e7f3e13621bd439b25d3393593">19: Model Unit Exploration for Sequence-to-Sequence Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.801588</td>
<td>0.962016</td>
<td><a href="https://www.semanticscholar.org/paper/e6901a5e6ce3e41b536878abd8eecefaf437ea65">18: Syllable-based acoustic modeling with CTC-SMBR-LSTM</a></td>
</tr>
<tr>
<td>0</td>
<td>0.794862</td>
<td>0.616704</td>
<td><a href="https://www.semanticscholar.org/paper/5b0d644f5c4b9880cbaf79932c0a4fa98996f068">516: A fast and simple algorithm for training neural probabilistic language models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793737</td>
<td>0.733161</td>
<td><a href="https://www.semanticscholar.org/paper/0fcc184b3b90405ec3ceafd6a4007c749df7c363">551: Continuous space language models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791884</td>
<td>0.913989</td>
<td><a href="https://www.semanticscholar.org/paper/e288f196d5deaa3d81794911944bd0af89a39158">6: Multi-Task Multi-Resolution Char-to-BPE Cross-Attention Decoder for End-to-End Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786955</td>
<td>0.836778</td>
<td><a href="https://www.semanticscholar.org/paper/ce6e1ae07bc798474c1a6ca4b58cb90e0aa1c587">1: OOV Recovery with Efficient 2nd Pass Decoding and Open-vocabulary Word-level RNNLM Rescoring for Hybrid ASR</a></td>
</tr>
<tr>
<td>0</td>
<td>0.786526</td>
<td>0.541450</td>
<td><a href="https://www.semanticscholar.org/paper/8b0df85e0a11fbeb213c6d82fb2b0a572371fe5d">15: Lattice-based Viterbi decoding techniques for speech translation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845624</td>
<td>0.995383</td>
<td><a href="https://www.semanticscholar.org/paper/dcaeb29ad3307e2bdab2218416c81cb0c4e548b2">116: End-to-end Speech Recognition Using Lattice-free MMI</a></td>
</tr>
<tr>
<td>0</td>
<td>0.778003</td>
<td>0.992237</td>
<td><a href="https://www.semanticscholar.org/paper/2683061823326301221f3604b5b071957b54be2c">14: Unsupervised Speaker Adaptation Using Attention-Based Speaker Memory for End-to-End ASR</a></td>
</tr>
<tr>
<td>0</td>
<td>0.758599</td>
<td>0.991652</td>
<td><a href="https://www.semanticscholar.org/paper/c3ae50a65810198979724a9c22fa5c7babe5e914">6: Utterance Invariant Training for Hybrid Two-Pass End-to-End Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.752871</td>
<td>0.991431</td>
<td><a href="https://www.semanticscholar.org/paper/e6504f8e3b4b3cf429b8d3ce4091ae9d1afa5df3">78: Multi-Dialect Speech Recognition with a Single Sequence-to-Sequence Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.668229</td>
<td>0.990245</td>
<td><a href="https://www.semanticscholar.org/paper/7be16462d6c01298974b4d211603f5d845fed502">0: Monolingual Data Selection Analysis for English-Mandarin Hybrid Code-Switching Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.771271</td>
<td>0.987923</td>
<td><a href="https://www.semanticscholar.org/paper/da8c898dfe4804ed60833ee0d019969a8c588a46">66: Letter-Based Speech Recognition with Gated ConvNets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785722</td>
<td>0.987683</td>
<td><a href="https://www.semanticscholar.org/paper/07b7d42f6b229eac4e0e76fe2442fb713d0a1ab3">2: On Lattice-Free Boosted MMI Training of HMM and CTC-Based Full-Context ASR Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.632132</td>
<td>0.987226</td>
<td><a href="https://www.semanticscholar.org/paper/1e0b8416b9d2afb9b1ef87557958ef964cb4472b">188: TED-LIUM: an Automatic Speech Recognition dedicated corpus</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732759</td>
<td>0.986766</td>
<td><a href="https://www.semanticscholar.org/paper/2fdaf478beee9ce7c433a5e72c03a0e1b83d981f">2: Reducing Spelling Inconsistencies in Code-Switching ASR Using Contextualized CTC Loss</a></td>
</tr>
</table></html>
