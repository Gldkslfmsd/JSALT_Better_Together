<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/34038d9424ce602d7ac917a4e582d977725d4393">2569: Librispeech: An ASR corpus based on public domain audio books</a></td>
</tr>
<tr>
<td>0</td>
<td>0.803058</td>
<td>0.917146</td>
<td><a href="https://www.semanticscholar.org/paper/8912a429df703b8a3c5c17fe99b7484a260e9c21">2: MediaSpeech: Multilanguage ASR Benchmark and Dataset</a></td>
</tr>
<tr>
<td>0</td>
<td>0.791996</td>
<td>0.294194</td>
<td><a href="https://www.semanticscholar.org/paper/87731209ff1cb6f7c0ad85d0dd5810337531bbdc">2: Automatic speech recognition system for under-resourced languages based on Speeral: application to berber language</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790785</td>
<td>0.364444</td>
<td><a href="https://www.semanticscholar.org/paper/ad91d3df2fed6128701476ddb28fe7ce2a379269">1: GTH-UPM system for search on speech evaluation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785251</td>
<td>0.425963</td>
<td><a href="https://www.semanticscholar.org/paper/65a669d09a1659f5a3f0d168c6edc430ff3ae75e">3: Are audio or textual training data more important for ASR in less-represented languages?</a></td>
</tr>
<tr>
<td>0</td>
<td>0.783687</td>
<td>0.370994</td>
<td><a href="https://www.semanticscholar.org/paper/8c5dac6e147ed032f8625a81b2773cadc1806005">37: Towards automatic transcription of large spoken archives - English ASR for the MALACH project</a></td>
</tr>
<tr>
<td>0</td>
<td>0.777246</td>
<td>0.370398</td>
<td><a href="https://www.semanticscholar.org/paper/05630f36f8aae3f536eceac732ba56e3d8e5cbff">68: Training LVCSR systems on thousands of hours of data</a></td>
</tr>
<tr>
<td>0</td>
<td>0.771868</td>
<td>0.679496</td>
<td><a href="https://www.semanticscholar.org/paper/32027985db867890ce3f79fd262dcdf4ee6e8dc9">21: Simulating ASR errors for training SLU systems</a></td>
</tr>
<tr>
<td>0</td>
<td>0.771538</td>
<td>0.777396</td>
<td><a href="https://www.semanticscholar.org/paper/b32c0704de409e0b672f311edf8e2c7d1ae8793b">36: Acoustic and Textual Data Augmentation for Improved ASR of Code-Switching Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.765889</td>
<td>0.496264</td>
<td><a href="https://www.semanticscholar.org/paper/76eb7082ed1a72c37871d3bab3e7323828edbda2">1: The NECTEC 2015 Thai Open-Domain Automatic Speech Recognition System</a></td>
</tr>
<tr>
<td>0</td>
<td>0.778341</td>
<td>0.980096</td>
<td><a href="https://www.semanticscholar.org/paper/5a8bb7b192373d8222a6efd99de4f9042da06f37">304: AISHELL-1: An open-source Mandarin speech corpus and a speech recognition baseline</a></td>
</tr>
<tr>
<td>0</td>
<td>0.674184</td>
<td>0.973290</td>
<td><a href="https://www.semanticscholar.org/paper/57341a6a1689f9b30d02ef602dc40c77217ab968">45: Speech Recognition with Augmented Synthesized Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.738201</td>
<td>0.972444</td>
<td><a href="https://www.semanticscholar.org/paper/d85b2af4f163383bbfa62b73d5f0b179868cc9a8">139: Jasper: An End-to-End Convolutional Neural Acoustic Model</a></td>
</tr>
<tr>
<td>0</td>
<td>0.699854</td>
<td>0.969056</td>
<td><a href="https://www.semanticscholar.org/paper/b79cd3e0e2b154922b5cd16e1fbed9cb44e5a59f">72: SpeechBrain: A General-Purpose Speech Toolkit</a></td>
</tr>
<tr>
<td>0</td>
<td>0.688900</td>
<td>0.968428</td>
<td><a href="https://www.semanticscholar.org/paper/92afb4be3569112e177c69b0d9830e1f8211a46f">22: Improving Speech Recognition Using Consistent Predictions on Synthesized Speech</a></td>
</tr>
<tr>
<td>0</td>
<td>0.694579</td>
<td>0.967621</td>
<td><a href="https://www.semanticscholar.org/paper/4097148c147f06b54802000a8476d28e525c63cf">68: Specaugment on Large Scale Datasets</a></td>
</tr>
<tr>
<td>0</td>
<td>0.756735</td>
<td>0.966944</td>
<td><a href="https://www.semanticscholar.org/paper/63a71de0dafc90910e37a2b07169ff486d9b5fe5">267: Common Voice: A Massively-Multilingual Speech Corpus</a></td>
</tr>
<tr>
<td>0</td>
<td>0.660271</td>
<td>0.965573</td>
<td><a href="https://www.semanticscholar.org/paper/1553084dcbf2235428e7dbf57b57e567c5ea4d1f">106: AISHELL-2: Transforming Mandarin ASR Research Into Industrial Scale</a></td>
</tr>
<tr>
<td>0</td>
<td>0.661665</td>
<td>0.965064</td>
<td><a href="https://www.semanticscholar.org/paper/b5395b0e878cefea90963250ada81b0f2ec8b9d1">19: Semi-Supervised Speech Recognition via Local Prior Matching</a></td>
</tr>
</table></html>
