<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/9cee45ef1212ebbc7d468f9b1d7df24f5005e64d">254: Highway long short-term memory RNNS for distant speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.854450</td>
<td>0.907694</td>
<td><a href="https://www.semanticscholar.org/paper/67949bf003dfc734c0f70a97828c1bfa436e5eea">8: Deep long short-term memory networks for speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.853455</td>
<td>0.950629</td>
<td><a href="https://www.semanticscholar.org/paper/cac32ca03bf3a4a8b4a726f19f539c729493ddc5">11: Exploiting LSTM structure in deep neural networks for speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.845802</td>
<td>0.974173</td>
<td><a href="https://www.semanticscholar.org/paper/725f82ddd348829f4ec49bf436dc4b8bde4a019a">15: COMPARING GRU AND LSTM FOR AUTOMATIC SPEECH RECOGNITION</a></td>
</tr>
<tr>
<td>0</td>
<td>0.844661</td>
<td>0.932211</td>
<td><a href="https://www.semanticscholar.org/paper/eb62dabac5f62f267a42b9f2615e057dd21eb9d3">23: Compact Feedforward Sequential Memory Networks for Large Vocabulary Continuous Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.837607</td>
<td>0.948934</td>
<td><a href="https://www.semanticscholar.org/paper/d103a6038c8f6741a7cd61c082d6402b5c0490d7">6: Investigating gated recurrent neural networks for acoustic modeling</a></td>
</tr>
<tr>
<td>0</td>
<td>0.834023</td>
<td>0.968113</td>
<td><a href="https://www.semanticscholar.org/paper/f84a30bf0554ee3e1c06cad52fe66f072956849b">25: Highway-LSTM and Recurrent Highway Networks for Speech Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.831061</td>
<td>0.935297</td>
<td><a href="https://www.semanticscholar.org/paper/cb37280f37b27efa04671bb6c38b613df7fb24ea">37: On Extended Long Short-term Memory and Dependent Bidirectional Recurrent Neural Network</a></td>
</tr>
<tr>
<td>0</td>
<td>0.821129</td>
<td>0.934019</td>
<td><a href="https://www.semanticscholar.org/paper/ec3738e45785b225d2e691299556ed7c838db4ba">20: Investigation on LSTM Recurrent N-gram Language Models for Speech Recognition</a></td>
</tr>
<tr>
<td>1</td>
<td>0.820833</td>
<td>0.983179</td>
<td><a href="https://www.semanticscholar.org/paper/28dd49edb8fda8188426e0396e5f260fee28bb3a">47: Improving latency-controlled BLSTM acoustic models for online speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.784231</td>
<td>0.989095</td>
<td><a href="https://www.semanticscholar.org/paper/9fca2af9a0e3f2c5c3ed47abb3ebd21b7265ac2b">377: Fast and accurate recurrent neural network acoustic models for speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.830417</td>
<td>0.988290</td>
<td><a href="https://www.semanticscholar.org/paper/d026408dc768588c1eef86302e967104c73ecb97">73: Simplifying long short-term memory acoustic models for fast training and decoding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.704105</td>
<td>0.985665</td>
<td><a href="https://www.semanticscholar.org/paper/25a5e8219b37354a27a6ab901759f27089f56a92">1: Using multi-task learning to improve the performance of acoustic-to-word and conventional hybrid models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.672617</td>
<td>0.984264</td>
<td><a href="https://www.semanticscholar.org/paper/39562f94f8cb0469ce3a7febbbca7887b577efb3">6: End-to-End Speech Recognition in Agglutinative Languages</a></td>
</tr>
<tr>
<td>0</td>
<td>0.808206</td>
<td>0.983828</td>
<td><a href="https://www.semanticscholar.org/paper/97acdfb3d247f8250d865ef8a9169f06e40f138b">608: EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding</a></td>
</tr>
<tr>
<td>0</td>
<td>0.840874</td>
<td>0.982702</td>
<td><a href="https://www.semanticscholar.org/paper/055681baf0722ef6ed3e27ade1e5d7c99efefa6c">138: A comprehensive study of deep bidirectional LSTM RNNS for acoustic modeling in speech recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.762078</td>
<td>0.981339</td>
<td><a href="https://www.semanticscholar.org/paper/b0316d17fef2a42fba426426e5ea090a83205aaa">79: An Exploration of Dropout with LSTMs</a></td>
</tr>
<tr>
<td>0</td>
<td>0.636441</td>
<td>0.981322</td>
<td><a href="https://www.semanticscholar.org/paper/f6fda11d2b31ad66dd008a65f7e708aa64a27703">130: Architectural Complexity Measures of Recurrent Neural Networks</a></td>
</tr>
</table></html>
