<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/389cd9824428be98a710f5f4de67121a70c15fd3">1351: X-Vectors: Robust DNN Embeddings for Speaker Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.864258</td>
<td>0.965195</td>
<td><a href="https://www.semanticscholar.org/paper/1bac915fdb518acf5c649de08e7f192e1dd3c803">48: Probing the Information Encoded in X-Vectors</a></td>
</tr>
<tr>
<td>0</td>
<td>0.862407</td>
<td>0.957395</td>
<td><a href="https://www.semanticscholar.org/paper/ec7ff1cefcd86523f98652150686de7ae1531287">30: x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.862171</td>
<td>0.040596</td>
<td>NA:226222418</td>
</tr>
<tr>
<td>0</td>
<td>0.859083</td>
<td>0.952835</td>
<td><a href="https://www.semanticscholar.org/paper/61668c48893ec216549a52a1b67f5c854478a2cc">1: Review of different robust x-vector extractors for speaker verification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.857782</td>
<td>0.918408</td>
<td><a href="https://www.semanticscholar.org/paper/e81e44772c95e1283f0806c6101c161418ebb883">51: Margin Matters: Towards More Discriminative Deep Neural Network Embeddings for Speaker Recognition</a></td>
</tr>
<tr>
<td>0</td>
<td>0.853678</td>
<td>0.948221</td>
<td><a href="https://www.semanticscholar.org/paper/6e9e31323045de5b319ba568e849b844a7c3bf81">0: Review of different robust x-vector extractors for speaker verification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.851501</td>
<td>0.812726</td>
<td><a href="https://www.semanticscholar.org/paper/2b68230ba08a8280e5910b8c2a80ec87b108f4ed">1: On Metric-based Deep Embedding Learning for Text-Independent Speaker Verification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.849985</td>
<td>0.895866</td>
<td><a href="https://www.semanticscholar.org/paper/aea1bc7f8c098763a3291bee4212ce766e60543e">3: Cosine-Distance Virtual Adversarial Training for Semi-Supervised Speaker-Discriminative Acoustic Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.849946</td>
<td>0.864122</td>
<td><a href="https://www.semanticscholar.org/paper/5dc0c04b95ec5194a8d3ab7a61a2cd616a8ac629">3: Analysis of Complementary Information Sources in the Speaker Embeddings Framework</a></td>
</tr>
<tr>
<td>0</td>
<td>0.809383</td>
<td>0.981133</td>
<td><a href="https://www.semanticscholar.org/paper/984263114a79a53699e26e431bf0ef545b47a42c">29: On the Usage of Phonetic Information for Text-Independent Speaker Embedding Extraction</a></td>
</tr>
<tr>
<td>0</td>
<td>0.590583</td>
<td>0.980997</td>
<td><a href="https://www.semanticscholar.org/paper/32d21dc13f8770958b196a96f99a6f3959c7dc0f">535: MUSAN: A Music, Speech, and Noise Corpus</a></td>
</tr>
<tr>
<td>0</td>
<td>0.619657</td>
<td>0.980338</td>
<td><a href="https://www.semanticscholar.org/paper/93122c7d659c036e9e290aebd0a28812cd71453c">72: Voices Obscured in Complex Environmental Settings (VOICES) corpus</a></td>
</tr>
<tr>
<td>0</td>
<td>0.867183</td>
<td>0.980061</td>
<td><a href="https://www.semanticscholar.org/paper/369728d7576683a25de8890e4bc02fae6132fccb">489: Deep Neural Network Embeddings for Text-Independent Speaker Verification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793769</td>
<td>0.978517</td>
<td><a href="https://www.semanticscholar.org/paper/8ecff6041fe1a46503a783b8d5ef0280e097ee81">6: Text Adaptation for Speaker Verification with Speaker-Text Factorized Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.814782</td>
<td>0.977522</td>
<td><a href="https://www.semanticscholar.org/paper/afb5e74474e239b32b97aa27e13ae2f83c171de8">171: Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.793073</td>
<td>0.975356</td>
<td><a href="https://www.semanticscholar.org/paper/67647780d9e13667bd9776fcdcee55e339264007">7: Bridging Mixture Density Networks with Meta-Learning for Automatic Speaker Identification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.750714</td>
<td>0.974870</td>
<td><a href="https://www.semanticscholar.org/paper/ca965906f9d411b70761afebdaa2aad0bf8282f2">0: Learning Device-invariant And Location-invariant Embedding For Speaker Verification Using Adversarial Multi-task Training</a></td>
</tr>
<tr>
<td>0</td>
<td>0.715833</td>
<td>0.973354</td>
<td><a href="https://www.semanticscholar.org/paper/f22b4182cdbe1b564f237ab6835376125248e9a6">441: Generalized End-to-End Loss for Speaker Verification</a></td>
</tr>
</table></html>
