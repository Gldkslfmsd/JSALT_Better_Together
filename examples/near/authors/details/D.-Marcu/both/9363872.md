<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/25f51f4132626a645924b3c8b3edcbdcc35c48a3">471: Statistics-Based Summarization - Step One: Sentence Compression</a></td>
</tr>
<tr>
<td>1</td>
<td>0.967024</td>
<td>0.998485</td>
<td><a href="https://www.semanticscholar.org/paper/fa07fa673d8c908e91d22c4566572a72548ccee9">521: Summarization beyond sentence extraction: A probabilistic approach to sentence compression</a></td>
</tr>
<tr>
<td>0</td>
<td>0.839926</td>
<td>0.837698</td>
<td><a href="https://www.semanticscholar.org/paper/b515e3e14ea5de615831c75238ec61d9ab545ba7">0: EXTRACTIVE DOCUMENT SUMMARIZATION</a></td>
</tr>
<tr>
<td>0</td>
<td>0.835728</td>
<td>0.658826</td>
<td><a href="https://www.semanticscholar.org/paper/5cebe6d3f70663d19f0d92154cad86c2d58a649c">32: Summary Level Training of Sentence Rewriting for Abstractive Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.828054</td>
<td>0.624346</td>
<td><a href="https://www.semanticscholar.org/paper/ed32242d76f0f52e3eace19b0314868f1d868b89">23: The Summary Loop: Learning to Write Abstractive Summaries Without Examples</a></td>
</tr>
<tr>
<td>0</td>
<td>0.825810</td>
<td>0.868458</td>
<td><a href="https://www.semanticscholar.org/paper/d442889917cf546fb9f54a28dda6db8754af9296">2: Neural Sentence Location Prediction for Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.820402</td>
<td>0.944144</td>
<td><a href="https://www.semanticscholar.org/paper/8b43d11ca01316f0e96c07f6481b6b3a04a78040">76: Ultra-summarization (poster abstract): a statistical approach to generating highly condensed non-extractive summaries</a></td>
</tr>
<tr>
<td>0</td>
<td>0.814995</td>
<td>0.951371</td>
<td><a href="https://www.semanticscholar.org/paper/7d63a367501c640f468a12c908b93fc63deebe24">18: Description of the UAM system for generating very short summaries at DUC-2004 âˆ—</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813499</td>
<td>0.834361</td>
<td><a href="https://www.semanticscholar.org/paper/72b8431703196f156bf707ce0209e7637ccd079b">1: Cross-Sentence Transformations in Text Simplification</a></td>
</tr>
<tr>
<td>0</td>
<td>0.813192</td>
<td>0.800273</td>
<td><a href="https://www.semanticscholar.org/paper/7be07436db9ad6f7aaf859aded74767e7d7e308d">105: A Neural Attention Model for Sentence Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.723603</td>
<td>0.998426</td>
<td><a href="https://www.semanticscholar.org/paper/5f9623a2959117dc05f2af3b961fd035a3f22d41">291: Sentence Reduction for Automatic Text Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790888</td>
<td>0.994906</td>
<td><a href="https://www.semanticscholar.org/paper/0d8e3db6fcd99313773fcaa16074f2cc76ce1fef">112: Syntactic Simplification for Improving Content Selection in Multi-Document Summarization</a></td>
</tr>
<tr>
<td>0</td>
<td>0.795918</td>
<td>0.993962</td>
<td><a href="https://www.semanticscholar.org/paper/f9ad221c2627e2b0d16edfa05e65656447e00b77">156: Multi-candidate reduction: Sentence compression as a tool for document summarization tasks</a></td>
</tr>
<tr>
<td>0</td>
<td>0.768606</td>
<td>0.993898</td>
<td><a href="https://www.semanticscholar.org/paper/013846a1e7ef8e4733496a6260096b70bd259f0e">20: A French Human Reference Corpus for Multi-Document Summarization and Sentence Compression</a></td>
</tr>
<tr>
<td>0</td>
<td>0.710810</td>
<td>0.993647</td>
<td><a href="https://www.semanticscholar.org/paper/3ced0fc0279e7acaebe1e9a28bc1b2067a9fa85e">2: TALAA-ATSF: A Global Operation-Based Arabic Text Summarization Framework</a></td>
</tr>
<tr>
<td>0</td>
<td>0.747375</td>
<td>0.992713</td>
<td><a href="https://www.semanticscholar.org/paper/a1bb253577724d26ebb3fdf1774423e90c0ffcf1">48: Improving summarization performance by sentence compression: a pilot study</a></td>
</tr>
<tr>
<td>0</td>
<td>0.743261</td>
<td>0.992565</td>
<td><a href="https://www.semanticscholar.org/paper/729d81ea218388a228d91a81baef45fead5b5294">6: Sentence Compression in Spanish driven by Discourse Segmentation and Language Models</a></td>
</tr>
<tr>
<td>0</td>
<td>0.790313</td>
<td>0.992395</td>
<td><a href="https://www.semanticscholar.org/paper/21a7b165b2e09cfc166bbbc69fef0732d6d99d5c">417: Sentence Fusion for Multidocument News Summarization</a></td>
</tr>
</table></html>
