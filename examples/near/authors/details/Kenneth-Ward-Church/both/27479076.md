<html><table><tr>
<th>Both</th>
<th>Specter</th>
<th>Proposed</th>
<th>Paper</th>
</tr>
<tr>
<td>1</td>
<td>1.000000</td>
<td>1.000000</td>
<td><a href="https://www.semanticscholar.org/paper/03923a033f22c7e55e201847852190b4439995b7">64: Nonlinear Estimators and Tail Bounds for Dimension Reduction in l1 Using Cauchy Random Projections</a></td>
</tr>
<tr>
<td>0</td>
<td>0.839291</td>
<td>0.739803</td>
<td><a href="https://www.semanticscholar.org/paper/4adf7e3535af819b5da447549c429517dc0d74cd">7: Deterministic Inequalities for Smooth M-estimators</a></td>
</tr>
<tr>
<td>0</td>
<td>0.817950</td>
<td>0.161995</td>
<td>NA:7827074</td>
</tr>
<tr>
<td>0</td>
<td>0.807105</td>
<td>0.700941</td>
<td><a href="https://www.semanticscholar.org/paper/83673cc8b62c2a341357b31a7e0bbaee81b07a02">10: Optimal Linear Shrinkage Estimator for Large Dimensional Precision Matrix</a></td>
</tr>
<tr>
<td>0</td>
<td>0.805196</td>
<td>0.745623</td>
<td><a href="https://www.semanticscholar.org/paper/c562a2479094768fcf76bcc992cdbf12227a98fe">240: Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming</a></td>
</tr>
<tr>
<td>0</td>
<td>0.804642</td>
<td>0.407006</td>
<td><a href="https://www.semanticscholar.org/paper/87bbbb095f58749cda35a1d993632c4d79387e66">29: Analysis of k-Nearest Neighbor Distances with Application to Entropy Estimation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.783988</td>
<td>0.732530</td>
<td><a href="https://www.semanticscholar.org/paper/88670b5bf214998dc4f7fff7f471637ae487143a">33: Adaptive estimation over anisotropic functional classes via oracle approach</a></td>
</tr>
<tr>
<td>0</td>
<td>0.781245</td>
<td>0.409398</td>
<td><a href="https://www.semanticscholar.org/paper/9afc87e2648498831aee3a7d472f8a1365e9de77">0: Dimension-Free Empirical Entropy Estimation</a></td>
</tr>
<tr>
<td>0</td>
<td>0.779821</td>
<td>0.936376</td>
<td><a href="https://www.semanticscholar.org/paper/8d6cf18188945115cf4f8c578d26ac0a66d92186">0: Random Projections with Best Confidence</a></td>
</tr>
<tr>
<td>0</td>
<td>0.778494</td>
<td>0.717054</td>
<td><a href="https://www.semanticscholar.org/paper/ad4df057cbe78cdc087f415806938fa7f671caa7">0: Empirical Bayes Estimators for Sparse Sequences</a></td>
</tr>
<tr>
<td>0</td>
<td>0.732011</td>
<td>0.949771</td>
<td><a href="https://www.semanticscholar.org/paper/edf43a53849fcbd1a22ff743c72f3b5880045a6b">0: Robust and Provable Guarantees for Sparse Random Embeddings</a></td>
</tr>
<tr>
<td>0</td>
<td>0.785626</td>
<td>0.943034</td>
<td><a href="https://www.semanticscholar.org/paper/9dd4083c180761c7388b344e73f23f84d3e01893">2: Exponentially Improved Dimensionality Reduction for ùìÅ1: Subspace Embeddings and Independence Testing</a></td>
</tr>
<tr>
<td>0</td>
<td>0.767675</td>
<td>0.941694</td>
<td><a href="https://www.semanticscholar.org/paper/5a37d2e307c0844aaf0b978886ee78e149968f4c">0: Linear dimension reduction approximately preserving a function of the 1-norm</a></td>
</tr>
<tr>
<td>0</td>
<td>0.696771</td>
<td>0.933788</td>
<td><a href="https://www.semanticscholar.org/paper/0393eaa7d18b9dc117743350efa7388b363985f9">177: On the impossibility of dimension reduction in l1</a></td>
</tr>
<tr>
<td>0</td>
<td>0.823515</td>
<td>0.933497</td>
<td><a href="https://www.semanticscholar.org/paper/5652264d1e12624d14054bfbe18573bb8272352e">12: A Unified Near-Optimal Estimator For Dimension Reduction in l_Œ±(0</a></td>
</tr>
<tr>
<td>0</td>
<td>0.655035</td>
<td>0.932003</td>
<td><a href="https://www.semanticscholar.org/paper/5effa642fc1dc129eb1f9a40a66cf377f9544769">0: Random Embeddings with Optimal Accuracy</a></td>
</tr>
<tr>
<td>0</td>
<td>0.740474</td>
<td>0.930840</td>
<td><a href="https://www.semanticscholar.org/paper/27ba2c4350887185504c4c9e4e66152ca3a802cf">2: Performance of Johnson--Lindenstrauss Transform for $k$-Means and $k$-Medians Clustering</a></td>
</tr>
<tr>
<td>0</td>
<td>0.571668</td>
<td>0.930810</td>
<td><a href="https://www.semanticscholar.org/paper/f20e71257b917c87c360bf993c7b737c808c3028">11: On variants of the JohnsonLindenstrauss lemma</a></td>
</tr>
<tr>
<td>0</td>
<td>0.668874</td>
<td>0.929783</td>
<td><a href="https://www.semanticscholar.org/paper/43265af53799be3ad18acc7ac73a56633f401b99">6: Compressed Least Squares Regression revisited</a></td>
</tr>
</table></html>
